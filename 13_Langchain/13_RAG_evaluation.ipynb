{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RAG 평가 개요\n",
    "- RAG 평가란 RAG 시스템이 주어진 입력에 대해 얼마나 효과적으로 관련 정보를 검색하고, 이를 기반으로 정확하고 유의미한 응답을 생성하는지를 측정하는 과정이다. \n",
    "- **평가 요소**\n",
    "    - **검색 단계 평가**\n",
    "        - 입력 질문에 대해 검색된 문서나 정보의 관련성과 정확성을 평가.\n",
    "    - **생성 단계 평가**\n",
    "        - 검색된 정보를 기반으로 생성된 응답의 품질, 정확성등을 평가.\n",
    "- **평가 방법**\n",
    "    - 온/오프라인 평가\n",
    "        1. **오프라인 평가**\n",
    "            - 미리 준비된 데이터셋을 활용하여 RAG 시스템의 성능을 측정한다.\n",
    "        2. **온라인 평가**\n",
    "            - 실제 사용자 트래픽과 피드백을 기반으로 시스템의 실시간 성능을 평가한다.\n",
    "    - 정량적/정성적 평가\n",
    "        1. 정량적 평가\n",
    "            - 자동화된 지표를 사용하여 생성된 텍스트의 품질을 평가한다.\n",
    "        2. 정성적 평가\n",
    "            - 전문가나 일반 사용자가 직접 생성된 응답의 품질을 평가하여 주관적인 지표를 평가한다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# [RAGAS](https://www.ragas.io/)\n",
    "- RAGAS는 RAG 파이프라인을 **정량적 으로 평가하는** 오픈소스 프레임 워크이다. \n",
    "- RAGAS 문서: https://docs.ragas.io/en/stable/\n",
    "## 설치\n",
    "- `pip install ragas`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RAGAS 평가 지표 개요\n",
    "![ragas_score](figures/ragas_score.png)\n",
    "- **Generation**\n",
    "    - llm 모델이 생성한 답변에 대한 평가 지표들.\n",
    "    - **Faithfulness(신뢰성)**\n",
    "        -  생성된 답변과 검색된 문서(context)간의 관련성을 평가하는 지표\n",
    "        -  생성된 답변이 주어진 문맥(context)에 얼마나 충실한지를 평가하는 지표로 할루시네이션에 대한 평가로 볼 수있다.\n",
    "    - **Answer relevancy(답변 적합성)**\n",
    "        - 생성된 답변과 사용자의 질문간의 관련성을 평가하는 지표\n",
    "        - 생성된 답변이 사용자의 질문과 얼마나 관련성이 있는지를 평가하는 지표.\n",
    "- **Retrieval**\n",
    "    -  질문에 대해 검색한 문서(context)들에 대한 평가\n",
    "    -  **Context Precision(문맥 정밀도)**\n",
    "        -  검색된 문서(context)들 중 질문과 관련 있는 것들이 **얼마나 상위 순위에 위치하는지** 평가하는 지표.\n",
    "    -  **Context Recall(문맥 재현률)**\n",
    "        -  검색된 문서(context)가 정답(ground-truth)의 정보를 얼마나 포함하고 있는지 평가하는 지표.\n",
    "- 이러한 지표들은 RAG 파이프라인의 성능을 다각도로 평가하는 데 활용된다.\n",
    "![RAGAS_score2](figures/RAGAS_score2.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 주요 평가지표\n",
    "### Generation 평가\n",
    "- LLM이 생성한 답변에 대한 평가\n",
    "  \n",
    "#### Faithfulness (신뢰성)\n",
    "- 생성된 답변이 얼마나 주어진 검색 문서들(context)를 잘 반영해서 생성되었는지 평가한다. 할루시네이션에 대한 평가라고 할 수 있다. \n",
    "- 점수범위: **0 ~ 1** (1에 가까울수록 좋음)\n",
    "- 답변에 포함된 모든 주장이 context에서 얼마나 추출 가능한지를 확인한다.\n",
    "\n",
    "##### 평가 방법\n",
    "1. Answer에서 주장 구문(claim statement)들을 생성(추출)한다. (주장이란, 질문(user input)과 관련된 내용)\n",
    "    - 예) \n",
    "        - **질문**: 한국의 수도는 어디이고 인구는 얼마나 되나요? \n",
    "        - **LLM 답변**: 한국의 수도는 서울이고 인구수는 3000만명이다. \n",
    "        - **주장(claim)**: \n",
    "            1. 한국의 수도는 서울이다.\n",
    "            2. 인구수는 3000만명이다.\n",
    "2. 각 주장들을 context로 부터 추론 가능한지 판단한다. 이를 바탕으로 faithfulness 점수를 계산한다.\n",
    "    - 예)\n",
    "        - context: 한국은 동아시아에 위치하고 있는 나라다. 한국의 수도는 서울이다. .... 한국의 인구는 5000만명이고 서울에 1000만이 살고 있다.\n",
    "        - 위 context에서 추론 가능한 주장: \n",
    "            - 한국의 수도는 서울이다. -> context에서 추론가능한 주장.\n",
    "            - 한국의 인구는 3000만명이다. -> context에서 추론 불가능한 주장.\n",
    "3. **Faithfulness score** 를 계산한다. 총 주장 수 중에서 context로 부터 추론가능한 주장의 개수.    \n",
    "    - 예)\n",
    "        - Faithfulness Score = $\\cfrac{1}{2} = 0.5$ (두 개의 주장 중 한 개의 주장만 context에서 유추할 수있다.)\n",
    "    - LLM 답변에서 주장을 추출 하는 것과 각 주장이 context에서 추론 가능한 지를 판단하는 것은 LLM 을 활용한다.\n",
    "- 공식\n",
    "    $$\n",
    "    \\text{Faithfulness Score}\\;=\\;\\cfrac{\\text{주어진\\;context\\;에서\\;추론할\\;수\\;있는\\;주장의\\;개수}}{\\text{총\\;주장\\;개수}}\n",
    "    $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Answer relevancy (답변 적합성)\n",
    "- 생성된 답변이 질문(user input)에 얼마나 잘 부합하는 지를 평가한다.\n",
    "- 점수 범위: -1~1 (1에 가까울수록 좋음)\n",
    "- LLM이 생성한 답변을 기반으로 질문들을 생성한다. 이렇게 생성한 질문들과 실제 질문(user input)의 embedding vector 간의 **코사인 유사도**를 측정한다.\n",
    "\n",
    "##### 평가방법\n",
    "1. LLM이 생성한 답변을 기반으로 질문들을 생성한다.\n",
    "    - 예) \n",
    "        - **LLM** 답변: 한국의 수도는 서울이고 인구수는 3000만명이다. \n",
    "        - **생성된 질문**: \n",
    "            1. 한국의 수도는 어디이고 인구는 얼마나 되나요?\n",
    "            2. 한국의 수도는 어디인가요?\n",
    "            3. 한국의 인구는 얼마나 되나요?\n",
    "2. 실제 질문과 생성한 질문간의 코사인 유사도를 측정한다. 그 평균이 최종 점수가 된다.\n",
    "    - 예)\n",
    "        - **실제 질문**: 한국의 수도는 어디이고 인구는 얼마나 되나요?\n",
    "        - **생성된 질문**: \n",
    "            1. 한국의 수도는 어디이고 인구는 얼마나 되나요?\n",
    "            2. 한국의 수도는 어디인가요?\n",
    "            3. 한국의 인구는 얼마나 되나요?\n",
    "- 공식\n",
    "  $$\n",
    "    \\cfrac{1}{N} \\sum_{i=1}^{N} \\text{cosine\\_similarity}(q_{\\text{user}_{_i}}, q_{\\text{generated}})\n",
    "  $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Retrieval 평가\n",
    "User input에 대해 Vector store에서 검색한 context에 대한 평가\n",
    "\n",
    "#### Context Precision\n",
    "- 검색된 문서(context)들 중 **질문과 관련 있는 것들이 얼마나 상위 순위**에 있는 지 평가.\n",
    "- 점수 범위: 0~1 (1에 가까울수록 좋음)\n",
    "\n",
    "\n",
    "##### 평가방법\n",
    "\n",
    "- 공식\n",
    "$$\n",
    " \\text{Context\\;Precision@K} = \\frac{\\sum_{k=1}^{K} \\left( \\text{Precision@k} \\times v_k \\right)}{\\ 상위\\;K개\\;결과에서의\\;관련\\;항목\\;수}\n",
    "$$\n",
    "$$\n",
    " \\text{Precision@k} = \\frac{\\text{True\\;positive@k}}{(\\text{True\\;positive@k} + \\text{False\\;positive@k})} \\\\\n",
    "$$\n",
    "- $\\text{Precision@k}$: 개별 문서에 대한 Precision\n",
    "- K: context 의 개수(chuck 수)\n",
    "- $v_k$: 질문과의 context간의 관련성 여부로 0 또는 1. (0: 관련 없음, 1: 관련 있음)\n",
    "\n",
    "##### 예시\n",
    "- 질문과 context 관련성 예\n",
    "    - 질문: 한국의 수도는 어디이고 인구는 얼마나 되나요?\n",
    "    - 높은 정밀도 context\n",
    "        - 한국의 수도는 서울이고 인구는 5000만명 입니다. \n",
    "        - 한국의 수도는 서울입니다.\n",
    "        - 한국은 동아시아에 위치해 있는 국가로 수도는 서울입니다.\n",
    "        - 한국의 인구는 5000만명 입니다.\n",
    "    - 낮은 정밀도 context\n",
    "        - 한국은 동아시아에 위치한 국가입니다.\n",
    "        - 한국의 K-pop은 전 세계적으로 유명합니다.\n",
    "        - 비빔밥, 불고기는 한국의 대표적인 음식입니다.\n",
    "    - **높은 정밀도의 context이 상위 순위에 위치했으면 높은 점수를 받는다.**\n",
    "- 상위 5개의 검색 결과 중 1번째, 3번째, 4번째 문서가 관련이 있다고 가정\n",
    "    ```bash\n",
    "    Precision@1 = 1/1 = 1.0    # True positive@1/(True positive@1 + False positive@1).  1/1(1번 문서 계산 시에는 1개 문서만 있으므로 분모가 1이 된다.)\n",
    "    Precision@2 = 1/2 = 0.5     \n",
    "    Precision@3 = 2/3 ≈ 0.67    \n",
    "    Precision@4 = 3/4 = 0.75\n",
    "    Precision@5 = 3/5 = 0.6\n",
    "    ```\n",
    "- vk의 값\n",
    "    - 1번째: $v_1 = 1$\n",
    "    - 2번째: $v_2 = 0$\n",
    "    - 3번째: $v_3 = 1$\n",
    "    - 4번째: $v_4 = 1$\n",
    "    - 5번째: $v_5 = 0$\n",
    "\n",
    "- Context Precision@5\n",
    "$$\n",
    "\\text{Context\\;Precision@5} = \\frac{(1.0 \\times 1) + (0.5 \\times 0) + (0.67 \\times 1) + (0.75 \\times 1) + (0.6 \\times 0)}{3} = \\frac{1.0 + 0 + 0.67 + 0.75 + 0}{3} ≈ 0.807\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Context Recall (문맥 재현률)\n",
    "- 검색된 문서(context)가 얼마나 정답(ground-truth)의 정보를 포함있는 지 평가하는 지표\n",
    "- 점수 범위: 0~1 (1에 가까울수록 좋음)\n",
    "- **정답(ground truth)의 각 주장(claim)이 검색된 context와 얼마나 일치**하는지 계산함.\n",
    "\n",
    "##### 평가방법\n",
    "1. **정답**에서 주장 문장(claim statement)들을 생성(추출)한다.\n",
    "    - 예) \n",
    "        - **정답**: 한국의 수도는 서울이고 인구수는 5000만명이다. \n",
    "        - **주장(claim)**: \n",
    "            1. 한국의 수도는 서울이다.\n",
    "            2. 인구수는 5000만명이다.\n",
    "2. 각 주장 문장(claim statement)의 정보를 검색된 context들에서 찾을 수 있는지 판별한다. 이를 바탕으로 context recall 점수를 계산한다.\n",
    "    - 예)\n",
    "        - context: 한국은 동아시아에 위치하고 있는 나라다. 한국의 수도는 서울이다.\n",
    "        - 위 context에서 추론 가능한 주장: \n",
    "            - 한국의 수도는 서울이다. -> context에서 찾을 수 있다.\n",
    "            - 한국의 인구는 5000만명이다. -> context에서 찾을 수 없다.\n",
    "3. **Context Recall Score** 를 계산한다. 총 주장 수 중에서 context로 부터 찾을 수 있는 주장의 개수.\n",
    "    - 예)\n",
    "        - Context Recall Score = $\\cfrac{1}{2} = 0.5$ (두 개의 주장 중 한 개의 주장만 context에서 찾을 수 있다.)\n",
    "\n",
    "- 공식\n",
    "    $$\n",
    "    \\text{Context Recall Score}\\;=\\;\\cfrac{\\text{GT의\\;주장\\;중\\;주어진\\;context\\;에서\\;찾을\\;수\\;있는\\;주장의\\;개수}}{\\text{GT의\\;총\\;주장\\;개수}}\n",
    "    $$ "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RAGAS 평가 실습"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI, OpenAIEmbeddings\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "model = ChatOpenAI(model=\"gpt-4o-mini\") #평가시 사용할 llm 모델은 성능 좋은 것을 써야 좀 더 정확한 평가가 가능.\n",
    "embedding_model = OpenAIEmbeddings(\n",
    "    model=\"text-embedding-3-small\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RAG Chain 구성\n",
    "- Vector Store 연결\n",
    "- Chain 응답 결과\n",
    "    - 평가를 위해 **Vector Store에서 검색한 context**들과 **LLM 응답**이 출력되도록 chain을 구성한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.document_loaders import TextLoader\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "from langchain_chroma import Chroma\n",
    "\n",
    "COLLECTION_NAME = \"olympic_info\"\n",
    "PERSIST_DIRECTORY = \"vector_store/olympic_info\"\n",
    "\n",
    "loader = TextLoader(\"data/olympic.txt\", encoding='utf-8')\n",
    "splitter = RecursiveCharacterTextSplitter.from_tiktoken_encoder(\n",
    "    model_name=\"gpt-4o-mini\",\n",
    "    chunk_size=500,\n",
    "    chunk_overlap=100\n",
    ")\n",
    "docs = loader.load_and_split(splitter)\n",
    "\n",
    "vector_store = Chroma.from_documents(\n",
    "    documents=docs,\n",
    "    embedding=embedding_model,\n",
    "    collection_name=COLLECTION_NAME,\n",
    "    persist_directory=PERSIST_DIRECTORY\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_chroma import Chroma\n",
    "# 연결\n",
    "COLLECTION_NAME = \"olympic_info\"\n",
    "PERSIST_DIRECTORY = \"vector_store/olympic_info\"\n",
    "\n",
    "vector_store = Chroma(\n",
    "    embedding_function=embedding_model,\n",
    "    collection_name=COLLECTION_NAME,\n",
    "    persist_directory=PERSIST_DIRECTORY\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "36"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vector_store._collection.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'홍길동'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from operator import itemgetter\n",
    "# 주어진 key/index의 값(원소)를 자료구조에서 추출해주는 함수.\n",
    "d = {\"name\":\"홍길동\", \"age\":30}\n",
    "i_getter = itemgetter(\"name\")  # name key의 value를 추출\n",
    "i_getter(d)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RAG 체인 구성\n",
    "# query -> pt -> llm -> 응답 (query에 같이 입력된 context, 답변 => 2가지를 출력)\n",
    "from langchain import hub\n",
    "from langchain_core.runnables import RunnablePassthrough, RunnableLambda\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.documents import Document\n",
    "from operator import itemgetter\n",
    "\n",
    "# prompt template. langchain hub에 등록된 것을 가져와서 사용.\n",
    "prompt_template = hub.pull(\"rlm/rag-prompt\")\n",
    "# prompt_template\n",
    "\n",
    "# Retriever 생성\n",
    "retriever = vector_store.as_retriever()\n",
    "\n",
    "\n",
    "def format_docs(src_docs:dict[str, list[Document]]) -> str:\n",
    "    \"\"\"list[Document]: Vector Store에서 검색한 context들에서 \n",
    "    page_content만 추출해서 하나의 문자열로 합쳐서 반환\"\"\"\n",
    "    docs = src_docs['context']\n",
    "    return \"\\n\\n\".join([doc.page_content for doc in docs])\n",
    "\n",
    "def str_from_documents(docs: list[Document]) -> list[str]:\n",
    "    \"\"\"list[Document]에서 page_content 값들만 추출한 list를 반환.\"\"\"\n",
    "    return [doc.page_content for doc in docs]\n",
    "\n",
    "rag_chain = (\n",
    "    RunnablePassthrough() # rag chain을 RunnableSequence로 만들기 위해 Runnable인 것으로 시작.\n",
    "    | {\n",
    "        \"context\": retriever, \"question\":RunnablePassthrough()\n",
    "    } # retriver -> {\"context\":list[Document], \"question\":\"user input\"}\n",
    "    | {\n",
    "        # 앞에서 넘어온 dictionary에서 context(List[Document])를 추출 -> page_content값들을 list로 반환. list[str]\n",
    "        \"source_context\" : itemgetter(\"context\") | RunnableLambda(str_from_documents), \n",
    "        \"llm_answer\": {\n",
    "            # {\"context\":list[Document]} -> str(page_content들만 모은 string)\n",
    "            \"context\": RunnableLambda(format_docs), \"question\":itemgetter(\"question\")\n",
    "        } | prompt_template | model | StrOutputParser()  # LLM 응답 처리 chain. \n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_input = \"국제 올림픽 위원회에 대해서 설명해 주세요.\"\n",
    "response = rag_chain.invoke(user_input)\n",
    "# response: dictionary - {source_context:VectorStore에 조회한 context들, llm_answer:LLM 답변변}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'dict'>\n",
      "dict_keys(['source_context', 'llm_answer'])\n",
      "답변: 국제 올림픽 위원회(IOC)는 올림픽 활동을 총괄하는 기구로, 올림픽 개최 도시 선정, 종목 변경, 스폰서 계약 등을 관리합니다. IOC는 국제경기연맹(IF), 국가 올림픽 위원회(NOC), 올림픽 조직 위원회(OCOG)로 구성되며, 올림픽의 공식언어는 프랑스어와 영어 및 개최국의 공용어입니다. IOC는 변화하는 사회 환경에 적응하며 올림픽의 상업화와 다양성을 증진시키기 위해 노력하고 있습니다.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['국제 올림픽 위원회\\n올림픽 활동이란 많은 수의 국가, 국제 경기 연맹과 협회 • 미디어 파트너를 맺기 • 선수, 직원, 심판, 모든 사람과 기관이 올림픽 헌장을 지키는 것을 말한다. 국제올림픽위원회(IOC)는 모든 올림픽 활동을 통솔하는 단체로서, 올림픽 개최 도시 선정, 계획 감독, 종목 변경, 스폰서 및 방송권 계약 체결 등의 권리가 있다. 올림픽 활동은 크게 세 가지로 구성된다.\\n- 국제경기연맹(IF)은 국제적인 규모의 경기를 관리, 감독하는 기구이다. 예를 들어서 국제 축구 연맹(FIFA)는 축구를 주관하며, 국제 배구 연맹(FIVB)은 배구를 주관하는 기구이다. 올림픽에는 현재 35개의 국제경기연맹이 있고 각 종목을 대표한다. (이 중에는 올림픽 종목은 아니지만 IOC의 승인을 받은 연맹도 있다.)\\n- 국가 올림픽 위원회(NOC)는 각국의 올림픽 활동을 감독하는 기구이다. 예를 들어서 대한 올림픽 위원회(KOC)는 대한민국의 국가 올림픽 위원회이다. 현재 IOC에 소속된 국가 올림픽 위원회는 205개이다.\\n- 올림픽 조직 위원회(OCOG)는 임시적인 조직으로 올림픽의 총체적인 것(개막식, 페막식 등)을 책임지기 위해 구성된 조직이다. 올림픽 조직 위원회는 올림픽이 끝나면 해산되며 최종보고서를 IOC에 제출한다.\\n올림픽의 공식언어는 프랑스어와 영어와 개최국의 공용어이다. 모든 선언(예를 들어서 개막식 때 각국 소개를 할 때)들은 세 언어가 모두 나오거나 영어나 프랑스어 중에서 한 언어로만 말하기도 한다. 개최국의 공용어가 영어나 프랑스어가 아닐 때는 당연히 그 나라의 공용어도 함께 나온다.',\n",
       " '또한 20세기에 올림픽 운동이 발전함에 따라, IOC는 변화하는 세계의 사회 환경에 적응해야 했다. 이러한 변화의 예로는 얼음과 눈을 이용한 경기 종목을 다루는 동계 올림픽, 장애인이 참여하는 패럴림픽, 스페셜 올림픽, 데플림픽, 10대 선수들이 참여하는 유스 올림픽 등을 들 수 있다. 그 뿐만 아니라 IOC는 20세기의 변화하는 경제, 정치, 기술 환경에도 적응해야 했다. 그리하여 올림픽은 피에르 드 쿠베르탱이 기대했던 순수한 아마추어 정신에서 벗어나서, 프로 선수도 참가할 수 있게 되었다. 올림픽은 점차 대중 매체의 중요성이 커짐에 따라 올림픽의 상업화와 기업 후원을 놓고도 논란이 생겨났다. 또한 올림픽을 치르며 발생한 보이콧, 도핑, 심판 매수, 테러와 같은 수많은 일들은 올림픽이 더욱 굳건히 성장할 수 있는 원동력이 되었다.\\n올림픽은 국제경기연맹(IF), 국가 올림픽 위원회(NOC), 각 올림픽의 위원회(예-벤쿠버동계올림픽조직위원회)로 구성된다. 의사 결정 기구인 IOC는 올림픽 개최 도시를 선정하며, 각 올림픽 대회마다 열리는 올림픽 종목도 IOC에서 결정한다. 올림픽 경기 개최 도시는 경기 축하 의식이 올림픽 헌장에 부합하도록 조직하고 기금을 마련해야 한다. 올림픽 축하 행사로는 여러 의식과 상징을 들 수 있는데 올림픽기나 성화가 그 예이다.',\n",
       " '오늘날의 올림픽\\n1896년 대회때는 14개국에서 241명의 선수단이 참가했지만 2008년 하계 올림픽때는 204개국에서 10,500명의 선수가 참가하는 등 세계적인 대회로 변모했다. 동계 올림픽의 규모는 하계 올림픽 규모보다 작다. 예를 들면 2006 토리노 동계 대회때는 80개국에서 2,508명의 선수가 참가했으며 82개 세부종목이 있었고, 2008 베이징 하계 대회때는 204개국, 11,508명의 선수, 302개의 세부종목이 있었다. 올림픽이 진행되는 동안 선수와 임직원들은 올림픽 선수촌에서 지낸다. 올림픽 선수촌에는 선수들을 위한 개인실이 있으며 카페테리아, 헬스 클리닉, 종교적인 시설 등 최상의 편의를 위한 시설들이 있다.\\n올림픽에 참가하는 나라는 UN에 등록된 국가의 수 193개보다 많다. 다른 국제조직이 개최하는 대회들은 정치적 주권국으로 참가를 제한하는 반면, IOC는 그에 상관없이 올림픽에 모든 공동체들이 참가할 수 있도록 한다. 이는 연합체나 공동체에서 국가올림픽위원회(NOC)를 만드는 것을 허용한다는 의미이다. 예를 들면 푸에르토리코, 버뮤다, 홍콩과 같은 곳도 올림픽에서 다른 나라와 스포츠 경쟁을 합법적으로 할 수 있다.',\n",
       " \"2004년 10월과 11월에 IOC는 '올림픽 프로그램 위원회'(Olympic Programme Commission)를 설립했다. 여기서는 올림픽 종목과 올림픽 종목이 아닌 스포츠를 모두 재검토하는 일을 한다. 이 위원회의 목표는 올림픽 종목에 더 체계적으로 다가가는 것이다. 위원회에서는 우선적으로 올림픽 종목으로 포함되기 위해서는 7개의 기준을 충족시켜야 한다고 말한다. 이 7개의 기준은 역사, 전통, 보편성, 인기도와 잠재성, 선수의 건강, 연맹의 스포츠를 관리할만한 능력, 스포츠를 여는 데에 필요한 비용이다. 예를 들면 2012년 하계 올림픽의 정식종목 후보에 7개 조건을 포함한 비(非)올림픽 스포츠가 올랐고 그 내용은, 골프, 가라테, 럭비, 인라인 스케이팅, 스쿼시였다. 이 스포츠들은 IOC 상임이사회에서 재검토되어 2005년 7월에 열린 싱가포르 총회에서 최종 결정하기로 했다. 결국 5개 중 2개(가라테와 스쿼시) 가 최종 후보로 올라왔으나 가라테와 스쿼시 둘 다 2/3의 미만의 찬성표로 정식종목이 되지는 못한다. 그 후 2016년 올림픽 정식종목에는 7개의 스포츠가 정식종목 신청을 했는데, 내용은 가라테, 골프, 스쿼시, 야구, 소프트볼, 7인제 럭비, 인라인 스케이팅이었다. 2009년 8월 13일, 신청된 7개의 스포츠 중 단 2개만 최종후보로 선정되었는데, 이는 7인제 럭비와 골프였다. 같은해인 2009년 10월에 열린 IOC 총회에서 골프와 럭비는 과반수 이상의 득표를 얻어서 2016년 하계 올림픽과 2020년 하계 올림픽의 정식종목으로 채택되었다.\"]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(type(response))\n",
    "print(response.keys())\n",
    "print(\"답변:\", response['llm_answer'])\n",
    "response['source_context']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 평가"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "국제 올림픽 위원회에 대해 설명해주세요.\n",
      "국제 올림픽 위원회(IOC)는 올림픽 활동을 총괄하는 기구로, 올림픽 개최 도시 선정, 종목 변경, 스폰서 계약 등을 관리합니다. IOC는 국제경기연맹(IF), 국가 올림픽 위원회(NOC), 올림픽 조직 위원회(OCOG)로 구성되며, 올림픽의 공식언어는 프랑스어와 영어 및 개최국의 공용어입니다. IOC는 변화하는 사회 환경에 적응하며 올림픽의 상업화와 다양성을 증진시키기 위해 노력하고 있습니다.\n",
      "['국제 올림픽 위원회\\n올림픽 활동이란 많은 수의 국가, 국제 경기 연맹과 협회 • 미디어 파트너를 맺기 • 선수, 직원, 심판, 모든 사람과 기관이 올림픽 헌장을 지키는 것을 말한다. 국제올림픽위원회(IOC)는 모든 올림픽 활동을 통솔하는 단체로서, 올림픽 개최 도시 선정, 계획 감독, 종목 변경, 스폰서 및 방송권 계약 체결 등의 권리가 있다. 올림픽 활동은 크게 세 가지로 구성된다.\\n- 국제경기연맹(IF)은 국제적인 규모의 경기를 관리, 감독하는 기구이다. 예를 들어서 국제 축구 연맹(FIFA)는 축구를 주관하며, 국제 배구 연맹(FIVB)은 배구를 주관하는 기구이다. 올림픽에는 현재 35개의 국제경기연맹이 있고 각 종목을 대표한다. (이 중에는 올림픽 종목은 아니지만 IOC의 승인을 받은 연맹도 있다.)\\n- 국가 올림픽 위원회(NOC)는 각국의 올림픽 활동을 감독하는 기구이다. 예를 들어서 대한 올림픽 위원회(KOC)는 대한민국의 국가 올림픽 위원회이다. 현재 IOC에 소속된 국가 올림픽 위원회는 205개이다.\\n- 올림픽 조직 위원회(OCOG)는 임시적인 조직으로 올림픽의 총체적인 것(개막식, 페막식 등)을 책임지기 위해 구성된 조직이다. 올림픽 조직 위원회는 올림픽이 끝나면 해산되며 최종보고서를 IOC에 제출한다.\\n올림픽의 공식언어는 프랑스어와 영어와 개최국의 공용어이다. 모든 선언(예를 들어서 개막식 때 각국 소개를 할 때)들은 세 언어가 모두 나오거나 영어나 프랑스어 중에서 한 언어로만 말하기도 한다. 개최국의 공용어가 영어나 프랑스어가 아닐 때는 당연히 그 나라의 공용어도 함께 나온다.', '또한 20세기에 올림픽 운동이 발전함에 따라, IOC는 변화하는 세계의 사회 환경에 적응해야 했다. 이러한 변화의 예로는 얼음과 눈을 이용한 경기 종목을 다루는 동계 올림픽, 장애인이 참여하는 패럴림픽, 스페셜 올림픽, 데플림픽, 10대 선수들이 참여하는 유스 올림픽 등을 들 수 있다. 그 뿐만 아니라 IOC는 20세기의 변화하는 경제, 정치, 기술 환경에도 적응해야 했다. 그리하여 올림픽은 피에르 드 쿠베르탱이 기대했던 순수한 아마추어 정신에서 벗어나서, 프로 선수도 참가할 수 있게 되었다. 올림픽은 점차 대중 매체의 중요성이 커짐에 따라 올림픽의 상업화와 기업 후원을 놓고도 논란이 생겨났다. 또한 올림픽을 치르며 발생한 보이콧, 도핑, 심판 매수, 테러와 같은 수많은 일들은 올림픽이 더욱 굳건히 성장할 수 있는 원동력이 되었다.\\n올림픽은 국제경기연맹(IF), 국가 올림픽 위원회(NOC), 각 올림픽의 위원회(예-벤쿠버동계올림픽조직위원회)로 구성된다. 의사 결정 기구인 IOC는 올림픽 개최 도시를 선정하며, 각 올림픽 대회마다 열리는 올림픽 종목도 IOC에서 결정한다. 올림픽 경기 개최 도시는 경기 축하 의식이 올림픽 헌장에 부합하도록 조직하고 기금을 마련해야 한다. 올림픽 축하 행사로는 여러 의식과 상징을 들 수 있는데 올림픽기나 성화가 그 예이다.', '오늘날의 올림픽\\n1896년 대회때는 14개국에서 241명의 선수단이 참가했지만 2008년 하계 올림픽때는 204개국에서 10,500명의 선수가 참가하는 등 세계적인 대회로 변모했다. 동계 올림픽의 규모는 하계 올림픽 규모보다 작다. 예를 들면 2006 토리노 동계 대회때는 80개국에서 2,508명의 선수가 참가했으며 82개 세부종목이 있었고, 2008 베이징 하계 대회때는 204개국, 11,508명의 선수, 302개의 세부종목이 있었다. 올림픽이 진행되는 동안 선수와 임직원들은 올림픽 선수촌에서 지낸다. 올림픽 선수촌에는 선수들을 위한 개인실이 있으며 카페테리아, 헬스 클리닉, 종교적인 시설 등 최상의 편의를 위한 시설들이 있다.\\n올림픽에 참가하는 나라는 UN에 등록된 국가의 수 193개보다 많다. 다른 국제조직이 개최하는 대회들은 정치적 주권국으로 참가를 제한하는 반면, IOC는 그에 상관없이 올림픽에 모든 공동체들이 참가할 수 있도록 한다. 이는 연합체나 공동체에서 국가올림픽위원회(NOC)를 만드는 것을 허용한다는 의미이다. 예를 들면 푸에르토리코, 버뮤다, 홍콩과 같은 곳도 올림픽에서 다른 나라와 스포츠 경쟁을 합법적으로 할 수 있다.', \"2004년 10월과 11월에 IOC는 '올림픽 프로그램 위원회'(Olympic Programme Commission)를 설립했다. 여기서는 올림픽 종목과 올림픽 종목이 아닌 스포츠를 모두 재검토하는 일을 한다. 이 위원회의 목표는 올림픽 종목에 더 체계적으로 다가가는 것이다. 위원회에서는 우선적으로 올림픽 종목으로 포함되기 위해서는 7개의 기준을 충족시켜야 한다고 말한다. 이 7개의 기준은 역사, 전통, 보편성, 인기도와 잠재성, 선수의 건강, 연맹의 스포츠를 관리할만한 능력, 스포츠를 여는 데에 필요한 비용이다. 예를 들면 2012년 하계 올림픽의 정식종목 후보에 7개 조건을 포함한 비(非)올림픽 스포츠가 올랐고 그 내용은, 골프, 가라테, 럭비, 인라인 스케이팅, 스쿼시였다. 이 스포츠들은 IOC 상임이사회에서 재검토되어 2005년 7월에 열린 싱가포르 총회에서 최종 결정하기로 했다. 결국 5개 중 2개(가라테와 스쿼시) 가 최종 후보로 올라왔으나 가라테와 스쿼시 둘 다 2/3의 미만의 찬성표로 정식종목이 되지는 못한다. 그 후 2016년 올림픽 정식종목에는 7개의 스포츠가 정식종목 신청을 했는데, 내용은 가라테, 골프, 스쿼시, 야구, 소프트볼, 7인제 럭비, 인라인 스케이팅이었다. 2009년 8월 13일, 신청된 7개의 스포츠 중 단 2개만 최종후보로 선정되었는데, 이는 7인제 럭비와 골프였다. 같은해인 2009년 10월에 열린 IOC 총회에서 골프와 럭비는 과반수 이상의 득표를 얻어서 2016년 하계 올림픽과 2020년 하계 올림픽의 정식종목으로 채택되었다.\"]\n",
      "국제 올림픽 위원회(IOC)는 올림픽 활동을 총괄하는 기구로, 올림픽 개최 도시 선정, 종목 변경, 스폰서 계약 등을 관리합니다.\n"
     ]
    }
   ],
   "source": [
    "user_input = \"국제 올림픽 위원회에 대해 설명해주세요.\"\n",
    "answer = response['llm_answer']\n",
    "context_list = response['source_context']\n",
    "ground_truth = \"국제 올림픽 위원회(IOC)는 올림픽 활동을 총괄하는 기구로, 올림픽 개최 도시 선정, 종목 변경, 스폰서 계약 등을 관리합니다.\"\n",
    "print(user_input) # 질문\n",
    "print(answer)     # llm 모델 답변\n",
    "print(context_list) # vector store에서 조회한 context들.\n",
    "print(ground_truth) # 정답"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'ragas.dataset_schema.EvaluationDataset'>\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "EvaluationDataset(features=['user_input', 'retrieved_contexts', 'response', 'reference'], len=1)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from ragas import SingleTurnSample, EvaluationDataset\n",
    "# 평가 데이터셋을 구성.\n",
    "\n",
    "## 개별 평가 데이터\n",
    "sample = SingleTurnSample(\n",
    "    user_input=user_input,           # 사용자 입력-질문\n",
    "    retrieved_contexts=context_list, # 질문에 대해서 Vector Store에서 조회한 context들.\n",
    "    response=answer,                 # LLM 답변 (정답 추정값)\n",
    "    reference=ground_truth           # 정답 답변\n",
    ")\n",
    "\n",
    "# 평가 데이터셋을 구성\n",
    "eval_dataset = EvaluationDataset(samples=[sample])\n",
    "print(type(eval_dataset))\n",
    "eval_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SingleTurnSample(user_input='국제 올림픽 위원회에 대해 설명해주세요.', retrieved_contexts=['국제 올림픽 위원회\\n올림픽 활동이란 많은 수의 국가, 국제 경기 연맹과 협회 • 미디어 파트너를 맺기 • 선수, 직원, 심판, 모든 사람과 기관이 올림픽 헌장을 지키는 것을 말한다. 국제올림픽위원회(IOC)는 모든 올림픽 활동을 통솔하는 단체로서, 올림픽 개최 도시 선정, 계획 감독, 종목 변경, 스폰서 및 방송권 계약 체결 등의 권리가 있다. 올림픽 활동은 크게 세 가지로 구성된다.\\n- 국제경기연맹(IF)은 국제적인 규모의 경기를 관리, 감독하는 기구이다. 예를 들어서 국제 축구 연맹(FIFA)는 축구를 주관하며, 국제 배구 연맹(FIVB)은 배구를 주관하는 기구이다. 올림픽에는 현재 35개의 국제경기연맹이 있고 각 종목을 대표한다. (이 중에는 올림픽 종목은 아니지만 IOC의 승인을 받은 연맹도 있다.)\\n- 국가 올림픽 위원회(NOC)는 각국의 올림픽 활동을 감독하는 기구이다. 예를 들어서 대한 올림픽 위원회(KOC)는 대한민국의 국가 올림픽 위원회이다. 현재 IOC에 소속된 국가 올림픽 위원회는 205개이다.\\n- 올림픽 조직 위원회(OCOG)는 임시적인 조직으로 올림픽의 총체적인 것(개막식, 페막식 등)을 책임지기 위해 구성된 조직이다. 올림픽 조직 위원회는 올림픽이 끝나면 해산되며 최종보고서를 IOC에 제출한다.\\n올림픽의 공식언어는 프랑스어와 영어와 개최국의 공용어이다. 모든 선언(예를 들어서 개막식 때 각국 소개를 할 때)들은 세 언어가 모두 나오거나 영어나 프랑스어 중에서 한 언어로만 말하기도 한다. 개최국의 공용어가 영어나 프랑스어가 아닐 때는 당연히 그 나라의 공용어도 함께 나온다.', '또한 20세기에 올림픽 운동이 발전함에 따라, IOC는 변화하는 세계의 사회 환경에 적응해야 했다. 이러한 변화의 예로는 얼음과 눈을 이용한 경기 종목을 다루는 동계 올림픽, 장애인이 참여하는 패럴림픽, 스페셜 올림픽, 데플림픽, 10대 선수들이 참여하는 유스 올림픽 등을 들 수 있다. 그 뿐만 아니라 IOC는 20세기의 변화하는 경제, 정치, 기술 환경에도 적응해야 했다. 그리하여 올림픽은 피에르 드 쿠베르탱이 기대했던 순수한 아마추어 정신에서 벗어나서, 프로 선수도 참가할 수 있게 되었다. 올림픽은 점차 대중 매체의 중요성이 커짐에 따라 올림픽의 상업화와 기업 후원을 놓고도 논란이 생겨났다. 또한 올림픽을 치르며 발생한 보이콧, 도핑, 심판 매수, 테러와 같은 수많은 일들은 올림픽이 더욱 굳건히 성장할 수 있는 원동력이 되었다.\\n올림픽은 국제경기연맹(IF), 국가 올림픽 위원회(NOC), 각 올림픽의 위원회(예-벤쿠버동계올림픽조직위원회)로 구성된다. 의사 결정 기구인 IOC는 올림픽 개최 도시를 선정하며, 각 올림픽 대회마다 열리는 올림픽 종목도 IOC에서 결정한다. 올림픽 경기 개최 도시는 경기 축하 의식이 올림픽 헌장에 부합하도록 조직하고 기금을 마련해야 한다. 올림픽 축하 행사로는 여러 의식과 상징을 들 수 있는데 올림픽기나 성화가 그 예이다.', '오늘날의 올림픽\\n1896년 대회때는 14개국에서 241명의 선수단이 참가했지만 2008년 하계 올림픽때는 204개국에서 10,500명의 선수가 참가하는 등 세계적인 대회로 변모했다. 동계 올림픽의 규모는 하계 올림픽 규모보다 작다. 예를 들면 2006 토리노 동계 대회때는 80개국에서 2,508명의 선수가 참가했으며 82개 세부종목이 있었고, 2008 베이징 하계 대회때는 204개국, 11,508명의 선수, 302개의 세부종목이 있었다. 올림픽이 진행되는 동안 선수와 임직원들은 올림픽 선수촌에서 지낸다. 올림픽 선수촌에는 선수들을 위한 개인실이 있으며 카페테리아, 헬스 클리닉, 종교적인 시설 등 최상의 편의를 위한 시설들이 있다.\\n올림픽에 참가하는 나라는 UN에 등록된 국가의 수 193개보다 많다. 다른 국제조직이 개최하는 대회들은 정치적 주권국으로 참가를 제한하는 반면, IOC는 그에 상관없이 올림픽에 모든 공동체들이 참가할 수 있도록 한다. 이는 연합체나 공동체에서 국가올림픽위원회(NOC)를 만드는 것을 허용한다는 의미이다. 예를 들면 푸에르토리코, 버뮤다, 홍콩과 같은 곳도 올림픽에서 다른 나라와 스포츠 경쟁을 합법적으로 할 수 있다.', \"2004년 10월과 11월에 IOC는 '올림픽 프로그램 위원회'(Olympic Programme Commission)를 설립했다. 여기서는 올림픽 종목과 올림픽 종목이 아닌 스포츠를 모두 재검토하는 일을 한다. 이 위원회의 목표는 올림픽 종목에 더 체계적으로 다가가는 것이다. 위원회에서는 우선적으로 올림픽 종목으로 포함되기 위해서는 7개의 기준을 충족시켜야 한다고 말한다. 이 7개의 기준은 역사, 전통, 보편성, 인기도와 잠재성, 선수의 건강, 연맹의 스포츠를 관리할만한 능력, 스포츠를 여는 데에 필요한 비용이다. 예를 들면 2012년 하계 올림픽의 정식종목 후보에 7개 조건을 포함한 비(非)올림픽 스포츠가 올랐고 그 내용은, 골프, 가라테, 럭비, 인라인 스케이팅, 스쿼시였다. 이 스포츠들은 IOC 상임이사회에서 재검토되어 2005년 7월에 열린 싱가포르 총회에서 최종 결정하기로 했다. 결국 5개 중 2개(가라테와 스쿼시) 가 최종 후보로 올라왔으나 가라테와 스쿼시 둘 다 2/3의 미만의 찬성표로 정식종목이 되지는 못한다. 그 후 2016년 올림픽 정식종목에는 7개의 스포츠가 정식종목 신청을 했는데, 내용은 가라테, 골프, 스쿼시, 야구, 소프트볼, 7인제 럭비, 인라인 스케이팅이었다. 2009년 8월 13일, 신청된 7개의 스포츠 중 단 2개만 최종후보로 선정되었는데, 이는 7인제 럭비와 골프였다. 같은해인 2009년 10월에 열린 IOC 총회에서 골프와 럭비는 과반수 이상의 득표를 얻어서 2016년 하계 올림픽과 2020년 하계 올림픽의 정식종목으로 채택되었다.\"], reference_contexts=None, response='국제 올림픽 위원회(IOC)는 올림픽 활동을 총괄하는 기구로, 올림픽 개최 도시 선정, 종목 변경, 스폰서 계약 등을 관리합니다. IOC는 국제경기연맹(IF), 국가 올림픽 위원회(NOC), 올림픽 조직 위원회(OCOG)로 구성되며, 올림픽의 공식언어는 프랑스어와 영어 및 개최국의 공용어입니다. IOC는 변화하는 사회 환경에 적응하며 올림픽의 상업화와 다양성을 증진시키기 위해 노력하고 있습니다.', multi_responses=None, reference='국제 올림픽 위원회(IOC)는 올림픽 활동을 총괄하는 기구로, 올림픽 개최 도시 선정, 종목 변경, 스폰서 계약 등을 관리합니다.', rubrics=None)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eval_dataset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_input</th>\n",
       "      <th>retrieved_contexts</th>\n",
       "      <th>response</th>\n",
       "      <th>reference</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>국제 올림픽 위원회에 대해 설명해주세요.</td>\n",
       "      <td>[국제 올림픽 위원회\\n올림픽 활동이란 많은 수의 국가, 국제 경기 연맹과 협회 •...</td>\n",
       "      <td>국제 올림픽 위원회(IOC)는 올림픽 활동을 총괄하는 기구로, 올림픽 개최 도시 선...</td>\n",
       "      <td>국제 올림픽 위원회(IOC)는 올림픽 활동을 총괄하는 기구로, 올림픽 개최 도시 선...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               user_input                                 retrieved_contexts  \\\n",
       "0  국제 올림픽 위원회에 대해 설명해주세요.  [국제 올림픽 위원회\\n올림픽 활동이란 많은 수의 국가, 국제 경기 연맹과 협회 •...   \n",
       "\n",
       "                                            response  \\\n",
       "0  국제 올림픽 위원회(IOC)는 올림픽 활동을 총괄하는 기구로, 올림픽 개최 도시 선...   \n",
       "\n",
       "                                           reference  \n",
       "0  국제 올림픽 위원회(IOC)는 올림픽 활동을 총괄하는 기구로, 올림픽 개최 도시 선...  "
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Dataset을 Pandas DataFrame으로 변환\n",
    "eval_df = eval_dataset.to_pandas()\n",
    "eval_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 평가\n",
    "\n",
    "from ragas.metrics import (\n",
    "    LLMContextRecall, Faithfulness, LLMContextPrecisionWithReference, AnswerRelevancy\n",
    ")\n",
    "from ragas.llms import LangchainLLMWrapper\n",
    "from ragas.embeddings import LangchainEmbeddingsWrapper\n",
    "from ragas import evaluate\n",
    "\n",
    "from langchain_openai import ChatOpenAI, OpenAIEmbeddings\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "model = ChatOpenAI(model=\"gpt-4o\") # 평가시 사용할 llm 모델.\n",
    "eval_llm = LangchainLLMWrapper(model) # Langchain 모델을 ragas에서 사용할 수있도록 변환.\n",
    "\n",
    "embedding_model = OpenAIEmbeddings(model=\"text-embedding-3-small\")\n",
    "eval_embedding = LangchainEmbeddingsWrapper(embedding_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "088dc24d30c945d5b5e4d79463e9b3e4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#평가 지표들을 List로 묶는다.\n",
    "metrics = [\n",
    "    LLMContextRecall(llm=eval_llm),\n",
    "    LLMContextPrecisionWithReference(llm=eval_llm),\n",
    "    Faithfulness(llm=eval_llm),\n",
    "    AnswerRelevancy(llm=eval_llm, embeddings=eval_embedding)\n",
    "]\n",
    "result = evaluate(dataset=eval_dataset, metrics=metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'context_recall': 1.0000, 'llm_context_precision_with_reference': 1.0000, 'faithfulness': 0.5385, 'answer_relevancy': 0.4782}"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(result)\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# context_recall: context와 ground-truth 간의 관련성\n",
    "# llm_context_precision_with_reference: context와 user input(사용자 질문)과의 관련성성\n",
    "# faithfulness: 모델이 출력한 정답예측과 context간의 관련성.\n",
    "# answer_relevancy: 모델이 출력한 정답예측과 사용자 질문간의 관계"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_input</th>\n",
       "      <th>retrieved_contexts</th>\n",
       "      <th>response</th>\n",
       "      <th>reference</th>\n",
       "      <th>context_recall</th>\n",
       "      <th>llm_context_precision_with_reference</th>\n",
       "      <th>faithfulness</th>\n",
       "      <th>answer_relevancy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>국제 올림픽 위원회에 대해 설명해주세요.</td>\n",
       "      <td>[국제 올림픽 위원회\\n올림픽 활동이란 많은 수의 국가, 국제 경기 연맹과 협회 •...</td>\n",
       "      <td>국제 올림픽 위원회(IOC)는 올림픽 활동을 총괄하는 기구로, 올림픽 개최 도시 선...</td>\n",
       "      <td>국제 올림픽 위원회(IOC)는 올림픽 활동을 총괄하는 기구로, 올림픽 개최 도시 선...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.538462</td>\n",
       "      <td>0.478239</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               user_input                                 retrieved_contexts  \\\n",
       "0  국제 올림픽 위원회에 대해 설명해주세요.  [국제 올림픽 위원회\\n올림픽 활동이란 많은 수의 국가, 국제 경기 연맹과 협회 •...   \n",
       "\n",
       "                                            response  \\\n",
       "0  국제 올림픽 위원회(IOC)는 올림픽 활동을 총괄하는 기구로, 올림픽 개최 도시 선...   \n",
       "\n",
       "                                           reference  context_recall  \\\n",
       "0  국제 올림픽 위원회(IOC)는 올림픽 활동을 총괄하는 기구로, 올림픽 개최 도시 선...             1.0   \n",
       "\n",
       "   llm_context_precision_with_reference  faithfulness  answer_relevancy  \n",
       "0                                   1.0      0.538462          0.478239  "
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result.to_pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 평가 데이터 셋 만들기\n",
    "\n",
    "1. 문서를 Loading하고 split하여 Context 들을 만든다.\n",
    "2. Context들 중 평가에 사용할 것을 Random하게 선택한다.\n",
    "3. 선택된 context를 기반으로 LLM 모델을 이용해서 질문과 답변을 생성한다. \n",
    "4. 생성된 질문과 답변을 검토하여 품질을 높인다. \n",
    "   - 질문과 답변 자체가 맞는지 검사한다.\n",
    "   - 나올만한 질문인 지 확인한다.\n",
    "\n",
    "- **생성된 질문-답변의 질이 낮으면 좋은 평가를 할 수 없다.**\n",
    "    - 질문-답변 생성시 사용하는 LLM 모델은 성능이 좋은 것을 사용해야 한다. \n",
    "    - 생성된 질문-답변을 사람이 검토해서 품질을 더 높여야 한다.\n",
    "\n",
    "## 데이터셋에 포함될 내용\n",
    "- Dataset을 생성할 때는 다음 항목이 들어가야 한다.\n",
    "    -  user_input: 질문. `string`\n",
    "    -  reference : 정답. `string`\n",
    "    -  retrieved_contexts : context. `list(string)`\n",
    "-  평가할 때 추가할 것\n",
    "    - response: LLM 모델이 생성한 답변. `string`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36\n"
     ]
    }
   ],
   "source": [
    "from langchain_community.document_loaders import TextLoader\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "\n",
    "loader = TextLoader(\"data/olympic.txt\", encoding='utf-8')\n",
    "splitter = RecursiveCharacterTextSplitter.from_tiktoken_encoder(\n",
    "    model_name=\"gpt-4o-mini\",\n",
    "    chunk_size=500,\n",
    "    chunk_overlap=100\n",
    ")\n",
    "docs = loader.load_and_split(splitter)\n",
    "print(len(docs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[14, 28, 9, 2, 10]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import random\n",
    "l = list(range(36))\n",
    "random.shuffle(l)\n",
    "l[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 평가 데이터로 사용할 context k개를 랜덤하게 추출\n",
    "import random\n",
    "total_samples = 5 # 추출할 샘플 개수\n",
    "eval_context_list = [] # Sample들을 담을 리스트\n",
    "while len(eval_context_list) < 5:\n",
    "    _context = docs[random.randint(0, len(docs)-1)].page_content\n",
    "    if len(_context) < 100: # 글자수 너무 적으면 질문을 생성 못하기 때문에 글자수 체크.\n",
    "        continue\n",
    "    eval_context_list.append(_context)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(eval_context_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Chain을 이용해서 LLM에게 질문-답 생성을 요청.\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain_core.output_parsers import JsonOutputParser\n",
    "from pydantic import BaseModel, Field\n",
    "from textwrap import dedent\n",
    "\n",
    "# JSONOutputParser에서 사용할 스키마 생성.\n",
    "class EvalDatasetSchema(BaseModel):\n",
    "    user_input:str = Field(..., description=\"질문(Question)\")\n",
    "    retrieved_contexts:list[str] = Field(..., description=\"LLM이 답변할 때 참조할 context\")\n",
    "    reference: str = Field(..., description=\"정답(ground truth)\")\n",
    "\n",
    "parser = JsonOutputParser(pydantic_object=EvalDatasetSchema)\n",
    "# print(parser.get_format_instructions())\n",
    "\n",
    "prompt_template = PromptTemplate.from_template(\n",
    "    template=dedent(\"\"\"\n",
    "        당신은 RAG 평가를 위해 질문과 정답 쌍을 생성하는 인공지능 비서입니다.\n",
    "        다음 [Context] 에 문서가 주어지면 해당 문서를 기반으로 {num_questions}개의 질문을 생성하세요. \n",
    "\n",
    "        질문과 정답을 생성한 후 아래의 출력 형식 GUIDE 에 맞게 생성합니다.\n",
    "        질문은 반드시 [context] 문서에 있는 정보를 바탕으로 생성해야 합니다. [context]에 없는 내용을 가지고 질문-답변을 절대 만들면 안됩니다.\n",
    "        질문은 간결하게 작성합니다.\n",
    "        하나의 질문에는 한 가지씩만 내용만 작성합니다. \n",
    "        질문을 만들 때 \"제공된 문맥에서\", \"문서에 설명된 대로\", \"주어진 문서에 따라\" 또는 이와 유사한 말을 하지 마세요.\n",
    "        정답은 반드시 [context]에 있는 정보를 바탕으로 작성합니다. 없는 내용을 추가하지 않습니다.\n",
    "        질문과 답변을 만들고 그 내용이 [context] 에 있는 항목인지 다시 한번 확인합니다.\n",
    "        생성된 질문-답변 쌍은 반드시 dictionary 형태로 정의하고 list로 묶어서 반환해야 합니다.\n",
    "        질문-답변 쌍은 반드시 {num_questions}개를 만들어 주십시오.\n",
    "                    \n",
    "        출력 형식: {format_instructions}\n",
    "\n",
    "        [Context]\n",
    "        {context}\n",
    "        \"\"\"\n",
    "    ),\n",
    "    partial_variables={\"format_instructions\":parser.get_format_instructions()}\n",
    ")\n",
    "\n",
    "model = ChatOpenAI(model=\"gpt-4o\")\n",
    "dataset_generator_chain = prompt_template | model | parser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "c = eval_context_list[0]\n",
    "\n",
    "qa = dataset_generator_chain.invoke({\"context\":c, \"num_questions\":5})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(qa)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'user_input': '세계반도핑기구(WADA)는 언제 설립되었나요?',\n",
       "  'retrieved_contexts': ['1990년대 후반, 여러 뜻있는 사람들이 도핑과의 전쟁을 선포하면서 1999년에 세계반도핑기구(WADA)를 설립한다. 2000년 하계 올림픽과 2002년 동계 올림픽 때는 약물 양성 반응을 보인 선수들이 급격히 증가했고, 역도와 크로스컨트리에서는 몇몇 선수들이 도핑 테스트에 걸려서 실격되기도 했다. 2006년 동계 올림픽 때는 메달리스트 한 명이 양성반응을 보여 메달을 반납해야 했다. IOC가 만든 약물 반응 판정(현재 올림픽 도핑테스트의 기준이 됨)은 인정을 받게 되었고 이제는 다른 경기 연맹에서도 벤치마킹을 할 정도가 되었다. 2008년 베이징 올림픽 기간중에는 3,667명의 선수들이 세계반도핑기구의 검사를 받았으며 소변과 혈액 검사로 약물 복용 검사를 했다. 몇몇 선수들은 국가 올림픽 위원회(NOC)에 의해 올림픽이 시작되기 전에 출전금지 조치를 당했고, 올림픽 기간중에는 단 3명만이 도핑 검사에 걸렸다.'],\n",
       "  'reference': '세계반도핑기구(WADA)는 1999년에 설립되었습니다.'},\n",
       " {'user_input': '2006년 동계 올림픽에서 어떤 일이 있었나요?',\n",
       "  'retrieved_contexts': ['1990년대 후반, 여러 뜻있는 사람들이 도핑과의 전쟁을 선포하면서 1999년에 세계반도핑기구(WADA)를 설립한다. 2000년 하계 올림픽과 2002년 동계 올림픽 때는 약물 양성 반응을 보인 선수들이 급격히 증가했고, 역도와 크로스컨트리에서는 몇몇 선수들이 도핑 테스트에 걸려서 실격되기도 했다. 2006년 동계 올림픽 때는 메달리스트 한 명이 양성반응을 보여 메달을 반납해야 했다. IOC가 만든 약물 반응 판정(현재 올림픽 도핑테스트의 기준이 됨)은 인정을 받게 되었고 이제는 다른 경기 연맹에서도 벤치마킹을 할 정도가 되었다. 2008년 베이징 올림픽 기간중에는 3,667명의 선수들이 세계반도핑기구의 검사를 받았으며 소변과 혈액 검사로 약물 복용 검사를 했다. 몇몇 선수들은 국가 올림픽 위원회(NOC)에 의해 올림픽이 시작되기 전에 출전금지 조치를 당했고, 올림픽 기간중에는 단 3명만이 도핑 검사에 걸렸다.'],\n",
       "  'reference': '2006년 동계 올림픽에서는 메달리스트 한 명이 양성반응을 보여 메달을 반납해야 했습니다.'},\n",
       " {'user_input': '올림픽 도핑 테스트의 기준은 무엇인가요?',\n",
       "  'retrieved_contexts': ['1990년대 후반, 여러 뜻있는 사람들이 도핑과의 전쟁을 선포하면서 1999년에 세계반도핑기구(WADA)를 설립한다. 2000년 하계 올림픽과 2002년 동계 올림픽 때는 약물 양성 반응을 보인 선수들이 급격히 증가했고, 역도와 크로스컨트리에서는 몇몇 선수들이 도핑 테스트에 걸려서 실격되기도 했다. 2006년 동계 올림픽 때는 메달리스트 한 명이 양성반응을 보여 메달을 반납해야 했다. IOC가 만든 약물 반응 판정(현재 올림픽 도핑테스트의 기준이 됨)은 인정을 받게 되었고 이제는 다른 경기 연맹에서도 벤치마킹을 할 정도가 되었다. 2008년 베이징 올림픽 기간중에는 3,667명의 선수들이 세계반도핑기구의 검사를 받았으며 소변과 혈액 검사로 약물 복용 검사를 했다. 몇몇 선수들은 국가 올림픽 위원회(NOC)에 의해 올림픽이 시작되기 전에 출전금지 조치를 당했고, 올림픽 기간중에는 단 3명만이 도핑 검사에 걸렸다.'],\n",
       "  'reference': 'IOC가 만든 약물 반응 판정이 올림픽 도핑 테스트의 기준입니다.'},\n",
       " {'user_input': '2008년 베이징 올림픽에서는 몇 명의 선수가 도핑 검사를 받았나요?',\n",
       "  'retrieved_contexts': ['1990년대 후반, 여러 뜻있는 사람들이 도핑과의 전쟁을 선포하면서 1999년에 세계반도핑기구(WADA)를 설립한다. 2000년 하계 올림픽과 2002년 동계 올림픽 때는 약물 양성 반응을 보인 선수들이 급격히 증가했고, 역도와 크로스컨트리에서는 몇몇 선수들이 도핑 테스트에 걸려서 실격되기도 했다. 2006년 동계 올림픽 때는 메달리스트 한 명이 양성반응을 보여 메달을 반납해야 했다. IOC가 만든 약물 반응 판정(현재 올림픽 도핑테스트의 기준이 됨)은 인정을 받게 되었고 이제는 다른 경기 연맹에서도 벤치마킹을 할 정도가 되었다. 2008년 베이징 올림픽 기간중에는 3,667명의 선수들이 세계반도핑기구의 검사를 받았으며 소변과 혈액 검사로 약물 복용 검사를 했다. 몇몇 선수들은 국가 올림픽 위원회(NOC)에 의해 올림픽이 시작되기 전에 출전금지 조치를 당했고, 올림픽 기간중에는 단 3명만이 도핑 검사에 걸렸다.'],\n",
       "  'reference': '2008년 베이징 올림픽에서는 3,667명의 선수가 도핑 검사를 받았습니다.'},\n",
       " {'user_input': '2008년 베이징 올림픽에서 도핑 검사에 걸린 선수는 몇 명인가요?',\n",
       "  'retrieved_contexts': ['1990년대 후반, 여러 뜻있는 사람들이 도핑과의 전쟁을 선포하면서 1999년에 세계반도핑기구(WADA)를 설립한다. 2000년 하계 올림픽과 2002년 동계 올림픽 때는 약물 양성 반응을 보인 선수들이 급격히 증가했고, 역도와 크로스컨트리에서는 몇몇 선수들이 도핑 테스트에 걸려서 실격되기도 했다. 2006년 동계 올림픽 때는 메달리스트 한 명이 양성반응을 보여 메달을 반납해야 했다. IOC가 만든 약물 반응 판정(현재 올림픽 도핑테스트의 기준이 됨)은 인정을 받게 되었고 이제는 다른 경기 연맹에서도 벤치마킹을 할 정도가 되었다. 2008년 베이징 올림픽 기간중에는 3,667명의 선수들이 세계반도핑기구의 검사를 받았으며 소변과 혈액 검사로 약물 복용 검사를 했다. 몇몇 선수들은 국가 올림픽 위원회(NOC)에 의해 올림픽이 시작되기 전에 출전금지 조치를 당했고, 올림픽 기간중에는 단 3명만이 도핑 검사에 걸렸다.'],\n",
       "  'reference': '2008년 베이징 올림픽 기간 중에는 단 3명의 선수가 도핑 검사에 걸렸습니다.'}]"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 확인 후 retrieved_contexts을 context로 변경.\n",
    "for d in qa:\n",
    "    d['retrieved_contexts'] = [c]\n",
    "qa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_input</th>\n",
       "      <th>retrieved_contexts</th>\n",
       "      <th>reference</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>세계반도핑기구(WADA)는 언제 설립되었나요?</td>\n",
       "      <td>[1990년대 후반, 여러 뜻있는 사람들이 도핑과의 전쟁을 선포하면서 1999년에 ...</td>\n",
       "      <td>세계반도핑기구(WADA)는 1999년에 설립되었습니다.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2006년 동계 올림픽에서 어떤 일이 있었나요?</td>\n",
       "      <td>[1990년대 후반, 여러 뜻있는 사람들이 도핑과의 전쟁을 선포하면서 1999년에 ...</td>\n",
       "      <td>2006년 동계 올림픽에서는 메달리스트 한 명이 양성반응을 보여 메달을 반납해야 했...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>올림픽 도핑 테스트의 기준은 무엇인가요?</td>\n",
       "      <td>[1990년대 후반, 여러 뜻있는 사람들이 도핑과의 전쟁을 선포하면서 1999년에 ...</td>\n",
       "      <td>IOC가 만든 약물 반응 판정이 올림픽 도핑 테스트의 기준입니다.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2008년 베이징 올림픽에서는 몇 명의 선수가 도핑 검사를 받았나요?</td>\n",
       "      <td>[1990년대 후반, 여러 뜻있는 사람들이 도핑과의 전쟁을 선포하면서 1999년에 ...</td>\n",
       "      <td>2008년 베이징 올림픽에서는 3,667명의 선수가 도핑 검사를 받았습니다.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2008년 베이징 올림픽에서 도핑 검사에 걸린 선수는 몇 명인가요?</td>\n",
       "      <td>[1990년대 후반, 여러 뜻있는 사람들이 도핑과의 전쟁을 선포하면서 1999년에 ...</td>\n",
       "      <td>2008년 베이징 올림픽 기간 중에는 단 3명의 선수가 도핑 검사에 걸렸습니다.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                               user_input  \\\n",
       "0               세계반도핑기구(WADA)는 언제 설립되었나요?   \n",
       "1              2006년 동계 올림픽에서 어떤 일이 있었나요?   \n",
       "2                  올림픽 도핑 테스트의 기준은 무엇인가요?   \n",
       "3  2008년 베이징 올림픽에서는 몇 명의 선수가 도핑 검사를 받았나요?   \n",
       "4   2008년 베이징 올림픽에서 도핑 검사에 걸린 선수는 몇 명인가요?   \n",
       "\n",
       "                                  retrieved_contexts  \\\n",
       "0  [1990년대 후반, 여러 뜻있는 사람들이 도핑과의 전쟁을 선포하면서 1999년에 ...   \n",
       "1  [1990년대 후반, 여러 뜻있는 사람들이 도핑과의 전쟁을 선포하면서 1999년에 ...   \n",
       "2  [1990년대 후반, 여러 뜻있는 사람들이 도핑과의 전쟁을 선포하면서 1999년에 ...   \n",
       "3  [1990년대 후반, 여러 뜻있는 사람들이 도핑과의 전쟁을 선포하면서 1999년에 ...   \n",
       "4  [1990년대 후반, 여러 뜻있는 사람들이 도핑과의 전쟁을 선포하면서 1999년에 ...   \n",
       "\n",
       "                                           reference  \n",
       "0                     세계반도핑기구(WADA)는 1999년에 설립되었습니다.  \n",
       "1  2006년 동계 올림픽에서는 메달리스트 한 명이 양성반응을 보여 메달을 반납해야 했...  \n",
       "2               IOC가 만든 약물 반응 판정이 올림픽 도핑 테스트의 기준입니다.  \n",
       "3         2008년 베이징 올림픽에서는 3,667명의 선수가 도핑 검사를 받았습니다.  \n",
       "4       2008년 베이징 올림픽 기간 중에는 단 3명의 선수가 도핑 검사에 걸렸습니다.  "
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "pd.DataFrame(qa)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "### 전체 context sample들로 qa dataset을 생성\n",
    "eval_data_list = []\n",
    "num_questions = 5  # context 당 k(5) 개 QA 쌍 생성.\n",
    "for context in eval_context_list:\n",
    "    _eval_data_list = dataset_generator_chain.invoke(\n",
    "        {\"context\":context, \"num_questions\":num_questions}\n",
    "    )\n",
    "    # retrieve_contexts의 값을 변경\n",
    "    # print(_eval_data_list)\n",
    "    for eval_data in _eval_data_list:\n",
    "        eval_data['retrieved_contexts'] = [context]\n",
    "    \n",
    "    eval_data_list.extend(_eval_data_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'user_input': '세계반도핑기구(WADA)는 언제 설립되었나요?',\n",
       "  'retrieved_contexts': ['1990년대 후반, 여러 뜻있는 사람들이 도핑과의 전쟁을 선포하면서 1999년에 세계반도핑기구(WADA)를 설립한다. 2000년 하계 올림픽과 2002년 동계 올림픽 때는 약물 양성 반응을 보인 선수들이 급격히 증가했고, 역도와 크로스컨트리에서는 몇몇 선수들이 도핑 테스트에 걸려서 실격되기도 했다. 2006년 동계 올림픽 때는 메달리스트 한 명이 양성반응을 보여 메달을 반납해야 했다. IOC가 만든 약물 반응 판정(현재 올림픽 도핑테스트의 기준이 됨)은 인정을 받게 되었고 이제는 다른 경기 연맹에서도 벤치마킹을 할 정도가 되었다. 2008년 베이징 올림픽 기간중에는 3,667명의 선수들이 세계반도핑기구의 검사를 받았으며 소변과 혈액 검사로 약물 복용 검사를 했다. 몇몇 선수들은 국가 올림픽 위원회(NOC)에 의해 올림픽이 시작되기 전에 출전금지 조치를 당했고, 올림픽 기간중에는 단 3명만이 도핑 검사에 걸렸다.'],\n",
       "  'reference': '세계반도핑기구(WADA)는 1999년에 설립되었습니다.'},\n",
       " {'user_input': '2006년 동계 올림픽에서 어떤 일이 있었나요?',\n",
       "  'retrieved_contexts': ['1990년대 후반, 여러 뜻있는 사람들이 도핑과의 전쟁을 선포하면서 1999년에 세계반도핑기구(WADA)를 설립한다. 2000년 하계 올림픽과 2002년 동계 올림픽 때는 약물 양성 반응을 보인 선수들이 급격히 증가했고, 역도와 크로스컨트리에서는 몇몇 선수들이 도핑 테스트에 걸려서 실격되기도 했다. 2006년 동계 올림픽 때는 메달리스트 한 명이 양성반응을 보여 메달을 반납해야 했다. IOC가 만든 약물 반응 판정(현재 올림픽 도핑테스트의 기준이 됨)은 인정을 받게 되었고 이제는 다른 경기 연맹에서도 벤치마킹을 할 정도가 되었다. 2008년 베이징 올림픽 기간중에는 3,667명의 선수들이 세계반도핑기구의 검사를 받았으며 소변과 혈액 검사로 약물 복용 검사를 했다. 몇몇 선수들은 국가 올림픽 위원회(NOC)에 의해 올림픽이 시작되기 전에 출전금지 조치를 당했고, 올림픽 기간중에는 단 3명만이 도핑 검사에 걸렸다.'],\n",
       "  'reference': '2006년 동계 올림픽 때 메달리스트 한 명이 양성반응을 보여 메달을 반납했습니다.'}]"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(eval_data_list)\n",
    "eval_data_list[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(25, 3)"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eval_df = pd.DataFrame(eval_data_list)\n",
    "eval_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_input</th>\n",
       "      <th>retrieved_contexts</th>\n",
       "      <th>reference</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>세계반도핑기구(WADA)는 언제 설립되었나요?</td>\n",
       "      <td>[1990년대 후반, 여러 뜻있는 사람들이 도핑과의 전쟁을 선포하면서 1999년에 ...</td>\n",
       "      <td>세계반도핑기구(WADA)는 1999년에 설립되었습니다.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2006년 동계 올림픽에서 어떤 일이 있었나요?</td>\n",
       "      <td>[1990년대 후반, 여러 뜻있는 사람들이 도핑과의 전쟁을 선포하면서 1999년에 ...</td>\n",
       "      <td>2006년 동계 올림픽 때 메달리스트 한 명이 양성반응을 보여 메달을 반납했습니다.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2008년 베이징 올림픽 기간 동안 몇 명의 선수가 도핑 검사를 받았나요?</td>\n",
       "      <td>[1990년대 후반, 여러 뜻있는 사람들이 도핑과의 전쟁을 선포하면서 1999년에 ...</td>\n",
       "      <td>2008년 베이징 올림픽 기간 동안 3,667명의 선수가 도핑 검사를 받았습니다.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>IOC가 만든 약물 반응 판정은 어떤 역할을 했나요?</td>\n",
       "      <td>[1990년대 후반, 여러 뜻있는 사람들이 도핑과의 전쟁을 선포하면서 1999년에 ...</td>\n",
       "      <td>IOC가 만든 약물 반응 판정은 올림픽 도핑 테스트의 기준이 되었고, 다른 경기 연...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2000년 하계 올림픽과 2002년 동계 올림픽에서 어떤 도핑 문제들이 발생했나요?</td>\n",
       "      <td>[1990년대 후반, 여러 뜻있는 사람들이 도핑과의 전쟁을 선포하면서 1999년에 ...</td>\n",
       "      <td>2000년 하계 올림픽과 2002년 동계 올림픽에서는 약물 양성 반응을 보인 선수들...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                       user_input  \\\n",
       "0                       세계반도핑기구(WADA)는 언제 설립되었나요?   \n",
       "1                      2006년 동계 올림픽에서 어떤 일이 있었나요?   \n",
       "2       2008년 베이징 올림픽 기간 동안 몇 명의 선수가 도핑 검사를 받았나요?   \n",
       "3                   IOC가 만든 약물 반응 판정은 어떤 역할을 했나요?   \n",
       "4  2000년 하계 올림픽과 2002년 동계 올림픽에서 어떤 도핑 문제들이 발생했나요?   \n",
       "\n",
       "                                  retrieved_contexts  \\\n",
       "0  [1990년대 후반, 여러 뜻있는 사람들이 도핑과의 전쟁을 선포하면서 1999년에 ...   \n",
       "1  [1990년대 후반, 여러 뜻있는 사람들이 도핑과의 전쟁을 선포하면서 1999년에 ...   \n",
       "2  [1990년대 후반, 여러 뜻있는 사람들이 도핑과의 전쟁을 선포하면서 1999년에 ...   \n",
       "3  [1990년대 후반, 여러 뜻있는 사람들이 도핑과의 전쟁을 선포하면서 1999년에 ...   \n",
       "4  [1990년대 후반, 여러 뜻있는 사람들이 도핑과의 전쟁을 선포하면서 1999년에 ...   \n",
       "\n",
       "                                           reference  \n",
       "0                     세계반도핑기구(WADA)는 1999년에 설립되었습니다.  \n",
       "1     2006년 동계 올림픽 때 메달리스트 한 명이 양성반응을 보여 메달을 반납했습니다.  \n",
       "2      2008년 베이징 올림픽 기간 동안 3,667명의 선수가 도핑 검사를 받았습니다.  \n",
       "3  IOC가 만든 약물 반응 판정은 올림픽 도핑 테스트의 기준이 되었고, 다른 경기 연...  \n",
       "4  2000년 하계 올림픽과 2002년 동계 올림픽에서는 약물 양성 반응을 보인 선수들...  "
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eval_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### HuggingFace hub에 생성된 평가 Dataset 저장\n",
    "- 생성한 평가 데이터셋을 HuggingFace hub에 저장하면 datasets을 이용해 load해서 사용 할 수 있다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['user_input', 'retrieved_contexts', 'reference'],\n",
       "    num_rows: 25\n",
       "})"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from datasets import Dataset\n",
    "import huggingface_hub as hub\n",
    "\n",
    "# DataFrame으로 부터 Dataset을 생성\n",
    "eval_dataset = Dataset.from_pandas(eval_df)\n",
    "eval_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5d7406eeca8a48f78f6c00c958c89451",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HTML(value='<center> <img\\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.sv…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 로그인\n",
    "hub.login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "094711332f1548b48c4de5106eb1081d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Uploading the dataset shards:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "271471e767d04fe2b9b64e3c0cea3e56",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Creating parquet from Arrow format:   0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "CommitInfo(commit_url='https://huggingface.co/datasets/kgmyh/olympic-ragas-eval-dataset/commit/1be519557b792ca505eddbbd7e666d0370b18143', commit_message='Upload dataset', commit_description='', oid='1be519557b792ca505eddbbd7e666d0370b18143', pr_url=None, repo_url=RepoUrl('https://huggingface.co/datasets/kgmyh/olympic-ragas-eval-dataset', endpoint='https://huggingface.co', repo_type='dataset', repo_id='kgmyh/olympic-ragas-eval-dataset'), pr_revision=None, pr_num=None)"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# dataset_name = \"계정명/데이터셋 이름\"\n",
    "dataset_name = \"kgmyh/olympic-ragas-eval-dataset\"\n",
    "eval_dataset.push_to_hub(dataset_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### HuggingFace hug의 평가 Datasets load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4a624304d18a4fe28e5471f431f3bd57",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "README.md:   0%|          | 0.00/360 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Playdata\\miniconda3\\envs\\langchain\\Lib\\site-packages\\huggingface_hub\\file_download.py:139: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\Playdata\\.cache\\huggingface\\hub\\datasets--kgmyh--olympic-ragas-eval-dataset. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9af30f2c724a4671ab8ef1a48c9496db",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "train-00000-of-00001.parquet:   0%|          | 0.00/13.7k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "296292d059714b358817e9628e9f3290",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split:   0%|          | 0/25 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "load_eval_dataset = load_dataset(\n",
    "    path=dataset_name\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['user_input', 'retrieved_contexts', 'reference'],\n",
       "    num_rows: 25\n",
       "})"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "load_eval_dataset[\"train\"]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "langchain",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
