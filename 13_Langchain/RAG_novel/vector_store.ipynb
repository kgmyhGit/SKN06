{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TODO\n",
    "\n",
    "- vector_store.ipynb\n",
    "    - data/ì†Œì„¤ë“¤.pdf ë“¤ Vector storeì— ì €ì¥.\n",
    "        - chroma, pinecone (ì•Œì•„ì„œ)\n",
    "        - metadata \n",
    "            - title: ì†Œì„¤ì œëª©\n",
    "            - author: ì €ì\n",
    "            - full_text: ì†Œì„¤ ì „ì²´ ë‚´ìš©\n",
    "        - Document(page_content=\"splitëœ ë‚´ìš©\", metadata={})\n",
    "        - page_contentëŠ” ì¡°íšŒí•  ë•Œ ì‚¬ìš©í•  embedding vectorë¥¼ ìƒì„±í•  ë•Œ ì‚¬ìš©ë  ë‚´ìš©.\n",
    "        - llm ëª¨ë¸ì— ì „ì†¡í•  contextëŠ” metadataì˜ full_text\n",
    "\n",
    "- app.py\n",
    "    - streamlitì„ ì´ìš©í•´ì„œ ì„œë¹„ìŠ¤í•˜ëŠ” application\n",
    "    - vector_store.ipynbì—ì„œ êµ¬ì¶•í•œ DBë¥¼ ì´ìš©í•´ ì§ˆë¬¸ê³¼ ê´€ë ¨ëœ ë‚´ìš©ë“¤ì„ \n",
    "      ì¡°íšŒí•´ì„œ llmì— ì „ì†¡í•˜ê³  ê·¸ ê²°ê³¼ë¥¼ ì±„íŒ…ì°½ì— ì¶œë ¥.\n",
    "    - memory ê¸°ëŠ¥ì€ ì‚¬ìš©í•˜ì§€ ì•ŠëŠ”ë‹¤."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ì†Œì„¤ë“¤ì„ Vector Storeì— ì €ì¥\n",
    "\n",
    "## Load\n",
    "- `data/*.pdf` íŒŒì¼ë“¤ì„ ëª¨ë‘ load"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- ê° ì†Œì„¤ë“¤ì„ split í•œ ë’¤ vector storeì— ì €ì¥í•œë‹¤.   \n",
    "- metadata:\n",
    "    - title: ì†Œì„¤ì œëª©\n",
    "    - author: ì €ì\n",
    "    - full_text: ì†Œì„¤ ì „ì²´ ë‚´ìš©"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import os\n",
    "import config\n",
    "from glob import glob\n",
    "\n",
    "from langchain_community.document_loaders import PyMuPDFLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain_core.documents import Document\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "# ì„¤ì • ì •ë³´ ì½ê¸°\n",
    "CHUNK_SIZE = config.chunk_size\n",
    "CHUNK_OVERLAP = config.chunk_overlap\n",
    "\n",
    "MODEL_NAME  = config.model_name\n",
    "EMBEDDING_NAME = config.embedding_name\n",
    "\n",
    "COLLECTION_NAME = config.collection_name\n",
    "PERSIST_DIRECTORY = config.persist_directory\n",
    "\n",
    "# ì†Œì„¤ íŒŒì¼ë“¤ ê²½ë¡œ ì¡°íšŒ\n",
    "path_list = glob(\"data/*.pdf\")\n",
    "\n",
    "document_list = []\n",
    "\n",
    "# load -> ì „ì²˜ë¦¬ -> split -> metadata ì¶”ê°€ \n",
    "for path in path_list:\n",
    "    # Document Load\n",
    "    loader = PyMuPDFLoader(path)\n",
    "    load_docs = loader.load()\n",
    "\n",
    "    # ì „ì²˜ë¦¬ - í˜ì´ì§€ ë²ˆí˜¸ ì œê±°, ğŸ™ğŸ™Ÿ ë¥¼ \\n\\n ìœ¼ë¡œ ë³€ê²½\n",
    "    full_text = [doc.page_content for doc in load_docs]\n",
    "    full_text = ''.join(full_text)\n",
    "    full_text = full_text.replace(\"ğŸ™ğŸ™Ÿ\", \"\\n\\n\")\n",
    "    full_text = re.sub(r\"\\d+\\n\", \" \", full_text)   # í˜ì´ì§€ ë²ˆí˜¸ ì œê±°\n",
    "    \n",
    "    # Split\n",
    "    splitter = RecursiveCharacterTextSplitter.from_tiktoken_encoder(\n",
    "        model_name=MODEL_NAME,\n",
    "        chunk_size=CHUNK_SIZE,\n",
    "        chunk_overlap=CHUNK_OVERLAP,\n",
    "    )\n",
    "    docs = splitter.split_text(full_text)\n",
    "\n",
    "    # Metadata ìƒì„±\n",
    "    author = os.path.splitext(os.path.basename(path))[0].split('_')[-1]\n",
    "    metadata = {\n",
    "        \"title\":load_docs[0].metadata[\"title\"],\n",
    "        \"author\": author,\n",
    "        \"full_text\":full_text\n",
    "    }\n",
    "\n",
    "    # Document ìƒì„±\n",
    "    for doc in docs:\n",
    "        _doc = Document(metadata=metadata, page_content=doc)\n",
    "        document_list.append(_doc)\n",
    "\n",
    "print(len(document_list))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vector Store ì €ì¥\n",
    "- Chroma Vector Storeì— ì €ì¥"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import OpenAIEmbeddings\n",
    "from langchain_chroma import Chroma\n",
    "\n",
    "\n",
    "embedding_model = OpenAIEmbeddings(\n",
    "    model=EMBEDDING_NAME\n",
    ")\n",
    "\n",
    "vector_store = Chroma.from_documents(\n",
    "    documents=document_list,\n",
    "    embedding=embedding_model,\n",
    "    collection_name=COLLECTION_NAME,\n",
    "    persist_directory=PERSIST_DIRECTORY\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# í™•ì¸"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ìì • ê°œìˆ˜ í™•ì¸\n",
    "vector_store._collection.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "###########################\n",
    "# ê²€ìƒ‰\n",
    "\n",
    "query = \"í˜„ì§„ê±´ì˜ ì†Œì„¤ë“¤ì˜ íŠ¹ì§•ì€ ì–´ë–¤ ê²ƒì´ ìˆì„ê¹Œ?\" \n",
    "query = \"ìš´ìˆ˜ì¢‹ì€ ë‚ ì—ì„œ ì£¼ì¸ê³µì€ ì™œ ê´´ìƒí•˜ê²Œë„ ìš´ìˆ˜ê°€ ì¢‹ë‹¤ê³  ëŠê¼ˆì„ê¹Œ?\"\n",
    "query = \"í—ˆ ìƒì›ì€ ì–´ëŠ ì¥ìœ¼ë¡œ ê°€ì„œ ì¥ì‚¬ë¥¼ í•  ì˜ˆì •ì¸ê°€?\"\n",
    "query = \"ì´íš¨ì„ì˜ ë©”ë°€ê½ƒ í•„ ë¬´ë µì˜ ì£¼ì¸ê³µì€ ëˆ„êµ¬ì¸ê°€?\"\n",
    "query = \"ë²™ì–´ë¦¬ ì‚¼ë£¡ì´ëŠ” í™”ìê°€ ëª‡ì‚´ ë•Œ ì¼ì¸ê°€?\"\n",
    "query = \"ì‚¼ë£¡ì´ì˜ ì£¼ì¸ ì•„ë“¤ì˜ ìƒ‰ì‹œëŠ” ëª‡ì‚´ì¸ê°€?\"\n",
    "\n",
    "result = vector_store.similarity_search(\n",
    "    query,\n",
    "    k=5,\n",
    "    # filter={\"author\": \"í˜„ì§„ê±´\"}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for res in result:\n",
    "    print(res.metadata['title'], res.metadata['author'], sep=\" | \")\n",
    "    print(res.page_content)\n",
    "    print(\"=====================================\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "langchain",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
