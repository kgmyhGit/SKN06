{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "35ee8245-0329-4185-971d-21bf20cc780e",
   "metadata": {},
   "source": [
    "# Chain\n",
    "\n",
    "- 여러 컴포넌트들을 논리적 순서대로 연결하여 복잡한 작업을 수행하는 구조로 복잡한 AI 작업을 체계적이고 효율적으로 구현할 수 있게 해준다.\n",
    "- 기본 개념\n",
    "    - 일련의 작업을 구성하는 여러 개별 컴포넌트들을 정의된 순서대로 실행시킨다.\n",
    "    - 단일 API 호출을 넘어 여러 호출을 논리적 순서로 연결 가능하다.\n",
    "    - 복잡한 작업을 작은 단계로 분해하여 순차적으로 처리할 수 있다.\n",
    "\n",
    "- Langchain은 `off-the-shelf chains` 방식과 `LCEL(Langchain Expression Language)`  두가지 방식이 있다.\n",
    "  - off-the-shelf chains 방식\n",
    "    - 미리정의된 Chain 클래스를 사용해 체인을 구성하는 방식\n",
    "    - Langchain의 초기 방식으로 대부분의 class들이 deprecated 되었다.\n",
    "  - LECL 방식\n",
    "    - 표현식을 이용해 체인을 구성하는 방식이다.\n",
    "    - 현재 LangChain은 LCEL(LangChain Expression Language)을 중심으로 발전하고 있다\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52ecc9c2-1744-4beb-84f3-257faddbec60",
   "metadata": {},
   "source": [
    "# Off-the-shelf chains 예제"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "83c6e80d-36bc-449d-bc94-6e92295e66ec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c5f09c17",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content='물론이죠! 스마트폰에 어울리는 이름 5개를 제안해드릴게요.\\n\\n1. **소닉폰 (Sonic Phone)** - 빠르고 효율적인 성능을 강조하는 이름.\\n2. **넥서스 (Nexus)** - 연결과 통합을 의미하는 이름으로, 다양한 기능을 포괄하는 스마트폰에 적합.\\n3. **스텔라 (Stella)** - 별을 의미하여, 반짝이는 디자인과 성능을 나타내는 이름.\\n4. **비전포 (VisionPro)** - 뛰어난 디스플레이와 카메라 기능을 강조하는 이름.\\n5. **에코스 (Echos)** - 사용자와의 소통과 반향을 중시하는 스마트폰에 잘 어울리는 이름.\\n\\n필요한 정보가 더 있으시면 말씀해 주세요!' additional_kwargs={'refusal': None} response_metadata={'token_usage': {'completion_tokens': 183, 'prompt_tokens': 22, 'total_tokens': 205, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_0705bf87c0', 'finish_reason': 'stop', 'logprobs': None} id='run-6bfca022-8a3a-41ab-8a50-80b14b9d3cfe-0' usage_metadata={'input_tokens': 22, 'output_tokens': 183, 'total_tokens': 205, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}\n"
     ]
    }
   ],
   "source": [
    "from langchain import PromptTemplate\n",
    "from langchain_openai import ChatOpenAI\n",
    "from pprint import pprint\n",
    "\n",
    "prompt_template = PromptTemplate(\n",
    "    template=\"{item}에 어울리는 이름 {count}개를 만들어 주세요.\"\n",
    ")\n",
    "model = ChatOpenAI(\n",
    "    model=\"gpt-4o-mini\",\n",
    "    temperature=1.0\n",
    ")\n",
    "\n",
    "# 순서\n",
    "## 1. prompt생성 -> 2. llm 요청\n",
    "prompt = prompt_template.invoke({\"item\":\"스마트폰\", \"count\": 5})\n",
    "# prompt.text\n",
    "result = model.invoke(prompt)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "66e2ce78",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Playdata\\AppData\\Local\\Temp\\ipykernel_4532\\22492021.py:3: LangChainDeprecationWarning: The class `LLMChain` was deprecated in LangChain 0.1.17 and will be removed in 1.0. Use :meth:`~RunnableSequence, e.g., `prompt | llm`` instead.\n",
      "  chain = LLMChain(\n"
     ]
    }
   ],
   "source": [
    "from langchain import LLMChain\n",
    "\n",
    "chain = LLMChain(\n",
    "    prompt=prompt_template,\n",
    "    llm=model\n",
    "    # , output_parser=OutputParser객체\n",
    ")\n",
    "# 입력: prompt_template의 전달할 값 -> chain(prompt_template -> llm) -> 출력:llm의 결과\n",
    "result = chain.invoke({\"item\":\"가방\", \"count\":3})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ac4eb688",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "물론이죠! 가방에 어울리는 이름 3개를 제안해 드릴게요.\n",
      "\n",
      "1. **모던 스퀘어** - 세련된 디자인의 가방에 잘 어울리는 이름으로, 도시적인 느낌을 줍니다.\n",
      "2. **에코 투고** - 자연친화적인 소재로 만든 가방에 적합한 이름으로, 환경을 생각하는 소비자에게 어필할 수 있습니다.\n",
      "3. **루나 클러치** - 우아하고 스타일리시한 클러치 백에 잘 어울리는 이름으로, 밤 외출 시 사용하기 좋습니다.\n",
      "\n",
      "이 이름들이 도움이 되길 바랍니다!\n"
     ]
    }
   ],
   "source": [
    "print(result['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "958fa29b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# LCEL\n",
    "chain2 = prompt_template | model \n",
    "result2 = chain2.invoke({\"item\":\"컴퓨터\", \"count\": 5})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5dcfb67c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "물론입니다! 여기 컴퓨터에 어울리는 이름 5개를 제안드립니다:\n",
      "\n",
      "1. **코드마스터 (CodeMaster)**\n",
      "2. **데이터스미스 (DataSmith)**\n",
      "3. **알고리즘스 (Algorithmus)**\n",
      "4. **바이트비전 (ByteVision)**\n",
      "5. **네트워크우즈 (NetworkWiz)**\n",
      "\n",
      "이 이름들이 마음에 드시길 바랍니다!\n"
     ]
    }
   ],
   "source": [
    "print(result2.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59ba00ec-6c7c-496e-b31f-f3978b74bdba",
   "metadata": {},
   "source": [
    "# LCEL (LangChain Expression Language)\n",
    "- LCEL은 LangChain의 핵심 기능인 **체인(Chain)을 더욱 효율적으로 구현하기 위해 도입된 **선언적 방식의 체인(chain) 구성 언어**이다.\n",
    "- `|` 연산자를 이용해 선언적 방법으로 Chain을 만든다.\n",
    "- [Runnable](https://api.python.langchain.com/en/latest/runnables/langchain_core.runnables.base.Runnable.html) type의 component들이 chain에 포함될 수있다.\n",
    "    - `|` 연산자를 이용해 Runnable들을 연결한다.\n",
    "    - chain이 실행되면 각 Runnable의 invoke() 메소드가 실행된다. 그리고 invoke()의 리턴값을 다음 Runnable의 invoke()에 전달해서 실행시킨다.\n",
    "    - [Runnable 컴포넌트별 입출력 타입](https://python.langchain.com/docs/expression_language/interface)\n",
    "        - 각 컴포넌트의 input과 output 타입에 맞춰 값이 전달되도록 한다.\n",
    "- https://python.langchain.com/v0.2/docs/concepts/#langchain-expression-language-lcel"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3f0d52c-23da-4ec6-87cc-925e3d6259ea",
   "metadata": {},
   "source": [
    "## Runnable\n",
    "- LangChain의 Runnable은 실행 가능한 작업 단위를 캡슐화한 개념으로, 데이터 흐름의 각 단계를 정의하고 체인(chain) 형태로 연결하여 복잡한 작업을 수행할 수 있게 한다.\n",
    "- Chain을 구성하는 class들은 Runnable의 하위 클래스로 구현한다.\n",
    "\n",
    "### 주요 특징\n",
    "- 작업 단위의 캡슐화:\n",
    "    - Runnable은 특정 작업(예: 프롬프트 생성, LLM 요청)을 수행하는 독립적인 컴포넌트이다.\n",
    "    - LangChain의 다양한 컴포넌트(PromptTemplate, LLM, OutputParser 등)들이 Runnable을# Runnable\n",
    "- LangChain의 Runnable은 실행 가능한 작업 단위를 캡슐화한 개념으로, 데이터 흐름의 각 단계를 정의하고 체인(chain) 형태로 연결하여 복잡한 작업을 수행할 수 있게 한다.\n",
    "- Chain을 구성하는 class들은 Runnable의 하위 클래스로 구현한다.\n",
    "\n",
    "### 주요 특징\n",
    "- 작업 단위의 캡슐화:\n",
    "    - Runnable은 특정 작업(예: 프롬프트 생성, LLM 요청)을 수행하는 독립적인 컴포넌트이다.\n",
    "    - LangChain의 다양한 컴포넌트(PromptTemplate, LLM, OutputParser 등)들이 Runnable을 상속받아 구현된다.\n",
    "- 체인 연결 및 작업 흐름 관리:\n",
    "    - Runnable은 파이프라인처럼 체인(순차적으로 실행되는 작업들을 연결한 것)을 구성할 수 있으며, `|` 연산자를 사용해 간단히 연결 가능하다.\n",
    "    - 입력과 출력 형식을 통일해서 컴포넌트를 매끄럽게 연결한다\n",
    "- 모듈화 및 디버깅 용이성:\n",
    "    - 각 단계가 명확히 분리되어 디버깅 및 유지보수가 용이하다.\n",
    "    - 복잡한 작업을 작은 단위로 나누어 관리할 수 있다.\n",
    "### Runnable의 표준 메소드\n",
    "- 모든 Runnable이 구현하는 공통 메소드\n",
    "- `invoke()`: 입력 데이터를 처리하여 결과를 반환.\n",
    "- `batch()`: 여러 입력 데이터들을 한 번에 처리.\n",
    "- `stream()`: 스트리밍 방식으로 응답 반환.\n",
    "- `ainvoke()`: 비동기 호출 지원.\n",
    "\n",
    "### Runnable의 주요 구현체\n",
    "- **`RunnablePassThrough`**\n",
    "    - 입력데이터를 다음 chain으로 그대로 전달하거나, 필요에 따라 추가적인 key-value 쌍을 더해서 전달한다. \n",
    "- **`RunnableParallel`**\n",
    "    - 여러 Runnable을 병렬로 실행하고 결과들을 합쳐서 다음 chain으로 전달한다.`**\n",
    "- **`RunnableLambda`**\n",
    "    - 일반 함수나 lambda 함수를 Runnable로 만들 때 사용."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c9491b0c-b9ec-4e12-a59c-ef6f04904b47",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "78906348",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Explain 아이폰 in one sentence.'"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### 사용자 정의 Runnable class\n",
    "from langchain_core.runnables import Runnable\n",
    "\n",
    "class MyRunnable(Runnable):\n",
    "    # invoke(): 1개 파라미터는 필수. -> Runnable이 작업할 때 필요한 입력 값.\n",
    "    def invoke(self, input_data:str, config=None):\n",
    "        # 이 Runnable이 해야하는 일을 invoke()에 구현.\n",
    "        ## config: 추가 설정 정보들. RunnableConfig 타입 받는다.-> 호출할 때 dict로 전달.\n",
    "        ### config에 어떤 값을 어떤 key로 넣을 지는 구현하는 쪽에서 결정.\n",
    "        ### lang:언어코드 => 그 코드에 맞는 prompt 문장을 반환하도록 구현.\n",
    "        if config is not None:\n",
    "            # config : {\"configurable\": {\"설정key\":\"설정값\"}} -> chain에서 호출시 config 전달형식\n",
    "            if config['configurable']['lang'] == \"en\":\n",
    "                return f\"Explain {input_data} in one sentence.\"\n",
    "        return f\"{input_data}에 대해서 한문장으로 설명해줘.\"\n",
    "    \n",
    "my_runnable = MyRunnable()\n",
    "my_runnable.invoke(\"사과\")\n",
    "my_runnable.invoke(\"아이폰\", {\"configurable\":{\"lang\":\"en\"}})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "80ffbeb7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "사과는 달콤하고 상큼한 맛을 가진 과일로, 건강에 좋은 영양소와 항산화 물질이 풍부하여 다양한 요리에 활용됩니다.\n"
     ]
    }
   ],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "model = ChatOpenAI(model=\"gpt-4o-mini\", max_tokens=100)\n",
    "prompt = my_runnable.invoke(\"사과\")\n",
    "res = model.invoke(prompt)\n",
    "print(res.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "afd2c247-a4e3-4b1b-a494-400b077eba54",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.output_parsers import StrOutputParser\n",
    "chain = my_runnable | model | StrOutputParser()\n",
    "result = chain.invoke(\"Galaxy s24\", {\"lang\":\"en\"})\n",
    "# chain에서 Runnable로 config를 전달할 때: config={\"configurable\":{\"lang\":\"en\"}})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "cdbb04b1-00c3-4534-9bed-45ac5064caa8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Samsung Galaxy S24 is an upcoming flagship smartphone expected to feature advanced technology, improved camera capabilities, and enhanced performance, building on the success of its predecessors in the Galaxy S series.\n"
     ]
    }
   ],
   "source": [
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "39c880f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "from langchain.prompts import ChatPromptTemplate\n",
    "from langchain_core.output_parsers import CommaSeparatedListOutputParser\n",
    "\n",
    "# 실행 순서: prompt -> model -> outputParser\n",
    "model = ChatOpenAI(\n",
    "    model=\"gpt-4o-mini\",\n",
    "    temperature=0.1\n",
    ")\n",
    "parser = CommaSeparatedListOutputParser()\n",
    "# system: 가이드, human: 질문\n",
    "prompt_template = ChatPromptTemplate(\n",
    "    messages=[\n",
    "        (\"system\", \"{format_instruction}.\\n목록의 item은 {count}개를 넘지 안도록 해주세요.\"),\n",
    "        (\"human\", \"{query}\")\n",
    "    ],\n",
    "    partial_variables={\"format_instruction\":parser.get_format_instructions()}\n",
    ")\n",
    "\n",
    "chain = prompt_template | model | parser\n",
    "\n",
    "result = chain.invoke({\"count\":5, \"query\":\"서울에 가 볼만한 여행지를 알려줘.\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "f5874ef5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['경복궁', '남산타워', '인사동', '홍대', '동대문 디자인 플라자']\n"
     ]
    }
   ],
   "source": [
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "ef8c73aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 레시피 요청 -(llm)-> 영어 레시피  한국어로 번역 요청 -llm-> 한국어 레시피\n",
    "# 1. chain(레시피를 알려주는 chain): 레시피요청 -> 레시피 출력(영어)\n",
    "# 2. chain(번역하는 chain): 영어 -> 한국어 번역\n",
    "# 3. 최종 chain: 레시피체인 -> 번역체인\n",
    "\n",
    "##### 레시피 체인\n",
    "model = ChatOpenAI(\n",
    "    model=\"gpt-4o-mini\", \n",
    "    temperature=0.1\n",
    ")\n",
    "chef_template = ChatPromptTemplate(\n",
    "    [\n",
    "        (\"system\", \"You are world-class international chef. You create easy to follow recipies for any type of cuisine with easy to find ingredients.\"),\n",
    "        (\"human\", \"I want to cook {food} food.\")\n",
    "    ]\n",
    ")\n",
    "\n",
    "chef_chain = chef_template | model | StrOutputParser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "f3c81a4b-17aa-4649-b2c8-f6d3c5787c77",
   "metadata": {},
   "outputs": [],
   "source": [
    "res = chef_chain.invoke({\"food\":\"steak\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52b2551e-9fc3-440b-8280-bc0d3ea0f91d",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(res.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "ae212bd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "##### 번역 chain\n",
    "translate_template = ChatPromptTemplate(\n",
    "    [\n",
    "        (\"system\", \"당신은 번역가 입니다. 다음 내용을 한국어로 번역해 주세요.\"),\n",
    "        (\"human\", \"{query}\")\n",
    "    ]\n",
    ")\n",
    "\n",
    "translate_chain = translate_template | model | StrOutputParser()\n",
    "\n",
    "# res = translate_chain.invoke({\"query\":\"You are world-class international chef.\"})\n",
    "res = translate_chain.invoke({\"query\":\"Ich bin hungrig.\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "73cf0eda",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "나는 배고파.\n"
     ]
    }
   ],
   "source": [
    "print(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "c71f50f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# chain도 Runnble Type -> 다른 chain의 컴포넌트로 포함될 수있다.\n",
    "final_chain = chef_chain | translate_chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "960c92b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = final_chain.invoke({\"food\":\"steak\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "76090d11",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'str'>\n",
      "좋은 선택입니다! 스테이크는 맛있고 다양한 방식으로 조리할 수 있는 요리입니다. 여기 클래식한 팬 시어드 스테이크와 마늘 버터를 위한 간단하고 쉬운 레시피가 있습니다. 이 레시피는 2인분입니다.\n",
      "\n",
      "### 마늘 버터를 곁들인 팬 시어드 스테이크\n",
      "\n",
      "#### 재료:\n",
      "- 리브아이 또는 등심 스테이크 2개 (약 1인치 두께)\n",
      "- 소금과 갓 간 블랙 페퍼\n",
      "- 올리브 오일 2큰술\n",
      "- 무염 버터 3큰술\n",
      "- 다진 마늘 3쪽\n",
      "- 장식용 신선한 허브 (타임이나 로즈마리 등, 선택 사항)\n",
      "\n",
      "#### 조리 방법:\n",
      "\n",
      "1. **스테이크 준비하기:**\n",
      "   - 스테이크를 냉장고에서 꺼내어 실온에서 약 30분간 두세요. 이렇게 하면 더 고르게 익습니다.\n",
      "   - 종이 타올로 스테이크의 수분을 제거하고, 양면에 소금과 갓 간 블랙 페퍼를 넉넉히 뿌려주세요.\n",
      "\n",
      "2. **팬 가열하기:**\n",
      "   - 중-강 불로 큰 팬(가급적 주철 팬)에 올리브 오일을 넣고 가열합니다. 오일이 반짝이지만 연기가 나지 않을 정도로 가열하세요.\n",
      "\n",
      "3. **스테이크 시어링하기:**\n",
      "   - 뜨거운 팬에 조심스럽게 스테이크를 놓습니다. 팬이 너무 붐비지 않도록 하세요; 필요하다면 한 번에 하나씩 조리하세요.\n",
      "   - 스테이크를 한쪽에서 약 4-5분간 움직이지 않고 시어링합니다. 이렇게 하면 맛있는 크러스트가 생깁니다.\n",
      "\n",
      "4. **뒤집고 버터 추가하기:**\n",
      "   - 집게를 사용하여 스테이크를 뒤집습니다. 팬에 버터와 다진 마늘을 추가합니다.\n",
      "   - 버터가 녹으면서 팬을 약간 기울이고 숟가락을 사용하여 녹은 버터를 스테이크 위에 뿌려줍니다. 이렇게 하면 풍미가 더해지고 스테이크의 윗부분이 익는 데 도움이 됩니다.\n",
      "\n",
      "5. **원하는 익힘 정도로 조리하기:**\n",
      "   - 원하는 익힘 정도에 따라 스테이크를 추가로 3-5분간 더 조리합니다:\n",
      "     - 레어: 125°F (51°C)\n",
      "     - 미디엄 레어: 135°F (57°C)\n",
      "     - 미디엄: 145°F (63°C)\n",
      "     - 미디엄 웰: 150°F (66°C)\n",
      "     - 웰던: 160°F (71°C)\n",
      "   - 정확한 온도를 위해 고기 온도계를 사용하세요.\n",
      "\n",
      "6. **스테이크 휴지시키기:**\n",
      "   - 원하는 익힘 정도로 조리한 후, 스테이크를 팬에서 꺼내어 도마에 놓습니다. 알루미늄 포일로 느슨하게 덮고 약 5-10분간 휴지시킵니다. 이렇게 하면 육즙이 재분배됩니다.\n",
      "\n",
      "7. **서빙하기:**\n",
      "   - 스테이크를 결 반대 방향으로 썰고, 위에 마늘 버터를 뿌려서 제공합니다. 원하시면 신선한 허브로 장식하세요.\n",
      "\n",
      "### 팁:\n",
      "- 스테이크와 함께 매시드 포테이토, 찐 야채 또는 신선한 샐러드 같은 사이드를 곁들여 보세요.\n",
      "- 다양한 양념이나 마리네이드로 풍미를 더해보세요.\n",
      "\n",
      "맛있는 스테이크 저녁을 즐기세요!\n"
     ]
    }
   ],
   "source": [
    "print(type(result))\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d3fd484",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76f5fe1d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fbb420e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33b9340a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d34b9d4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "01456936-8643-4dbc-8771-46678243d46f",
   "metadata": {},
   "source": [
    "## 사용자 함수를 chain으로 정의\n",
    "- 임의의 함수를 Runnable로 정의 할 수있다.\n",
    "    - LangChain 에서 제공하지 않는 기능을 Chain으로 만들 때 유용한다.\n",
    "- LangChain에서는 Runnable로 사용되는 사용자 정의 함수를 **Runnable Lambda** 라고 한다.\n",
    "- 함수를 Runnable 로 명시하는데는 다음 두가지 방법이 있다.\n",
    "1. `RunnableLambda` 이용\n",
    "   - `RunnableLambda(함수)`\n",
    "3. `@chain` 데코레이터 이용\n",
    "   - ```python\n",
    "     @chain\n",
    "     def func():\n",
    "         ...\n",
    "    ```\n",
    "### Runnable 로 정의 하는 함수 정의\n",
    "- 이전 Chain의 출력을 입력 받는 파라미터를 한개 선언한다.\n",
    "- 만약 함수가 여러개의 인자를 받는 경우 단일 입력을 받아들이고 이를 여러 인수로 풀어내는 래퍼 함수를 작성하여 Runnable로 만든다.\n",
    "```python\n",
    "def plus(num1, num2):\n",
    "    ...\n",
    "\n",
    "def wrapper_plus(nums:dict|list):\n",
    "    return plus(nums['num1'], nums['num2'])\n",
    "```\n",
    "- Chain의 실행결과를 return 한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f2616e7-27df-4012-8d54-e1d7cdaae11b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26c3436c-dc85-432b-8355-1a144af4577e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28dd2ad7-ea19-44a4-93b8-a74c80e3b96b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "70cfbc5c-6c03-48fc-9e4d-ddf8f34893f5",
   "metadata": {},
   "source": [
    "## Chain 간의 연결"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98e306d3-430f-4bfa-982c-a806e1910f23",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d1ab4d0-0f9f-4227-a821-5d9751d49942",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1806283d-0f8f-45e4-a68a-0207c90ad7c7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "1c8b48ae-b4b2-412f-a7b5-17e9c1ebc1a4",
   "metadata": {},
   "source": [
    "# Cache\n",
    "\n",
    "- 응답 결과를 저장해서 같은 질문이 들어오면 LLM에 요청하지 않고 저장된 결과를 보여주도록 한다.\n",
    "    - 처리속도와 비용을 절감할 수 있다.\n",
    "    - 특히 chatbot같이 비슷한 질문을 하는 경우 유용하다.\n",
    "- 저장 방식은 `메모리`, `sqlite` 등 다양한 방식을 지원한다.\n",
    "    - https://python.langchain.com/docs/integrations/llms/llm_caching\n",
    "```python\n",
    "set_llm_cache(Cache객체)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e8c002f-7f0c-4357-b3ae-efe8569f04cf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b74a46a8-703c-452b-9d57-e80749c3f528",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "520effd5-677c-46e3-9068-553e973bfea4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "langchain",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
