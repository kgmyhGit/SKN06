{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "49822c20-074d-44e0-9334-7530c0ed6cc3",
   "metadata": {},
   "source": [
    "# Memory\n",
    "\n",
    "- LLM과 주고 받은 대화를 저장하는 기능을 말한다. \n",
    "  - LLM 모델은 대화의 상태를 저장하지 않는다. 그래서 질문을 하면 그것에 대한 답변을 하고 끝이다. 대화 내용에 따라 이전 대화 내용을 바탕으로 연결되는 질문을 하고 그것에 대한 답변을 받아야 할 때가 있다. 이런 경우 지금 까지의 대화 내용을 저장하는 것을 메모리(memory)라고 한다.\n",
    "- **방식**\n",
    "  - 대화 내용을 저장한 뒤 다음 질문을 할 때 저장된 이전 질문들을 합쳐서 전송한다.\n",
    "  - 이전 대화내용을 어떻게 저장하는지에 따라 다양한 방식의 memory 기능이 있다.\n",
    "    - LLM은 [입력 토큰수의 제한이](https://platform.openai.com/docs/models) 있기 때문에 대화를 무한정 저장할 수없다.\n",
    "    - Langchain은 이전 대화 내용들을 요약하거나 최신 몇개만 저장하는 방식의 다양한 memory 방식을 제공한다.\n",
    "\n",
    "![memory.png](figures/memory.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76026745-6467-4c23-8816-d9cfae70854d",
   "metadata": {},
   "source": [
    "## 주요 Memory Class\n",
    "### ConversationBufferMemory\n",
    "- https://python.langchain.com/v0.1/docs/modules/memory/types/buffer/\n",
    "- **대화를 모두 그대로 저장**한다.\n",
    "- 대화가 길어질 경우 저장 양이 많아지는 문제가 있다.\n",
    "\n",
    "### ConversationBufferWindowMemory\n",
    "- **최신 대화 K개만 저장** 하고 그 이전 대화는 삭제한다. (K를 window size라고 하고 객체 생성시 설정한다.)\n",
    "  - 한개의 대화는 input(질문)-output(답변) 한 쌍을 말한다.\n",
    "    \n",
    "### ConversationTokenBufferMemory\n",
    "- https://python.langchain.com/v0.1/docs/modules/memory/types/token_buffer/\n",
    "- 지정한 **token 수를 넘지 않는 범위**에서 최신 대화들을 저장한다.\n",
    "  \n",
    "\n",
    "### ConversationSummaryMemory\n",
    "- https://python.langchain.com/v0.1/docs/modules/memory/types/summary/\n",
    "- **기존 대화들을 요약**해서 저장한다. 다만 요약은 llm이 하기 때문에 객체 생성시 llm 모델을 지정해야 한다.\n",
    "- 대화 내용이 요약되어 전송되므로 토큰 수를 줄여 요금을 절약할 수있다.\n",
    "  \n",
    "### ConversationSummaryBufferMemory\n",
    "- https://python.langchain.com/v0.1/docs/modules/memory/types/summary_buffer/\n",
    "- 대화들 자체를 메모리에 저장하다가 지정한 token을 넘어가면 **오래된 대화들 순서대로 요약**한다. \n",
    "  - 최신대화는 그대로 저장하고 오래된 대화는 요약해서 저장하는 방식.\n",
    "\n",
    "> #### ConversationSummaryMemory 토큰 비용\n",
    "> - 초기 비용은 ConversationSummaryMemory가 기존 대화를 요약하기 위해 LLM을 사용하므로 ConversationBufferMemory보다 더 많은 토큰을 사용한다. 그래서 비용이 더 많이 든다.\n",
    "> - 대화가 길어질수록 ConversationBufferMemory모든 대화 내용을 그대로 저장하므로 토큰 수가 선형적으로 증가한다. \n",
    "> - 반면 ConversationSummaryMemory는 대화가 길어질수록 요약된 형태로 기존 대화들이 저장되어 토큰 증가율이 더 낮아지게 되서 비용을 절감할 수있다.\n",
    "> - 비용과 관련해 **짧은 대화**일 경우 ConversationBufferMemory 가 효율적이고 **긴 대화일 경우** ConversationSummaryMemory가 효율적이다.\n",
    "> - **요약 비용을 절감** 하기 위해 **요약에는 저렴한 모델**을 사용할 수 있다.\n",
    "\n",
    "> #### Deprecated\n",
    "> - 위 메모리 저장 방식은 0.3.1 부터 deprecated 되었다. (1.0 버전에서 제거될 예정) \n",
    "> - 대신 RunnableWithMessageHistory 사용이 권장 된다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20719e99-4a9c-4db8-90cb-3dd38b16745d",
   "metadata": {},
   "source": [
    "### 공통 메소드\n",
    "- **initializer**\n",
    "  - memory_key: str = \"history\"\n",
    "    - 대화내역을 dict로 저장하는데 그때 사용되는 key.\n",
    "    - default는 **\"history\"**\n",
    "    - Prompt template에서 memory의 대화내용을 저장하는 placeholder(template variable)의 이름을 이 memory_key 로 지정한다.\n",
    "  - return_message: bool\n",
    "    - True: 각 대화내용을 Message(HumanMessage, AIMessage) 객체에 저장하고 그것을 List로 묶어서 반환\n",
    "    - False: 대화내용을 문자열(str)로 반환한다.\n",
    "  - chat_memory: BaseChatMessageHistory\n",
    "    - 대화 history를 어디에 저장할 지 설정. (메모리, sql등)\n",
    "- **save_context(inputs: dict, outputs: dict)**\n",
    "  - Memory에 대화내용(Context)을 저장.\n",
    "  - 파라미터\n",
    "    - inputs: Human message\n",
    "    - outputs: AI message\n",
    "- **load_memory_variables(dict)**\n",
    "  - 저장된 대화내용(context)를 반환.\n",
    "  - argument로 빈 dict를 넣어준다.\n",
    "- **clear()**\n",
    "  - 저장된 모든 대화 비우기\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e25be7a-6636-4fc6-946e-7d57e35bb14d",
   "metadata": {},
   "source": [
    "## 대화 저장"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "77a85e5f-a667-4622-b237-e821a6ceabbf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'chat_history': [HumanMessage(content='안녕하세요. 은행 계좌를 개설 하고 싶습니다.', additional_kwargs={}, response_metadata={}),\n",
      "                  AIMessage(content='계좌 개설을 원하시는 군요. 신분증을 먼저 준비하세요.', additional_kwargs={}, response_metadata={})]}\n"
     ]
    }
   ],
   "source": [
    "from langchain.memory import ConversationBufferMemory # 모든 대화를 다 저장.\n",
    "from pprint import pprint\n",
    "# 메모리 객체 생성\n",
    "memory = ConversationBufferMemory(\n",
    "    memory_key=\"chat_history\", \n",
    "    return_messages=True, # 대화내용을 Message객체로 반환. False: 문자열\n",
    ")\n",
    "\n",
    "# 메모리에 대화 저장.\n",
    "memory.save_context(\n",
    "    inputs={\"human\":\"안녕하세요. 은행 계좌를 개설 하고 싶습니다.\"}, #{role:대화내용}\n",
    "    outputs={\"ai\":\"계좌 개설을 원하시는 군요. 신분증을 먼저 준비하세요.\"}\n",
    ")\n",
    "# 저장된 대화들을 조회\n",
    "save_conv = memory.load_memory_variables({})\n",
    "pprint(save_conv)\n",
    "# 저장형식: dictionary\n",
    "### {memory_key: \"대화들\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "77691e85-d2ed-4706-9ec5-1e71d66acd3c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[HumanMessage(content='안녕하세요. 은행 계좌를 개설 하고 싶습니다.', additional_kwargs={}, response_metadata={}),\n",
       " AIMessage(content='계좌 개설을 원하시는 군요. 신분증을 먼저 준비하세요.', additional_kwargs={}, response_metadata={})]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# save_conv['history']\n",
    "save_conv['chat_history']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1be35310",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'chat_history': [HumanMessage(content='안녕하세요. 은행 계좌를 개설 하고 싶습니다.', additional_kwargs={}, response_metadata={}),\n",
      "                  AIMessage(content='계좌 개설을 원하시는 군요. 신분증을 먼저 준비하세요.', additional_kwargs={}, response_metadata={}),\n",
      "                  HumanMessage(content='신분증을 준비했습니다. 다음에는 무엇을 하면 되나요?', additional_kwargs={}, response_metadata={}),\n",
      "                  AIMessage(content='신분증 앞면을 촬영해서 업로드 해주세요.', additional_kwargs={}, response_metadata={})]}\n"
     ]
    }
   ],
   "source": [
    "memory.save_context(\n",
    "    inputs={\"human\":\"신분증을 준비했습니다. 다음에는 무엇을 하면 되나요?\"},\n",
    "    outputs={\"ai\":\"신분증 앞면을 촬영해서 업로드 해주세요.\"}\n",
    ")\n",
    "pprint(memory.load_memory_variables({}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "39b4bba2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'chat_history': []}\n"
     ]
    }
   ],
   "source": [
    "memory.clear() # 저장내용 모두 삭제\n",
    "pprint(memory.load_memory_variables({}))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16202258-7635-4055-b43b-d17d5cb13446",
   "metadata": {},
   "source": [
    "# 주요 메모리 클래스 예제\n",
    "\n",
    "## ConversationBufferMemory\n",
    "메모리에 대화를 모두 저장한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e10e48ff-7210-45ce-96c8-dd56dbe35fc4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'history': [HumanMessage(content='안녕하세요', additional_kwargs={}, response_metadata={}),\n",
      "             AIMessage(content='반갑습니다.', additional_kwargs={}, response_metadata={}),\n",
      "             HumanMessage(content='한국 여행에 대해 물어보려고 합니다.', additional_kwargs={}, response_metadata={}),\n",
      "             AIMessage(content='무엇이든 물어보세요.', additional_kwargs={}, response_metadata={}),\n",
      "             HumanMessage(content='여행 할 때 꼭 먹어봐야할 음식 3개만 추천해줘.', additional_kwargs={}, response_metadata={}),\n",
      "             AIMessage(content='불고기, 비빔밥, 삼겹살을 추천합니다.', additional_kwargs={}, response_metadata={}),\n",
      "             HumanMessage(content='여행지 두 곳을 추천해줘.', additional_kwargs={}, response_metadata={}),\n",
      "             AIMessage(content='경복궁과 국립중앙박물관입니다.', additional_kwargs={}, response_metadata={}),\n",
      "             HumanMessage(content='여행지 한 곳 더 추천해줘.', additional_kwargs={}, response_metadata={}),\n",
      "             AIMessage(content='민속촌을 추천합니다.', additional_kwargs={}, response_metadata={}),\n",
      "             HumanMessage(content='한국의 자연을 느낄 수있는 여행지를 알려줘.', additional_kwargs={}, response_metadata={}),\n",
      "             AIMessage(content='북한산을 추천합니다. 서울 도심에서 자연을 느낄 수있습니다.', additional_kwargs={}, response_metadata={})]}\n"
     ]
    }
   ],
   "source": [
    "from langchain.memory import ConversationBufferMemory\n",
    "from pprint import pprint\n",
    "\n",
    "memory = ConversationBufferMemory(\n",
    "    return_messages=True\n",
    ")\n",
    "\n",
    "memory.save_context(\n",
    "    inputs={\n",
    "        \"human\":\"안녕하세요\"\n",
    "    },\n",
    "    outputs={\n",
    "        \"ai\": \"반갑습니다.\"\n",
    "    }\n",
    ")\n",
    "\n",
    "memory.save_context(\n",
    "    inputs={\n",
    "        \"human\":\"한국 여행에 대해 물어보려고 합니다.\"\n",
    "    },\n",
    "    outputs={\n",
    "        \"ai\":\"무엇이든 물어보세요.\"\n",
    "    }\n",
    ")\n",
    "\n",
    "memory.save_context(\n",
    "    inputs={\n",
    "        \"human\":\"여행 할 때 꼭 먹어봐야할 음식 3개만 추천해줘.\"\n",
    "    },\n",
    "    outputs={\n",
    "        \"ai\":\"불고기, 비빔밥, 삼겹살을 추천합니다.\"\n",
    "    }\n",
    ")\n",
    "\n",
    "memory.save_context(\n",
    "    inputs={\n",
    "        \"human\":\"여행지 두 곳을 추천해줘.\"\n",
    "    },\n",
    "    outputs={\n",
    "        \"ai\":\"경복궁과 국립중앙박물관입니다.\"\n",
    "    }\n",
    ")\n",
    "memory.save_context(\n",
    "    inputs={\n",
    "        \"human\":\"여행지 한 곳 더 추천해줘.\"\n",
    "    },\n",
    "    outputs={\n",
    "        \"ai\":\"민속촌을 추천합니다.\"\n",
    "    }\n",
    ")\n",
    "\n",
    "memory.save_context(\n",
    "    inputs={\n",
    "        \"human\":\"한국의 자연을 느낄 수있는 여행지를 알려줘.\"\n",
    "    },\n",
    "    outputs={\n",
    "        \"ai\":\"북한산을 추천합니다. 서울 도심에서 자연을 느낄 수있습니다.\"\n",
    "    }\n",
    ")\n",
    "\n",
    "pprint(memory.load_memory_variables({}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9871296e-070b-4989-833a-4ea1ebcf7cbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# LLM 모델에 요청\n",
    "from langchain.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "model = ChatOpenAI(model=\"gpt-4o-mini\")\n",
    "prompt_template = ChatPromptTemplate(\n",
    "    [\n",
    "        (\"system\", \"당신은 한국 여행 전문가 입니다. 한국 여행과 관련된 다양한 정보를 알려주세요.\"),\n",
    "        MessagesPlaceholder(\"history\", optional=True),\n",
    "        (\"human\", \"{query}\")\n",
    "    ]\n",
    ")\n",
    "chain = prompt_template | model | StrOutputParser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5eadcf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"마지막 소개한 여행지를 가는 방법에 대해 알려주세요.\"\n",
    "res = chain.invoke(\n",
    "    {\"query\":query, \"history\":memory.load_memory_variables({})[\"history\"]}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "64833b00",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "어떤 여행지를 말씀하시는지 구체적으로 알려주시면, 그 여행지를 가는 방법에 대해 자세히 안내해드리겠습니다. 한국에는 다양한 여행지가 있으니, 특정한 장소를 지정해 주시면 더욱 정확한 정보를 제공할 수 있습니다. 예를 들어, 서울, 부산, 제주도 등 특정 지역을 말씀해 주시면 좋습니다!\n"
     ]
    }
   ],
   "source": [
    "print(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ff8bbab",
   "metadata": {},
   "outputs": [],
   "source": [
    "## 최신 대화를 memery에 저장\n",
    "memory.save_context(\n",
    "    inputs={\"human\":query},\n",
    "    outputs={\"ai\":res}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "845aec9a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[HumanMessage(content='안녕하세요', additional_kwargs={}, response_metadata={}),\n",
      " AIMessage(content='반갑습니다.', additional_kwargs={}, response_metadata={}),\n",
      " HumanMessage(content='한국 여행에 대해 물어보려고 합니다.', additional_kwargs={}, response_metadata={}),\n",
      " AIMessage(content='무엇이든 물어보세요.', additional_kwargs={}, response_metadata={}),\n",
      " HumanMessage(content='여행 할 때 꼭 먹어봐야할 음식 3개만 추천해줘.', additional_kwargs={}, response_metadata={}),\n",
      " AIMessage(content='불고기, 비빔밥, 삼겹살을 추천합니다.', additional_kwargs={}, response_metadata={}),\n",
      " HumanMessage(content='여행지 두 곳을 추천해줘.', additional_kwargs={}, response_metadata={}),\n",
      " AIMessage(content='경복궁과 국립중앙박물관입니다.', additional_kwargs={}, response_metadata={}),\n",
      " HumanMessage(content='여행지 한 곳 더 추천해줘.', additional_kwargs={}, response_metadata={}),\n",
      " AIMessage(content='민속촌을 추천합니다.', additional_kwargs={}, response_metadata={}),\n",
      " HumanMessage(content='한국의 자연을 느낄 수있는 여행지를 알려줘.', additional_kwargs={}, response_metadata={}),\n",
      " AIMessage(content='북한산을 추천합니다. 서울 도심에서 자연을 느낄 수있습니다.', additional_kwargs={}, response_metadata={}),\n",
      " HumanMessage(content='마지막 소개한 여행지를 가는 방법에 대해 알려주세요.', additional_kwargs={}, response_metadata={}),\n",
      " AIMessage(content='어떤 여행지를 말씀하시는지 구체적으로 알려주시면, 그 여행지를 가는 방법에 대해 자세히 안내해드리겠습니다. 한국에는 다양한 여행지가 있으니, 특정한 장소를 지정해 주시면 더욱 정확한 정보를 제공할 수 있습니다. 예를 들어, 서울, 부산, 제주도 등 특정 지역을 말씀해 주시면 좋습니다!', additional_kwargs={}, response_metadata={})]\n"
     ]
    }
   ],
   "source": [
    "pprint(memory.load_memory_variables({})[\"history\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4023e498",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_memory(memory):\n",
    "    memory.save_context(\n",
    "        inputs={\n",
    "            \"human\":\"안녕하세요\"\n",
    "        },\n",
    "        outputs={\n",
    "            \"ai\": \"반갑습니다.\"\n",
    "        }\n",
    "    )\n",
    "\n",
    "    memory.save_context(\n",
    "        inputs={\n",
    "            \"human\":\"한국 여행에 대해 물어보려고 합니다.\"\n",
    "        },\n",
    "        outputs={\n",
    "            \"ai\":\"무엇이든 물어보세요.\"\n",
    "        }\n",
    "    )\n",
    "\n",
    "    memory.save_context(\n",
    "        inputs={\n",
    "            \"human\":\"여행 할 때 꼭 먹어봐야할 음식 3개만 추천해줘.\"\n",
    "        },\n",
    "        outputs={\n",
    "            \"ai\":\"불고기, 비빔밥, 삼겹살을 추천합니다.\"\n",
    "        }\n",
    "    )\n",
    "\n",
    "    memory.save_context(\n",
    "        inputs={\n",
    "            \"human\":\"여행지 두 곳을 추천해줘.\"\n",
    "        },\n",
    "        outputs={\n",
    "            \"ai\":\"경복궁과 국립중앙박물관입니다.\"\n",
    "        }\n",
    "    )\n",
    "    memory.save_context(\n",
    "        inputs={\n",
    "            \"human\":\"여행지 한 곳 더 추천해줘.\"\n",
    "        },\n",
    "        outputs={\n",
    "            \"ai\":\"민속촌을 추천합니다.\"\n",
    "        }\n",
    "    )\n",
    "\n",
    "    memory.save_context(\n",
    "        inputs={\n",
    "            \"human\":\"한국의 자연을 느낄 수있는 여행지를 알려줘.\"\n",
    "        },\n",
    "        outputs={\n",
    "            \"ai\":\"북한산을 추천합니다. 서울 도심에서 자연을 느낄 수있습니다.\"\n",
    "        }\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c62ab200-4ac3-4d9e-8982-3e26e91d9db6",
   "metadata": {},
   "source": [
    "## ConversationBufferWindowMemory\n",
    "최신 대화 K개만 저장 한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bff1d534-9362-4275-bfb8-e63a04eb4b7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.memory import ConversationBufferWindowMemory\n",
    "from warnings import filterwarnings\n",
    "filterwarnings('ignore')  # 경고메세지는 출력안되게 처리.\n",
    "\n",
    "memory = ConversationBufferWindowMemory(\n",
    "    k=5, # 최근 대화(input+output: 1개) k(3) 개까지만 저장. 오래된 것은 삭제.\n",
    "    return_messages=True\n",
    ")\n",
    "# memory.save_context(inputs=...., outputs=...)\n",
    "save_memory(memory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d2d4074-5632-4917-bbb4-6c517a1d1f91",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[HumanMessage(content='한국 여행에 대해 물어보려고 합니다.', additional_kwargs={}, response_metadata={}),\n",
      " AIMessage(content='무엇이든 물어보세요.', additional_kwargs={}, response_metadata={}),\n",
      " HumanMessage(content='여행 할 때 꼭 먹어봐야할 음식 3개만 추천해줘.', additional_kwargs={}, response_metadata={}),\n",
      " AIMessage(content='불고기, 비빔밥, 삼겹살을 추천합니다.', additional_kwargs={}, response_metadata={}),\n",
      " HumanMessage(content='여행지 두 곳을 추천해줘.', additional_kwargs={}, response_metadata={}),\n",
      " AIMessage(content='경복궁과 국립중앙박물관입니다.', additional_kwargs={}, response_metadata={}),\n",
      " HumanMessage(content='여행지 한 곳 더 추천해줘.', additional_kwargs={}, response_metadata={}),\n",
      " AIMessage(content='민속촌을 추천합니다.', additional_kwargs={}, response_metadata={}),\n",
      " HumanMessage(content='한국의 자연을 느낄 수있는 여행지를 알려줘.', additional_kwargs={}, response_metadata={}),\n",
      " AIMessage(content='북한산을 추천합니다. 서울 도심에서 자연을 느낄 수있습니다.', additional_kwargs={}, response_metadata={})]\n"
     ]
    }
   ],
   "source": [
    "from pprint import pprint\n",
    "pprint(memory.load_memory_variables({})['history'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4eba863-a009-4ddd-91bf-6ac26a05e56b",
   "metadata": {},
   "source": [
    "## ConversationTokenBufferMemory\n",
    "대화의 토큰 길이를 기준으로 최신 대화만 저장한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "700de1e3-8d33-4f55-ae59-e370621c48f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.memory import ConversationTokenBufferMemory\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "model = ChatOpenAI(model='gpt-4o-mini')\n",
    "memory = ConversationTokenBufferMemory(\n",
    "    llm=model, # llm 모델이 필요. (토큰 체크용.-모델마다 토큰 계산이 다르기 때문에 사용할 모델을 넣어준다.)\n",
    "    max_token_limit=100, \n",
    "    return_messages=True\n",
    ")\n",
    "save_memory(memory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "7e46c3e0-bfc0-4d77-a91a-e292f1b9ea9f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[AIMessage(content='경복궁과 국립중앙박물관입니다.', additional_kwargs={}, response_metadata={}),\n",
      " HumanMessage(content='여행지 한 곳 더 추천해줘.', additional_kwargs={}, response_metadata={}),\n",
      " AIMessage(content='민속촌을 추천합니다.', additional_kwargs={}, response_metadata={}),\n",
      " HumanMessage(content='한국의 자연을 느낄 수있는 여행지를 알려줘.', additional_kwargs={}, response_metadata={}),\n",
      " AIMessage(content='북한산을 추천합니다. 서울 도심에서 자연을 느낄 수있습니다.', additional_kwargs={}, response_metadata={})]\n"
     ]
    }
   ],
   "source": [
    "pprint(memory.load_memory_variables({})[\"history\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66c04e70-3d47-49d0-9dbd-70c6423da7ba",
   "metadata": {},
   "source": [
    "## ConversationSummaryMemory\n",
    "대화를 요약해서 저장한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0304b3e-0607-4abb-b2f0-74cefc66ceba",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.memory import ConversationSummaryMemory\n",
    "\n",
    "memory = ConversationSummaryMemory(\n",
    "    llm=model, # 대화내용을 요약할 모델을 설정. \n",
    ")\n",
    "save_memory(memory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "d3aff8bd-4be8-4c8c-9748-192b22367dad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('The human greets the AI in Korean, and the AI responds with a greeting. The '\n",
      " 'human expresses that they want to ask about traveling to Korea, and the AI '\n",
      " 'invites them to ask anything. The human requests the AI to recommend three '\n",
      " 'must-try foods while traveling, and the AI suggests bulgogi, bibimbap, and '\n",
      " 'samgyeopsal. The human then asks the AI to recommend two travel '\n",
      " 'destinations, and the AI suggests Gyeongbokgung Palace and the National '\n",
      " 'Museum of Korea. Finally, the human asks for one more travel destination, '\n",
      " 'and the AI recommends the Korean Folk Village. The human then asks for a '\n",
      " \"travel destination to experience Korea's nature, and the AI recommends \"\n",
      " 'Bukhansan, which allows visitors to enjoy nature within the city of Seoul.')\n"
     ]
    }
   ],
   "source": [
    "pprint(memory.load_memory_variables({})['history'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63765d06",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_variables=['new_lines', 'summary'] input_types={} partial_variables={} template='Progressively summarize the lines of conversation provided, adding onto the previous summary returning a new summary.\\n\\nEXAMPLE\\nCurrent summary:\\nThe human asks what the AI thinks of artificial intelligence. The AI thinks artificial intelligence is a force for good.\\n\\nNew lines of conversation:\\nHuman: Why do you think artificial intelligence is a force for good?\\nAI: Because artificial intelligence will help humans reach their full potential.\\n\\nNew summary:\\nThe human asks what the AI thinks of artificial intelligence. The AI thinks artificial intelligence is a force for good because it will help humans reach their full potential.\\nEND OF EXAMPLE\\n\\nCurrent summary:\\n{summary}\\n\\nNew lines of conversation:\\n{new_lines}\\n\\nNew summary:'\n",
      "--------------------------\n",
      "Progressively summarize the lines of conversation provided, adding onto the previous summary returning a new summary.\n",
      "\n",
      "EXAMPLE\n",
      "Current summary:\n",
      "The human asks what the AI thinks of artificial intelligence. The AI thinks artificial intelligence is a force for good.\n",
      "\n",
      "New lines of conversation:\n",
      "Human: Why do you think artificial intelligence is a force for good?\n",
      "AI: Because artificial intelligence will help humans reach their full potential.\n",
      "\n",
      "New summary:\n",
      "The human asks what the AI thinks of artificial intelligence. The AI thinks artificial intelligence is a force for good because it will help humans reach their full potential.\n",
      "END OF EXAMPLE\n",
      "\n",
      "Current summary:\n",
      "{summary}\n",
      "\n",
      "New lines of conversation:\n",
      "{new_lines}\n",
      "\n",
      "New summary:\n"
     ]
    }
   ],
   "source": [
    "print(memory.prompt) # LLM에게 대화를 요청하기 위한 prompt template 조회.\n",
    "print(\"--------------------------\")\n",
    "print(memory.prompt.template)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2168db8b-4a5f-4a66-aed9-e78dfdb96fe7",
   "metadata": {},
   "source": [
    "## ConversationSummaryBufferMemory\n",
    "오래된 대화는 요약하고 최신대화는 그대로 저장한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05a2fa84-18da-4393-be59-65d7632de3ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.memory import ConversationSummaryBufferMemory\n",
    "\n",
    "memory = ConversationSummaryBufferMemory(\n",
    "    llm=model, #요약에 사용할 모델.\n",
    "    max_token_limit=100, \n",
    "    return_messages=True\n",
    ")\n",
    "save_memory(memory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "f3894e55-26ae-4487-937b-051eeb4f103d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[SystemMessage(content='The human greets the AI in Korean, and the AI responds warmly. The human then states that they would like to ask about traveling in Korea, and the AI encourages the human to ask anything. The human requests three must-try foods when traveling, and the AI recommends bulgogi, bibimbap, and samgyeopsal. The human then asks for two travel destination recommendations.', additional_kwargs={}, response_metadata={}),\n",
      " AIMessage(content='경복궁과 국립중앙박물관입니다.', additional_kwargs={}, response_metadata={}),\n",
      " HumanMessage(content='여행지 한 곳 더 추천해줘.', additional_kwargs={}, response_metadata={}),\n",
      " AIMessage(content='민속촌을 추천합니다.', additional_kwargs={}, response_metadata={}),\n",
      " HumanMessage(content='한국의 자연을 느낄 수있는 여행지를 알려줘.', additional_kwargs={}, response_metadata={}),\n",
      " AIMessage(content='북한산을 추천합니다. 서울 도심에서 자연을 느낄 수있습니다.', additional_kwargs={}, response_metadata={})]\n"
     ]
    }
   ],
   "source": [
    "pprint(memory.load_memory_variables({})['history'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee66a928-177d-4f03-9975-0e218660c021",
   "metadata": {},
   "source": [
    "# Chain\n",
    "## Off-the-shelf chains"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "148ec7f6-232d-4bc8-b918-d9eed90a1b78",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.chains import LLMChain, ConversationChain # 미리 정의된 Chain클래스들(off the shelf chain)\n",
    "from langchain.memory import ConversationSummaryBufferMemory\n",
    "from langchain.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from pprint import pprint\n",
    "from warnings import filterwarnings\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "filterwarnings('ignore')\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "1213759e",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_template = ChatPromptTemplate(\n",
    "    [\n",
    "        (\"system\", \"답변은 세 문장 이하로 간결하게 대답해줘.\"),\n",
    "        MessagesPlaceholder(\"history\"), # varable_name -> memory_key와 동일한 값으로 지정.\n",
    "        (\"human\", \"{query}\")\n",
    "    ]\n",
    ")\n",
    "# 모델: 대화기록을 summary하는 모델과 실제 요청에 응답하는 모델을 따로 생성할 수있다.\n",
    "s_model = ChatOpenAI(\n",
    "    model=\"gpt-4o-mini\"\n",
    ")\n",
    "# 메모리 객체\n",
    "memory = ConversationSummaryBufferMemory(\n",
    "    llm=s_model,\n",
    "    max_token_limit=200,\n",
    "    # memory_key=\"history\", # default: history\n",
    "    return_messages=True\n",
    ")\n",
    "output_parser = StrOutputParser()\n",
    "model = ChatOpenAI(\n",
    "    model=\"gpt-4o-mini\"\n",
    ")\n",
    "chain = LLMChain(\n",
    "    llm=model, # LLM Model\n",
    "    prompt=prompt_template,\n",
    "    output_parser=output_parser,\n",
    "    memory=memory  # 메모리\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "e8715ae3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'query': '안녕하세요', 'history': [HumanMessage(content='안녕하세요', additional_kwargs={}, response_metadata={}), AIMessage(content='안녕하세요! 어떻게 도와드릴까요?', additional_kwargs={}, response_metadata={})], 'text': '안녕하세요! 어떻게 도와드릴까요?'}\n"
     ]
    }
   ],
   "source": [
    "result = chain.invoke({\"query\":\"안녕하세요\"})\n",
    "# result - template 변수들에 넣은 값들 key=valaue, history에 저장된 값들, 응답값들을\n",
    "#          딕셔너리에 묶어서 반환.\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "d29bb055",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "안녕하세요! 어떻게 도와드릴까요?\n"
     ]
    }
   ],
   "source": [
    "print(result[\"text\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "8dfc933a-11de-46f8-b88e-18c20e0a25d1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[HumanMessage(content='안녕하세요', additional_kwargs={}, response_metadata={}),\n",
       " AIMessage(content='안녕하세요! 어떻게 도와드릴까요?', additional_kwargs={}, response_metadata={})]"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 메모리에 저장된 내역 확인.\n",
    "memory.load_memory_variables({})[\"history\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "b7528169",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Human: 내 이름은 김성환입니다.\n",
      "AI: 반갑습니다, 김성환님! 무엇을 도와드릴까요?\n",
      "=========================================================\n",
      "Human: 내 이름을 불러줘.\n",
      "AI: 김성환님!\n",
      "=========================================================\n",
      "Human: 한국음식 3개를 목록형태로 알려줘.\n",
      "AI: 1. 김치찌개  \n",
      "2. 비빔밥  \n",
      "3. 불고기\n",
      "=========================================================\n",
      "Human: 두번째 음식의 요리법을 알려줘.\n",
      "AI: 비빔밥 요리법:\n",
      "\n",
      "1. 밥을 준비하고, 시금치, 당근, 버섯, 콩나물 등 각종 나물을 볶아 준비합니다.\n",
      "2. 그릇에 밥을 담고, 볶은 나물과 고기를 고명으로 올립니다.\n",
      "3. 고추장과 참기름을 곁들여 잘 비비고, 계란 후라이를 올려서 완성합니다.\n",
      "=========================================================\n",
      "Human: .\n",
      "AI: 무엇을 도와드릴까요?\n",
      "=========================================================\n"
     ]
    }
   ],
   "source": [
    "query = input(\"질문:\")\n",
    "while True:\n",
    "    if query == \"!q\":\n",
    "        break\n",
    "    # 모델에 질문\n",
    "    result = chain.invoke({\"query\":query})\n",
    "    print(\"Human:\", query)\n",
    "    print(\"AI:\", result['text'])\n",
    "    print(\"=========================================================\")\n",
    "    # 다음 질문 입력\n",
    "    query = input(\"질문:\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "89383487",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[SystemMessage(content='The human greets the AI, which responds warmly and asks how it can assist. The human inquires about three memory classes in LangChain that remember conversation content. The AI explains there are three types: \\n\\n1. **ConversationBufferMemory**, which sequentially stores all inputs and outputs to maintain conversation context.\\n2. **ConversationSummaryMemory**, which summarizes and stores key information from the conversation for efficient memory management, especially in longer dialogues.\\n3. **CombinedMemory**, which integrates multiple memory classes to retain both detailed and summarized information for a richer conversation experience.\\n\\nThese memory classes help LangChain\\'s conversational AI effectively remember and generate responses during interactions. The human then asks the AI to explain the second class, and the AI responds by clarifying that \"second class\" can vary in meaning based on context. Upon the human\\'s further request in Korean for an explanation of the second memory class, the AI explains that it usually refers to **RAM (Random Access Memory)**, emphasizing its characteristics such as volatility, speed, capacity, and form. RAM is crucial for computer performance, as it temporarily stores data and programs while they are in use.', additional_kwargs={}, response_metadata={})]\n"
     ]
    }
   ],
   "source": [
    "pprint(memory.load_memory_variables({})['history'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd1002a4-cd88-4883-9a3e-622b693049c4",
   "metadata": {},
   "source": [
    "## LCEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "6b2da59d-8ad2-4573-9615-4fa6c831488e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.runnables import RunnablePassthrough, chain\n",
    "\n",
    "prompt_template = ChatPromptTemplate(\n",
    "    [\n",
    "        (\"system\", \"답변은 세 문장 이하로 간결하게 대답해줘.\"),\n",
    "        MessagesPlaceholder(\"history\"), # varable_name -> memory_key와 동일한 값으로 지정.\n",
    "        (\"human\", \"{query}\")\n",
    "    ]\n",
    ")\n",
    "\n",
    "model = ChatOpenAI(model='gpt-4o-mini')\n",
    "output_parser = StrOutputParser()\n",
    "memory = ConversationSummaryBufferMemory(\n",
    "    llm=model,\n",
    "    max_token_limit=200,\n",
    "    return_messages=True,\n",
    "    memory_key=\"history\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64698490-3786-4155-821c-b0626a545f27",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_memory(input):\n",
    "    # RunnablePassThrough.assign(key=함수) 에 넣어줄 함수.\n",
    "    # input: RunnablePassThrough.invoke(입력값) 의 입력값을 받는 파라미터.\n",
    "    ##### memory에서 저장된 대화 내역을 반환하는 함수.\n",
    "    return memory.load_memory_variables({})[\"history\"]\n",
    "\n",
    "@chain\n",
    "def question_chain(query):\n",
    "    # chain.invoke({\"query\":query})\n",
    "    # 입력: {\"query\":query} -> {\"query\":query, \"history\":load_memory()}\n",
    "    ### 메모리의 history를 추가해서 프롬프트에 전달 (RunnablePassThrough.assign())\n",
    "    chain = (RunnablePassthrough.assign(history=load_memory) \n",
    "            | prompt_template\n",
    "            | model\n",
    "            | output_parser)\n",
    "    # chain을 이용해 질문 요청 -> 응답\n",
    "    result = chain.invoke({\"query\":query})\n",
    "    # 질문과 응답을 메모리에 저장. - 문자열로 저장.\n",
    "    memory.save_context(inputs={\"human\":query}, outputs={\"ai\":result})\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd71fcd7-74bc-4b68-8ae7-856469ceb6f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = question_chain.invoke(\"한국의 유명한 위인 세명을 알려주세요.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "6986a6a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "세종대왕, 이순신, 김구가 한국의 유명한 위인입니다.\n"
     ]
    }
   ],
   "source": [
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "e702cb5d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "이순신은 1545년 4월 28일에 태어났습니다.\n"
     ]
    }
   ],
   "source": [
    "result = question_chain.invoke(\"두번째 사람은 언제 태어났나?\")\n",
    "print(result)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "langchain",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
