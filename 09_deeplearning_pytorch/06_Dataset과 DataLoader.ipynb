{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# Dataset 과 DataLoader\n",
    "\n",
    "-   딥러닝 모델을 학습시키고 평가할때 제공할 데이터셋을 관리하기 위한 클래스.\n",
    "    -   `Dataset`은 데이터셋을 관리하고 `DataLoader`는 Model에 데이터를 제공하는 것을 관리한다.\n",
    "-   **torch.utils.data.Dataset**\n",
    "    -   원본 데이터셋(input/output dataset)의 위치를 가지고 있으면서 indexing으로 데이터를 **하나씩 제공**한다.\n",
    "        -   제공시 data augmentation등 원본데이터를 변환해서 제공 할 수 있다.\n",
    "    -   subscriptable, iterable 타입.\n",
    "        > **subscriptable타입**: indexing을 이용해 원소 조회가 가능한 타입  \n",
    "        > Dataset은 **slicing과 fancy indexing은 지원하지 않는다.** 즉 한번에 여러개 데이터조회를 지원하지 않는다.\n",
    "-   **torch.utils.data.DataLoader**\n",
    "    -   Dataset이 제공하는 데이터를 batch size 단위 묶어서 모델에 제공하기 위한 객체.\n",
    "        -   iterable 타입\n",
    "    -   Dataset이 가지고 있는 **데이터를 모델에 어떻게 제공**할 지 batch size, shuffle 여부 등을 설정한다.\n",
    "-   **Dataset과 DataLoader 관계**\n",
    "    -   **Dataset은** raw data를 하나씩 읽어서 제공하는 기능만 제공한다.\n",
    "        -   **데이터를 읽어오는 것이 목적**\n",
    "    -   **DataLoader는** Dataset에 데이터를 모델에 주입할 batch 크기 만큼 가져오는 역할을 한다.\n",
    "        -   **데이터를 model에 제공하는 것이 목적**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Built-in Dataset\n",
    "\n",
    "-   파이토치는 분야별 공개 데이터셋을 종류별로 torchvision, torchtext, torchaudio 모듈을 통해 제공한다.\n",
    "-   모든 built-in dataset은 [`torch.utils.data.Dataset`](https://pytorch.org/docs/stable/data.html#torch.utils.data.Dataset)의 하위클래스로 구현되있다.\n",
    "    -   [computer vision dataset](https://pytorch.org/vision/stable/datasets.html)\n",
    "    -   [audio dataset](https://pytorch.org/audio/stable/datasets.html)\n",
    "    -   [text dataset](https://pytorch.org/text/stable/datasets.html)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Image Built-in dataset Loading\n",
    "\n",
    "torchvision 모듈을 통해 다양한 오픈소스 이미지 데이터셋을 loading할 수 있는 Dataset 클래스를 제공한다.\n",
    "\n",
    "-   각 Dataset 클래스의 주요 매개변수 (클래스들 마다 약간의 차이가 있다.)\n",
    "    -   **root**: str\n",
    "        -   Raw data를 저장할 디렉토리 경로\n",
    "    -   **train**: bool\n",
    "        -   True일경우 Train set을 False일 경우 Test set을 load\n",
    "    -   **download**: bool\n",
    "        -   True이면 root에 지정된 경로에 raw 데이터를 인터셋에서 download할지 여부. 이미 저장되 있는 경우 download하지 않는다.\n",
    "    -   **transform**: function\n",
    "        -   Loading한 이미지를 변환하는 function.\n",
    "            -   Normalization이나 data Agumentation 처리를 한다.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TODO: CIFAR10 Dataset loading\n",
    "\n",
    "-   CIFAR10 Built-in dataset 을 LOADING 후 다음을 확인하시오.\n",
    "    1. Dataset loading\n",
    "    1. train dataset, test dataset의 데이터 개수 확인\n",
    "    1. class index - class name 확인\n",
    "    1. train set의 이미지 5장을 출력. label의 이름을 title로 출력.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### transform 매개변수를 이용한 데이터전처리\n",
    "\n",
    "-   Dataset 생성할 때 전달하는 함수로 원본 영상 데이터를 모델에 주입(feeding)하기 전 **전처리 과정을 정의한다.**\n",
    "    -   Data Pipeline을 구성하는 함수\n",
    "-   매개변수로 input data 한개를 입력받아 처리한 결과를 반환하도록 구현한다.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-24T10:48:13.851346Z",
     "start_time": "2023-05-24T10:48:13.831036Z"
    }
   },
   "source": [
    "### torchvision.transforms.ToTensor\n",
    "\n",
    "-   PIL Image나 NumPy ndarray 를 FloatTensor(float32) 로 변환하고, 이미지의 픽셀의 크기(intensity) 값을 \\[0., 1.\\] 범위로 비례하여 조정한다.\n",
    "-   Image 의 shape을 (channel, height, width) 로 변경한다.\n",
    "-   https://pytorch.org/vision/stable/transforms.html\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### transform.Normalize\n",
    "\n",
    "-   채널별로 지정한 평균을 뺀 뒤 지정한 표준편차로 나누어서 정규화를 진행한다.\n",
    "-   ToTensor()로 변환된 데이터를 받아서 추가 변환\n",
    "    -   여려 변환 순서대로 한번에 할 경우 `torchvision.transforms.Compose` 클래스를 이용해서 묶어준다.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DataLoader 생성\n",
    "\n",
    "-   DataLoader\n",
    "    -   모델이 학습하거나 추론할 때 Dataset의 데이터를 모델에 제공해준다. (feeding)\n",
    "    -   initalizer속성\n",
    "        -   dataset: 값을 제공하는 Dataset 타입 객체\n",
    "        -   batch_size: 한번에 값을 제공할 batch 크기\n",
    "        -   shuffle: 에폭마다 데이터셋을 섞을 지 여부 (default: False)\n",
    "        -   drop_last: 마지막 배치의 데이터개수가 batch_size 설정보다 적을 경우 모델에 제공하지 않는다.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Custom Dataset 구현\n",
    "\n",
    "1. `torch.utils.data.Dataset` 클래스를 상속한 클래스를 정의한다.\n",
    "2. `__init__(self, ...)`\n",
    "    - DataSet객체 생성시 필요한 설정들을 초기화 한다.\n",
    "    - ex) Data저장 경로, transform 설정 여부 등\n",
    "3. `__len__(self)`\n",
    "    - 총 데이터 수를 반환하도록 구현한다.\n",
    "    - DataLoader가 Batch 생성할 때 사용한다.\n",
    "4. `__getitem__(self, index)`\n",
    "    - index의 Data point를 반환한다.\n",
    "    - input(X), output(y) 를 튜플로 반환한다.\n",
    "    - transform이 있을 경우 변환처리한 input을 반환한다.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## OxfordPet Dataset 생성\n",
    "\n",
    "-   https://www.robots.ox.ac.uk/~vgg/data/pets/\n",
    "-   개,고양이 37가지 품종\n",
    "-   품종별로 200장 정도씩 구성됨. (품종별로 이미지 개수는 다르다)\n",
    "-   목표\n",
    "    -   train: 70%, validation: 20%, test: 10%\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### index_to_class, class_to_index 생성\n",
    "\n",
    "-   **index**: class index 번호(0, 1, 2), **class**: class 이름 (dog, cat, ..)\n",
    "-   **index_to_class**: class들을 가지는 리스트. index(0, 1, ..)로 class 조회\n",
    "    -   index를 주면 class 이름을 반환\n",
    "-   **class_to_index**: key: 클래스이름, value: index -> class이름 넣으면 index 반환\n",
    "    -   class 이름을 주면 index를 반환\n",
    "-   Oxford PET - 파일명이 class\n",
    "    -   대문자로 시작: 고양이, 소문자로 시작: 개\n",
    "    -   파일명: 품종\\_번호.jpg\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## torchvision.datasets.ImageFolder 이용\n",
    "\n",
    "-   영구저장장치(HDD)에 파일로 저장된 image들을 쉽게 로딩할 수 있도록 한다.\n",
    "-   train/validation/test 데이터셋을 저장하는 디렉토리에 class 별로 디렉토리를 만들고 이미지를 저장한다.\n",
    "\n",
    "![img](figures/06_image_folder_dir.png)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# gdown: google drive 의 파일을 다운로드 하는 라이브러리.\n",
    "!pip install gdown --upgrade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from zipfile import ZipFile\n",
    "import gdown\n",
    "\n",
    "\n",
    "def down_extract():\n",
    "    os.makedirs(\"data\", exist_ok=True)\n",
    "    url = \"https://drive.google.com/uc?id=1YIxDL0XJhhAMdScdRUfDgccAqyCw5-ZV\"\n",
    "    fname = \"data/cats_and_dogs_small.zip\"\n",
    "\n",
    "    gdown.download(url, fname, quiet=False)\n",
    "\n",
    "    # zipfile모듈: Zip 압축파일을 다루는 모듈(압축하기, 풀기)\n",
    "    from zipfile import ZipFile\n",
    "\n",
    "    # 압축풀기: ZipFile(압축파일경로).extractall(풀경로) # 디렉토리 없으면 생성해 준다.\n",
    "    with ZipFile(fname) as zipFile:\n",
    "        zipFile.extractall(os.path.join(\"data\", \"cats_and_dogs_small\"))\n",
    "\n",
    "\n",
    "down_extract()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 메모리상의 Tensor, ndarray 타입의 데이터를 이용해 Dataset생성\n",
    "\n",
    "-   torch.utils.data.TensorDataset 이용\n",
    "-   parameter\n",
    "    -   input: Tensor\n",
    "    -   output: Tensor\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 모델 성능 평가를 위한 데이터셋 분리\n",
    "\n",
    "-   **Train 데이터셋 (훈련/학습 데이터셋)**\n",
    "    -   모델을 학습시킬 때 사용할 데이터셋.\n",
    "-   **Validation 데이터셋 (검증 데이터셋)**\n",
    "    -   모델의 성능 중간 검증을 위한 데이터셋\n",
    "-   **Test 데이터셋 (평가 데이터셋)**\n",
    "    -   모델의 성능을 최종적으로 측정하기 위한 데이터셋\n",
    "    -   **Test 데이터셋은 마지막에 모델의 성능을 측정하는 용도로 한번만 사용한다.**\n",
    "\n",
    "## 검증(validation), 평가(test) 데이터셋을 나누는 이유\n",
    "\n",
    "-   모델을 훈련하고 성능 검증했을 때 원하는 성능이 나오지 않으면 모델의 여러 설정(하이퍼파라미터)들을 수정한 뒤에 다시 훈련시키고 검증을 하게 된다. 그리고 원하는 성능이 나올때 까지 설정변경->훈련->검증을 반복하게 된다. 이 작업이 **모델링(Modeling)** 이다.\n",
    "-   위 사이클을 반복하게 되면 검증 결과를 바탕으로 설정을 변경하게 되므로 검증 할 때 사용한 데이터셋(Test set)에 모델이 맞춰서 훈련하는 것과 동일한 효과를 내게 된다.(설정을 변경하는 이유가 Test set에 대한 결과를 좋게 만들기 위해 변경하므로) 그래서 Train dataset과 Test dataset 두 개의 데이터셋만 사용하게 되면 **모델의 성능을 제대로 평가할 수 없게 된다.** 그래서 데이터셋을 train set, validation set, test set으로 나눠 train set 와 validation set을 사용해 훈련과 검증을 해 모델을 최적화 한 뒤 마지막에 test set으로 최종 평가를 한다.\n",
    "\n",
    "> -   **(Parameter)머신러닝 모델 파라미터**\n",
    ">     -   성능에 영향을 주는 값으로 최적화의야 하는 대상내는 값을 찾아야 한다.\n",
    ">         -   **하이퍼파라미터(Hyper Parameter)**\n",
    ">             -   사람이 직접 설정해야하는 파라미터 값으로 주로 어떻게 모델을 학습시킬지에 대한 모델설정 값이다.\n",
    ">             -   딥러닝에서는 학습률, Epoch수, batch size, optimizer, loss 함수 등 다양한 하이퍼파라미터가 있다.\n",
    ">         -   **파라미터(Parameter)**\n",
    ">             -   모델의 함수를 데이터에 맞추기 위한 값으로 학습을 통해 찾는 변수.\n",
    ">             -   딥러닝 모델에서는 weight와 bias 가 파라미터다.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset 분리\n",
    "\n",
    "### torch.utils.data.Subset을 이용\n",
    "\n",
    "-   Dataset의 일부를 가지는 부분집합 데이터셋을 생성\n",
    "-   주로 사용하는 곳\n",
    "    1. 데이터 셋을 분리\n",
    "    2. 전체 데이터 셋에서 일부 데이터를 추출 할 때\n",
    "    3. 데이터셋에서 특정 데이터만 골라서 추출할 때 (ex: 특정 class만 추출하는 경우)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### random_split() 함수 이용\n",
    "\n",
    "-   Dataset객체와 나눌 데이터셋들의 원소개수를 리스트로 묶어서 전달하면 Shuffle후 나눈뒤 그 결과를 Subset객체들을 리스트에 담아 반환한다.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "455.111px"
   },
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
