{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# LinearRegression from Scratch\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 구현할 것\n",
    "- 공부시간과 성적간의 관계를 모델링한다.\n",
    "    - **머신러닝 모델(모형)이란** 수집한 데이터를 기반으로 입력값(Feature)와 출력값(Target)간의 관계를 하나의 공식으로 정의한 함수이다. 그 공식을 찾는 과정을 **모델링**이라고 한다.\n",
    "    - 이 예제에서는 공부한 시험시간으로 점수를 예측하는 모델을 정의한다.\n",
    "    - 입력값과 출력값 간의 관계를 정의할 수있는 다양한 함수(공식)이 있다. 여기에서는 딥러닝과 관계가 있는 **Linear Regression** 을 사용해본다.\n",
    "\n",
    "# 데이터 확인\n",
    "- 입력데이터: 공부시간\n",
    "- 출력데이터: 성적\n",
    "\n",
    "|공부시간|점수|\n",
    "|-|-|\n",
    "|1|20|\n",
    "|2|40|\n",
    "|3|60|\n",
    "\n",
    "우리가 수집한 공부시간과 점수 데이터를 바탕으로 둘 간의 관계를 식으로 정의 할 수 있으면 **내가 몇시간 공부하면 점수를 얼마 받을 수 있는지 예측할 수 있게 된다.**   \n",
    "수집한 데이터를 기반으로 앞으로 예측할 수있는 모형을 만드는 것이 머신러닝 모델링이다.\n",
    "\n",
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 학습(훈련) 데이터셋 만들기\n",
    "- 모델을 학습시키기 위한 데이터셋을 구성한다.\n",
    "- 입력데이터와 출력데이터을 각각 다른 행렬로 구성한다.\n",
    "- 하나의 데이터 포인트의 입력/출력 값은 같은 index에 정의한다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 선형회귀 (Linear Regression)\n",
    "- Feature들의 가중합을 이용해 Target을 추정한다.\n",
    "- Feature에 곱해지는 가중치(weight)들은 각 Feature가 Target 얼마나 영향을 주는지 영향도가 된다.\n",
    "    - 음수일 경우는 target값을 줄이고 양수일 경우는 target값을 늘린다.\n",
    "    - 가중치가 0에 가까울 수록 target에 영향을 주지 않는 feature이고 0에서 멀수록 target에 많은 영향을 준다.\n",
    "- 모델 학습과정에서 가장 적절한 Feature의 가중치를 찾아야 한다.\n",
    "      \n",
    "\n",
    "\\begin{align}\n",
    "&\\large \\hat{y} = W\\cdot X + b\\\\\n",
    "&\\small \\hat{y}: \\text{모델추정값}\\\\\n",
    "&\\small W: \\text{가중치}\\\\\n",
    "&\\small X: \\text{Feature(입력값)}\\\\\n",
    "&\\small b: \\text{bias(편향)}\n",
    "\\end{align}\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train dataset 구성\n",
    "- Train data는 feature(input)와 target(output) 각각 2개의 행렬로 구성한다.\n",
    "- Feature의 행은 관측치(개별 데이터)를 열을 Feature(특성, 변수)를 표현한다. 이 문제에서는 `공부시간` 1개의 변수를 가진다.\n",
    "- Target은 모델이 예측할 대상으로 행은 개별 관측치, 열은 각 항목에 대한 정답으로 구성한다.   \n",
    "  이 문제에서 예측할 항목은 `시험점수` 한개이다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((3, 1), (3, 1))"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "study_hours = [[1], [2], [3]]\n",
    "scores = [[20],[40],[60]]\n",
    "\n",
    "np.shape(study_hours), np.shape(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tensor로 정의\n",
    "import torch\n",
    "X_train = torch.tensor(study_hours, dtype=torch.float32)\n",
    "y_train = torch.tensor(scores, dtype=torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 1]) torch.Size([3, 1])\n",
      "torch.float32 torch.float32\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'torch.FloatTensor'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(X_train.shape, y_train.size())\n",
    "print(X_train.dtype, y_train.dtype)\n",
    "X_train.type()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 파라미터 (weight, bias) 정의\n",
    "- 학습대상/최적화 대상"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 1])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 1]) torch.Size([1])\n",
      "tensor([[-0.6871]], requires_grad=True) tensor([-1.5204], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "# torch.manual_seed(0)\n",
    "# y_pred = X_train * weight + bias\n",
    "weight = torch.randn(1, 1, requires_grad=True) #shape: (1:X의 feature개수, 1:출력값(예측)의 개수)\n",
    "bias = torch.randn(1, requires_grad=True)\n",
    "\n",
    "print(weight.shape, bias.shape)\n",
    "print(weight, bias)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-2.2075],\n",
       "        [-2.8946],\n",
       "        [-3.5817]], grad_fn=<AddBackward0>)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 추론 (w * x + b)\n",
    "pred = X_train @ weight + bias\n",
    "pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[20.],\n",
       "        [40.],\n",
       "        [60.]])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-20.8624],\n",
       "        [-41.9991],\n",
       "        [-63.1358]], grad_fn=<SubBackward0>)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred - y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(2125.2480, grad_fn=<MeanBackward0>)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 오차 계산 - MSE\n",
    "loss = torch.mean((y_train - pred) ** 2)\n",
    "loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# weight, bias의 gradient계산\n",
    "loss.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[-199.1611]]), tensor([-85.7891]))"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weight.grad, bias.grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# weight 변경(update)\n",
    "## new_weight = weight - weight.grad * learning_rate\n",
    "lr = 0.01\n",
    "new_weight = weight.data - weight.grad * lr\n",
    "new_bias = bias.data - bias.grad * lr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1.3045]]) tensor([[-0.6871]])\n",
      "tensor([-0.6625]) tensor([-1.5204])\n"
     ]
    }
   ],
   "source": [
    "print(new_weight.data, weight.data)\n",
    "print(new_bias.data, bias.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred2 = X_train @ new_weight + new_bias\n",
    "loss2 = torch.mean((y_train - pred2)**2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "이전 loss: tensor(2227.4529, grad_fn=<MeanBackward0>)\n",
      "update후 loss: tensor(1762.5054)\n"
     ]
    }
   ],
   "source": [
    "print(\"이전 loss:\", loss)\n",
    "print(\"update후 loss:\", loss2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 모델링"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "weight = torch.randn(1, 1, requires_grad=True)\n",
    "bias = torch.randn(1, requires_grad=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 추론하는 함수 (예측 모델)\n",
    "def linear_model(X):\n",
    "    return X @ weight + bias\n",
    "\n",
    "# 오차계산함수 (MSE)\n",
    "def loss_fn(pred, y):\n",
    "    return torch.mean((pred-y)**2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 학습\n",
    "1. 모델을 이용해 추정한다.\n",
    "   - pred = model(input)\n",
    "1. loss를 계산한다.\n",
    "   - loss = loss_fn(pred, target)\n",
    "1. 계산된 loss를 파라미터에 대해 미분하여 계산한 gradient 값을 각 파라미터에 저장한다.\n",
    "   - loss.backward()\n",
    "1. optimizer를 이용해 파라미터를 update한다.\n",
    "   - optimizer.step()  \n",
    "1. 파라미터의 gradient(미분값)을 0으로 초기화한다.\n",
    "   - optimizer.zero_grad()\n",
    "- 위의 단계를 반복한다.   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1/2000] loss: 1982.44788\n",
      "[101/2000] loss: 4.13011\n",
      "[201/2000] loss: 2.55215\n",
      "[301/2000] loss: 1.57707\n",
      "[401/2000] loss: 0.97453\n",
      "[501/2000] loss: 0.60220\n",
      "[601/2000] loss: 0.37212\n",
      "[701/2000] loss: 0.22995\n",
      "[801/2000] loss: 0.14209\n",
      "[901/2000] loss: 0.08781\n",
      "[1001/2000] loss: 0.05426\n",
      "[1101/2000] loss: 0.03353\n",
      "[1201/2000] loss: 0.02072\n",
      "[1301/2000] loss: 0.01280\n",
      "[1401/2000] loss: 0.00791\n",
      "[1501/2000] loss: 0.00489\n",
      "[1601/2000] loss: 0.00302\n",
      "[1701/2000] loss: 0.00187\n",
      "[1801/2000] loss: 0.00115\n",
      "[1901/2000] loss: 0.00071\n",
      "[2000/2000] loss: 0.00044\n"
     ]
    }
   ],
   "source": [
    "epochs = 2000 # 반복횟수\n",
    "lr = 0.01\n",
    "# lr = 1000\n",
    "# lr = 0.00000001\n",
    "for epoch in range(epochs):\n",
    "    # 1. 추정\n",
    "    pred = linear_model(X_train)\n",
    "    # 2. loss 계산\n",
    "    loss = loss_fn(pred, y_train)\n",
    "    # 3. parameter들의 gradient를 계산 (loss에대한 변화)\n",
    "    loss.backward()\n",
    "    # 4. parameter update\n",
    "    weight.data = weight.data - weight.grad * lr # .data:현재값, .grad: gradient계산값.\n",
    "    bias.data = bias.data - bias.grad * lr\n",
    "    # 5. gradient 초기화\n",
    "    weight.grad = None\n",
    "    bias.grad = None\n",
    "    ## 로그 - loss를 출력\n",
    "    if epoch % 100 == 0 or epoch == (epochs-1):\n",
    "        print(f\"[{epoch+1}/{epochs}] loss: {loss.item():.5f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[19.9979]]), tensor([0.0047]))"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weight.data, bias.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[99.9944],\n",
       "        [79.9964],\n",
       "        [40.0006]], grad_fn=<AddBackward0>)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_X = torch.tensor([[5], [4], [2]], dtype=torch.float32)\n",
    "linear_model(new_X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 다중 입력, 다중 출력\n",
    "- 다중입력: Feature가 여러개인 경우\n",
    "- 다중출력: Output 결과가 여러개인 경우\n",
    "\n",
    "다음 가상 데이터를 이용해 사과와 오렌지 수확량을 예측하는 선형회귀 모델을 정의한다.  \n",
    "[참조](https://www.kaggle.com/code/aakashns/pytorch-basics-linear-regression-from-scratch)\n",
    "\n",
    "\n",
    "|온도(F)|강수량(mm)|습도(%)|사과생산량(ton)|오렌지생산량|\n",
    "|-|-|-|-:|-:|\n",
    "|73|67|43|56|70|\n",
    "|91|88|64|81|101|\n",
    "|87|134|58|119|133|\n",
    "|102|43|37|22|37|\n",
    "|69|96|70|103|119|\n",
    "\n",
    "```\n",
    "사과수확량  = w11 * 온도 + w12 * 강수량 + w13 * 습도 + b1\n",
    "오렌지수확량 = w21 * 온도 + w22 * 강수량 + w23 *습도 + b2\n",
    "```\n",
    "\n",
    "- `온도`, `강수량`, `습도` 값이 **사과**와, **오렌지 수확량**에 어느정도 영향을 주는지 가중치를 찾는다.\n",
    "    - 모델은 사과의 수확량, 오렌지의 수확량 **두개의 예측결과를 출력**해야 한다.\n",
    "    - 사과에 대해 예측하기 위한 weight 3개와 오렌지에 대해 예측하기 위한 weight 3개 이렇게 두 묶음, 총 6개의 weight를 정의하고 학습을 통해 가장 적당한 값을 찾는다.\n",
    "        - `개별 과일를 예측하기 위한 weight들 @ feature들` 의 계산 결과를  **Node, Unit, Neuron** 이라고 한다.\n",
    "        - 두 과일에 대한 Unit들을 묶어서 **Layer** 라고 한다.\n",
    "- 목적은 우리가 수집한 train 데이터셋을 이용해 **정확한 예측을 위한 weight와 bias 들**을 찾는 것이다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train Dataset\n",
    "- Train data는 feature(input)와 target(output) 각각 2개의 행렬로 구성한다.\n",
    "- Feature의 행은 관측치(개별 데이터)를 열을 Feature(특성, 변수)를 표현한다. 이 문제에서는 `온도, 강수량, 습도` 세개의 변수를 가진다.\n",
    "- Target은 모델이 예측할 대상으로 행은 개별 관측치, 열은 각 항목에 대한 정답으로 구성한다. 이 문제에서 예측할 항목은 `사과수확량, 오렌지 수확량` 2개의 값이다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  input: 생산환경 (temp, rainfall, humidity) : (5, 3)\n",
    "environs = [\n",
    "    [73, 67, 43], \n",
    "    [91, 88, 64], \n",
    "    [87, 134, 58], \n",
    "    [102, 43, 37], \n",
    "    [69, 96, 70]\n",
    "]\n",
    "\n",
    "# Targets: 생산량 - (apples, oranges) - (5, 2)\n",
    "apple_orange_output = [\n",
    "    [56, 70], \n",
    "    [81, 101], \n",
    "    [119, 133], \n",
    "    [22, 37], \n",
    "    [103, 119]\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([5, 3]), torch.Size([5, 2]))"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Dataset을 torch.Tensor로 생성\n",
    "X = torch.tensor(environs, dtype=torch.float32)\n",
    "y = torch.tensor(apple_orange_output, dtype=torch.float32)\n",
    "X.shape, y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 73.,  67.,  43.],\n",
       "        [ 91.,  88.,  64.],\n",
       "        [ 87., 134.,  58.],\n",
       "        [102.,  43.,  37.],\n",
       "        [ 69.,  96.,  70.]])"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## weight와 bias\n",
    "- weight: 각 feature들이 생산량에 영향을 주었는지의 가중치로 feature에 곱해줄 값.\n",
    "    - 사과, 오렌지의 생산량을 구해야 하므로 가중치가 두개가 된다.\n",
    "    - weight의 shape: `(3, 2)`\n",
    "- bias는 모든 feature들이 0일때 생산량이 얼마일지를 나타내는 값으로 feature와 weight간의 가중합 결과에 더해줄 값이다.\n",
    "    - 사과, 오렌지의 생산량을 구하므로 bias가 두개가 된다.\n",
    "    - bias의 shape: `(2, )`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Linear Regression model\n",
    "모델은 weights `w`와 inputs `x`의 내적(dot product)한 값에 bias `b`를 더하는 함수.\n",
    "\n",
    "$$\n",
    "\\hspace{2.5cm} X \\hspace{1.1cm} \\cdot \\hspace{1.2cm} W \\hspace{1.2cm}  + \\hspace{1cm} b \\hspace{2cm}\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\left[ \\begin{array}{cc}\n",
    "73 & 67 & 43 \\\\\n",
    "91 & 88 & 64 \\\\\n",
    "\\vdots & \\vdots & \\vdots \\\\\n",
    "69 & 96 & 70\n",
    "\\end{array} \\right]\n",
    "%\n",
    "\\cdot\n",
    "%\n",
    "\\left[ \\begin{array}{cc}\n",
    "w_{11} & w_{21} \\\\\n",
    "w_{12} & w_{22} \\\\\n",
    "w_{13} & w_{23}\n",
    "\\end{array} \\right]\n",
    "%\n",
    "+\n",
    "%\n",
    "\\left[ \\begin{array}{cc}\n",
    "b_{1} & b_{2} \\\\\n",
    "b_{1} & b_{2} \\\\\n",
    "\\vdots & \\vdots \\\\\n",
    "b_{1} & b_{2} \\\\\n",
    "\\end{array} \\right]\n",
    "$$\n",
    "\n",
    "\n",
    "<center style=\"font-size:0.9em\">\n",
    "$w_{11},\\,w_{12},\\,w_{13}$: 사과 생산량 계산시 각 feature들(생산환경)에 곱할 가중치   <br>\n",
    "$w_{21},\\,w_{22},\\,w_{23}$: 오렌지 생산량 계산시 각 feature들(생산환경)에 곱할 가중치    \n",
    "</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center>\n",
    "<img src=\"figures/3_unit_layer.png\">\n",
    "</center>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([3, 2]), torch.Size([2]))"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# weight/bias 를 정의 -> 초기값은 random 값을 이용해서 생성.\n",
    "weight = torch.randn(3, 2, requires_grad=True)\n",
    "bias = torch.randn(2, requires_grad=True)\n",
    "\n",
    "weight.size(), bias.size()\n",
    "# weight: (3:input feature개수  ,  2:output 개수)\n",
    "# bias: (2:output 개수, )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.1575,  0.9041],\n",
       "        [ 0.9811, -0.0167],\n",
       "        [-0.6411, -0.6732]], requires_grad=True)"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.5808, 0.8419], requires_grad=True)"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 73.,  67.,  43.],\n",
       "        [ 91.,  88.,  64.],\n",
       "        [ 87., 134.,  58.],\n",
       "        [102.,  43.,  37.],\n",
       "        [ 69.,  96.,  70.]])"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 한번 학습(최적화)\n",
    "## 추론\n",
    "pred = X @ weight + bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[27.2482, 36.7768],\n",
       "        [31.5527, 38.5633],\n",
       "        [81.1584, 38.2158],\n",
       "        [ 2.9820, 67.4377],\n",
       "        [39.0194, 14.4992]], grad_fn=<AddBackward0>)"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 56.,  70.],\n",
       "        [ 81., 101.],\n",
       "        [119., 133.],\n",
       "        [ 22.,  37.],\n",
       "        [103., 119.]])"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(3499.1926, grad_fn=<MeanBackward0>)"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## loss 계산(MSE)\n",
    "loss = torch.mean((pred - y)**2) # 전체 추론한 결과의 평균오차를 계산.\n",
    "loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loss를 가지고 파라미터들(weight들, bias들)의 gradient 계산.\n",
    "loss.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.1575,  0.9041],\n",
       "        [ 0.9811, -0.0167],\n",
       "        [-0.6411, -0.6732]])"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weight.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-3249.0632, -4091.8333],\n",
       "        [-3661.6863, -5828.9434],\n",
       "        [-2355.6167, -3422.1777]])"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weight.grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([0.5808, 0.8419]), tensor([-39.8079, -52.9014]))"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bias.data, bias.grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 파라미터 업데이트\n",
    "lr = 0.00001\n",
    "weight.data = weight.data - lr * weight.grad\n",
    "bias.data = bias.data - lr * bias.grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 업데이트된 파라미터로 추정 -> loss 계산\n",
    "pred2 = X @ weight + bias\n",
    "loss2 = torch.mean((pred2 - y)**2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3499.192626953125 2661.15185546875\n"
     ]
    }
   ],
   "source": [
    "print(loss.item(), loss2.item())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  모델링"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "weight = torch.randn(3, 2, requires_grad=True)\n",
    "bias = torch.randn(2, requires_grad=True)\n",
    "\n",
    "## 모델 정의\n",
    "def model(X):\n",
    "    return X @ weight + bias\n",
    "\n",
    "## loss 함수(MSE)\n",
    "def loss_fn(pred, y):\n",
    "    return torch.mean((pred - y)**2) # 전체 오차의 평균."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0001/5000] - 0.54958\n",
      "[0101/5000] - 0.54940\n",
      "[0201/5000] - 0.54924\n",
      "[0301/5000] - 0.54911\n",
      "[0401/5000] - 0.54901\n",
      "[0501/5000] - 0.54892\n",
      "[0601/5000] - 0.54884\n",
      "[0701/5000] - 0.54878\n",
      "[0801/5000] - 0.54873\n",
      "[0901/5000] - 0.54869\n",
      "[1001/5000] - 0.54865\n",
      "[1101/5000] - 0.54862\n",
      "[1201/5000] - 0.54860\n",
      "[1301/5000] - 0.54858\n",
      "[1401/5000] - 0.54856\n",
      "[1501/5000] - 0.54854\n",
      "[1601/5000] - 0.54853\n",
      "[1701/5000] - 0.54852\n",
      "[1801/5000] - 0.54851\n",
      "[1901/5000] - 0.54850\n",
      "[2001/5000] - 0.54850\n",
      "[2101/5000] - 0.54849\n",
      "[2201/5000] - 0.54849\n",
      "[2301/5000] - 0.54848\n",
      "[2401/5000] - 0.54848\n",
      "[2501/5000] - 0.54848\n",
      "[2601/5000] - 0.54848\n",
      "[2701/5000] - 0.54847\n",
      "[2801/5000] - 0.54847\n",
      "[2901/5000] - 0.54847\n",
      "[3001/5000] - 0.54847\n",
      "[3101/5000] - 0.54846\n",
      "[3201/5000] - 0.54846\n",
      "[3301/5000] - 0.54846\n",
      "[3401/5000] - 0.54846\n",
      "[3501/5000] - 0.54846\n",
      "[3601/5000] - 0.54846\n",
      "[3701/5000] - 0.54846\n",
      "[3801/5000] - 0.54845\n",
      "[3901/5000] - 0.54845\n",
      "[4001/5000] - 0.54845\n",
      "[4101/5000] - 0.54845\n",
      "[4201/5000] - 0.54845\n",
      "[4301/5000] - 0.54845\n",
      "[4401/5000] - 0.54845\n",
      "[4501/5000] - 0.54845\n",
      "[4601/5000] - 0.54844\n",
      "[4701/5000] - 0.54844\n",
      "[4801/5000] - 0.54844\n",
      "[4901/5000] - 0.54844\n",
      "[5000/5000] - 0.54844\n"
     ]
    }
   ],
   "source": [
    "epochs = 5000\n",
    "lr = 0.00001  # 1e-5\n",
    "for epoch in range(epochs):\n",
    "    # 1. 추론\n",
    "    pred = model(X)\n",
    "    # 2. loss 계산\n",
    "    loss = loss_fn(pred, y)\n",
    "    # 3. 파라미터 들의 gradient 계산\n",
    "    loss.backward()\n",
    "    # 4. 파라미터 업데이트\n",
    "    weight.data = weight.data - lr * weight.grad\n",
    "    bias.data = bias.data - lr * bias.grad\n",
    "    # 5. gradient 초기화\n",
    "    weight.grad = None\n",
    "    bias.grad = None\n",
    "    ## 100 epoch, 마지막 epoch에서 loss를 출력 => 학습 과정 log를 출력\n",
    "    if epoch % 100 == 0 or epoch == epochs-1:\n",
    "        print(f\"[{epoch+1:04d}/{epochs}] - {loss.item():.5f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 57.4287,  70.3354],\n",
       "        [ 82.0229, 100.6778],\n",
       "        [118.6928, 132.8992],\n",
       "        [ 21.0604,  36.9963],\n",
       "        [101.9201, 119.1969]], grad_fn=<AddBackward0>)"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 새로운 데이터로 추론\n",
    "p = model(X)\n",
    "p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 56.,  70.],\n",
       "        [ 81., 101.],\n",
       "        [119., 133.],\n",
       "        [ 22.,  37.],\n",
       "        [103., 119.]])"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 3])"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_x = torch.tensor([68, 82, 56], dtype=torch.float32)\n",
    "new_x = new_x.unsqueeze(dim=0)\n",
    "new_x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[80.9965, 95.6196]], grad_fn=<AddBackward0>)"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model(new_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# pytorch built-in 모델을 사용해 Linear Regression 구현"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = torch.tensor(\n",
    "    [[73, 67, 43], \n",
    "     [91, 88, 64], \n",
    "     [87, 134, 58], \n",
    "     [102, 43, 37], \n",
    "     [69, 96, 70]], dtype=torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "targets = torch.tensor(\n",
    "    [[56, 70], \n",
    "    [81, 101], \n",
    "    [119, 133], \n",
    "    [22, 37], \n",
    "    [103, 119]], dtype=torch.float32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## nn.Linear\n",
    "Pytorch는 nn.Linear 클래스를 통해 Linear Regression 모델을 제공한다.  \n",
    "nn.Linear에 입력 feature의 개수와 출력 값의 개수를 지정하면 random 값으로 초기화한 weight와 bias들을 생성해 모델을 구성한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import torch\n",
    "\n",
    "# torch.nn.Linear(input feature개수 , output 개수)   # weight, bias, X@weight  + bias"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optimizer와 Loss 함수 정의\n",
    "- torch.optim 모듈에 다양한 Optimizer 클래스가 구현되있다.\n",
    "- torch.nn 또는 torch.nn.functional 모듈에 다양한 Loss 함수가 제공된다. 이중 mse_loss() 를 사용한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 선형회귀 모델을 정의. torch.nn.Linear 클래스\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "model = nn.Linear(3, 2)  # 3: input feature 개수, 2: output 수수\n",
    "# def model(X):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loss 함수\n",
    "loss_fn = torch.nn.functional.mse_loss # 함수 \n",
    "# loss_fn = torch.nn.MSELoss()  # 클래스 -> 객체를 생성\n",
    "# def loss_fn(pred, y):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "# optimizer (torch.optim 모듈에 정의):    weight.data = weight.data - lr * weight.grad\n",
    "optimizer = torch.optim.SGD(\n",
    "    model.parameters(), # 최적화 대상 파라미터들을 model에서 조회해서 전달.\n",
    "    lr = 0.00001,  # Learning Rage\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Parameter containing:\n",
       " tensor([[-0.4338,  0.5429, -0.2817],\n",
       "         [ 0.2112, -0.5735,  0.1724]], requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([-0.1661, -0.3176], requires_grad=True)]"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(model.parameters())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0001/5000] - 0.5096172094345093\n",
      "[0101/5000] - 0.5091460943222046\n",
      "[0201/5000] - 0.5087567567825317\n",
      "[0301/5000] - 0.5084331631660461\n",
      "[0401/5000] - 0.508165180683136\n",
      "[0501/5000] - 0.5079387426376343\n",
      "[0601/5000] - 0.5077613592147827\n",
      "[0701/5000] - 0.5076063275337219\n",
      "[0801/5000] - 0.5074799060821533\n",
      "[0901/5000] - 0.507374107837677\n",
      "[1001/5000] - 0.5072866082191467\n",
      "[1101/5000] - 0.5072098970413208\n",
      "[1201/5000] - 0.5071526765823364\n",
      "[1301/5000] - 0.5071009397506714\n",
      "[1401/5000] - 0.5070592164993286\n",
      "[1501/5000] - 0.5070251822471619\n",
      "[1601/5000] - 0.5069953203201294\n",
      "[1701/5000] - 0.5069748163223267\n",
      "[1801/5000] - 0.5069497227668762\n",
      "[1901/5000] - 0.5069342255592346\n",
      "[2001/5000] - 0.5069197416305542\n",
      "[2101/5000] - 0.5069082975387573\n",
      "[2201/5000] - 0.506901204586029\n",
      "[2301/5000] - 0.5068908929824829\n",
      "[2401/5000] - 0.5068827271461487\n",
      "[2501/5000] - 0.5068793892860413\n",
      "[2601/5000] - 0.5068731904029846\n",
      "[2701/5000] - 0.5068670511245728\n",
      "[2801/5000] - 0.5068671107292175\n",
      "[2901/5000] - 0.5068622827529907\n",
      "[3001/5000] - 0.5068596601486206\n",
      "[3101/5000] - 0.5068578124046326\n",
      "[3201/5000] - 0.5068563222885132\n",
      "[3301/5000] - 0.5068546533584595\n",
      "[3401/5000] - 0.5068530440330505\n",
      "[3501/5000] - 0.5068536400794983\n",
      "[3601/5000] - 0.5068506002426147\n",
      "[3701/5000] - 0.506851315498352\n",
      "[3801/5000] - 0.5068479180335999\n",
      "[3901/5000] - 0.5068492293357849\n",
      "[4001/5000] - 0.5068472623825073\n",
      "[4101/5000] - 0.506851851940155\n",
      "[4201/5000] - 0.506846010684967\n",
      "[4301/5000] - 0.506848156452179\n",
      "[4401/5000] - 0.5068482756614685\n",
      "[4501/5000] - 0.5068470239639282\n",
      "[4601/5000] - 0.5068460702896118\n",
      "[4701/5000] - 0.5068439841270447\n",
      "[4801/5000] - 0.5068426132202148\n",
      "[4901/5000] - 0.5068451762199402\n",
      "[5000/5000] - 0.5068451166152954\n"
     ]
    }
   ],
   "source": [
    "epochs = 5000\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    # 추론\n",
    "    pred = model(inputs)\n",
    "    # loss 계산\n",
    "    loss = loss_fn(pred, targets) # torch.nn.functional.mse_loss(pred, targets) # (모델추정값, 정답)\n",
    "    # gradient 계산\n",
    "    loss.backward()\n",
    "    # 파라미터 업데이트: optimizer.step()\n",
    "    optimizer.step()\n",
    "    # 파라미터 초기화 w.grad=None, b.grad=None\n",
    "    optimizer.zero_grad()\n",
    "    # 현재 epoch 학습 결과를 log로 출력\n",
    "    if epoch % 100 == 0 or epoch == epochs-1:\n",
    "        print(f\"[{epoch+1:04d}/{epochs}] - {loss.item()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 추론 => gradient 계산을 할 필요가 없다. ==> grad_fn을 만들 필요가 없다.\n",
    "with torch.no_grad():\n",
    "    pred = model(inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 56.,  70.],\n",
       "        [ 81., 101.],\n",
       "        [119., 133.],\n",
       "        [ 22.,  37.],\n",
       "        [103., 119.]])"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 57.1382,  70.2557],\n",
       "        [ 82.2236, 100.7036],\n",
       "        [118.6980, 132.9673],\n",
       "        [ 21.0851,  37.0220],\n",
       "        [101.9156, 119.1292]])"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 학습 로직을 함수 구현\n",
    "def train(inputs, targets, epochs, model, loss_fn, optimizer):\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        # 추론\n",
    "        pred = model(inputs)\n",
    "        # loss 계산\n",
    "        loss = loss_fn(pred, targets) # torch.nn.functional.mse_loss(pred, targets) # (모델추정값, 정답)\n",
    "        # gradient 계산\n",
    "        loss.backward()\n",
    "        # 파라미터 업데이트: optimizer.step()\n",
    "        optimizer.step()\n",
    "        # 파라미터 초기화 w.grad=None, b.grad=None\n",
    "        optimizer.zero_grad()\n",
    "        # 현재 epoch 학습 결과를 log로 출력\n",
    "        if epoch % 100 == 0 or epoch == epochs-1:\n",
    "            print(f\"[{epoch+1:04d}/{epochs}] - {loss.item()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = nn.Linear(3, 2)\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.0001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0001/5000] - 18969.671875\n",
      "[0101/5000] - 10.212318420410156\n",
      "[0201/5000] - 2.0050790309906006\n",
      "[0301/5000] - 0.7476084232330322\n",
      "[0401/5000] - 0.5549023747444153\n",
      "[0501/5000] - 0.525364339351654\n",
      "[0601/5000] - 0.5208339095115662\n",
      "[0701/5000] - 0.5201326608657837\n",
      "[0801/5000] - 0.5200199484825134\n",
      "[0901/5000] - 0.5199987888336182\n",
      "[1001/5000] - 0.5199880003929138\n",
      "[1101/5000] - 0.5199852585792542\n",
      "[1201/5000] - 0.5199781060218811\n",
      "[1301/5000] - 0.5199733972549438\n",
      "[1401/5000] - 0.5199659466743469\n",
      "[1501/5000] - 0.519959568977356\n",
      "[1601/5000] - 0.5199530124664307\n",
      "[1701/5000] - 0.5199490785598755\n",
      "[1801/5000] - 0.5199415683746338\n",
      "[1901/5000] - 0.519936203956604\n",
      "[2001/5000] - 0.5199282169342041\n",
      "[2101/5000] - 0.5199248194694519\n",
      "[2201/5000] - 0.5199151039123535\n",
      "[2301/5000] - 0.5199094414710999\n",
      "[2401/5000] - 0.5199055671691895\n",
      "[2501/5000] - 0.5198995471000671\n",
      "[2601/5000] - 0.5198938250541687\n",
      "[2701/5000] - 0.5198862552642822\n",
      "[2801/5000] - 0.5198787450790405\n",
      "[2901/5000] - 0.5198774933815002\n",
      "[3001/5000] - 0.5198687314987183\n",
      "[3101/5000] - 0.5198593139648438\n",
      "[3201/5000] - 0.5198537707328796\n",
      "[3301/5000] - 0.5198507905006409\n",
      "[3401/5000] - 0.5198450684547424\n",
      "[3501/5000] - 0.5198394656181335\n",
      "[3601/5000] - 0.5198336243629456\n",
      "[3701/5000] - 0.5198286771774292\n",
      "[3801/5000] - 0.5198220014572144\n",
      "[3901/5000] - 0.5198140144348145\n",
      "[4001/5000] - 0.519809365272522\n",
      "[4101/5000] - 0.519803524017334\n",
      "[4201/5000] - 0.5197988152503967\n",
      "[4301/5000] - 0.5197930335998535\n",
      "[4401/5000] - 0.5197843313217163\n",
      "[4501/5000] - 0.519779622554779\n",
      "[4601/5000] - 0.5197713971138\n",
      "[4701/5000] - 0.5197663307189941\n",
      "[4801/5000] - 0.5197619199752808\n",
      "[4901/5000] - 0.5197523832321167\n",
      "[5000/5000] - 0.5197480916976929\n"
     ]
    }
   ],
   "source": [
    "train(inputs, targets, 5000, model, nn.functional.mse_loss, optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
