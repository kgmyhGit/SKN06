{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Pytorch 개발 Process"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "1. **데이터 준비**\n",
    "    - Dataset 준비\n",
    "    - Dataloader 생성"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "2. **입력과 출력을 연결하는 Layer(층)으로 이뤄진 네트워크(모델)을 정의**\n",
    "    - **Sequential 방식**: 순서대로 쌓아올린 네트워크로 이뤄진 모델을 생성하는 방식\n",
    "        - layer를 순서대로 쌓은 모델을 구현할때 간단히 모델을 정의할 수 있다.\n",
    "        - layer block을 정의하는데 사용할 수 있다.\n",
    "    - **Subclass 방식**: 네트워크를 정의하는 클래스를 구현.\n",
    "        - 다양한 구조의 모델을 정의할 수 있다.\n",
    "        - inializer에서 필요한 layer들을 생성한다.\n",
    "        - forward(self, X) 메소드에 forward propagation 계산을 구현한다.\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "3. **train**\n",
    "    - train 함수, test 함수 정의"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "4. test set 최종평가"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# MNIST 이미지 분류 \n",
    "- **[MNIST](https://ko.wikipedia.org/wiki/MNIST_%EB%8D%B0%EC%9D%B4%ED%84%B0%EB%B2%A0%EC%9D%B4%EC%8A%A4) (Modified National Institute of Standards and Technology) database**\n",
    "- 흑백 손글씨 숫자 0-9까지 10개의 범주로 구분해놓은 데이터셋\n",
    "- 하나의 이미지는 28 * 28 pixel 의 크기\n",
    "- 6만개의 Train 이미지와 1만개의 Test 이미지로 구성됨."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn  # 다양한 layer/모델 들이 정의된 패키지. (Neural Network)\n",
    "from torch.utils.data import DataLoader # DataLoader 클래스 -> 모델에 데이터들을 제공하는 역할.\n",
    "from torchvision import datasets, transforms \n",
    "# torchvision 패키지(라이브러리): pytorch의 Image 전용 sub package\n",
    "### datasets(모듈): Vision(영상) 데이터셋들을 제공하는 모듈\n",
    "### transforms: 이미지(영상) 전처리 기능들을 제공하는 모듈\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.5.1+cpu'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### device 설정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n",
      "cpu\n"
     ]
    }
   ],
   "source": [
    "# 어느 Device에서 연산처리를 할지 지정. (cpu, cuda(GPU))\n",
    "# device = \"cpu\"\n",
    "print(torch.cuda.is_available())  # cuda를 사용할 수있는 환경인지 조회\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\" # 2.0이전: torch.Device(\"cuda\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n"
     ]
    }
   ],
   "source": [
    "# MAC OS  (\"cpu\", \"mps\")\n",
    "device = \"mps\" if torch.backends.mps.is_available() else \"cpu\"\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 하이퍼파라미터, 변수 설정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = 0.001 # 학습률. 0 ~ 1 실수. \n",
    "batch_size = 256  # 모델을 학습할 때 한 번에 몇개의 데이터를 제공할 지 개수.\n",
    "# step: 모델의 파라미터들을 update하는 단위.\n",
    "#                                     (1 step: batch_size(256)만큼의 데이터로 파라미터를 한번 update)\n",
    "# epoch: train set 전체를 학습하는 단위. (1 epoch: 총데이터개수(60000개)만큼 한번 다 학습한 것.)\n",
    "epochs = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "# 학습이 끝난 모델을 저장할 디렉토리.\n",
    "model_dir = \"models\"\n",
    "os.makedirs(model_dir, exist_ok=True)\n",
    "# Dataset을 저장할 디렉토리\n",
    "dataset_dir = \"datasets/mnist\"\n",
    "os.makedirs(dataset_dir, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-30T05:02:52.852140Z",
     "start_time": "2021-08-30T05:02:52.563117Z"
    },
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### MNIST dataset Loading\n",
    "\n",
    "#### Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainset = datasets.MNIST(\n",
    "    root=dataset_dir, # Dataset을 읽어올 디렉토리.\n",
    "    download=True,    # root 에 dataset이 없을 경우 다운로드 받을지 여부.\n",
    "    transform=transforms.ToTensor()\n",
    ")\n",
    "testset = datasets.MNIST(\n",
    "    root=dataset_dir,\n",
    "    download=True,\n",
    "    train=False,       # Trainset인지 여부. True(default): train set, False: test set\n",
    "    transform=transforms.ToTensor()\n",
    ")\n",
    "# transform=함수 -> input data를 전처리하는 함수를 전달.\n",
    "# transforms.ToTensor\n",
    "## ndarray, PIL.Image 객체를 torch.Tensor 로 변환.\n",
    "## (height, width, channel) 순서를 channel first (channel, height, width) 형태로 변환.\n",
    "## pixcel값들(0~255 정수)을 0 ~ 1 로 정규화. (Feature Scaling - MinMaxScaling)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset MNIST\n",
       "    Number of datapoints: 10000\n",
       "    Root location: datasets/mnist\n",
       "    Split: Test\n",
       "    StandardTransform\n",
       "Transform: ToTensor()"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<PIL.Image.Image image mode=L size=28x28>, 5)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 개별데이터 조회\n",
    "trainset[0]  # tuple: (X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/jpeg": "/9j/4AAQSkZJRgABAQAAAQABAAD/2wBDAAgGBgcGBQgHBwcJCQgKDBQNDAsLDBkSEw8UHRofHh0aHBwgJC4nICIsIxwcKDcpLDAxNDQ0Hyc5PTgyPC4zNDL/wAALCAAcABwBAREA/8QAHwAAAQUBAQEBAQEAAAAAAAAAAAECAwQFBgcICQoL/8QAtRAAAgEDAwIEAwUFBAQAAAF9AQIDAAQRBRIhMUEGE1FhByJxFDKBkaEII0KxwRVS0fAkM2JyggkKFhcYGRolJicoKSo0NTY3ODk6Q0RFRkdISUpTVFVWV1hZWmNkZWZnaGlqc3R1dnd4eXqDhIWGh4iJipKTlJWWl5iZmqKjpKWmp6ipqrKztLW2t7i5usLDxMXGx8jJytLT1NXW19jZ2uHi4+Tl5ufo6erx8vP09fb3+Pn6/9oACAEBAAA/APAACzBVBJJwAO9dnp/wm8damu6Dw5dRjGf9IKw/+hkVPffCnWNJa7XVNV0Kxa1hErrNe/M2cnYqgElsAHpjkc1wlAODkV694W8c654t8M6n4TuvEctrrFw0cun3c0/lq+3AMJcDK5AyOeTkd+fPvGFn4gsvEtzF4m89tUG1ZJJjuMgUBVYN/EMKOe9YVXtK0bUtdvVs9LsZ7y4YgbIULYycZPoPc8V6lpfwh0/w7p66z8RdXj0y2z8llC4aWQ+mRn8lz9RXPfE3x1pvi46TYaPZTQadpMJghluWDSyrhQM9SMBe5Oc5NcBV7Tda1XRZJJNK1O8sXkG12tZ2iLD0JUjNQ3l9eahN517dT3MvTfNIXb16n6mq9Ff/2Q==",
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAABwAAAAcCAAAAABXZoBIAAAA90lEQVR4AWNgGMyAWUhIqK5jvdSy/9/rQe5kgTlWjs3KRiAYxHsyKfDzxYMgFiOIAALDvfwQBsO/pK8Mz97fhPLAlNDtvyBwbNv3j8jCUHbAnOy/f89yM2jPwiLJwMc4628UqgQTnPvp/0eGFAQXLg5lcO/764YuhuArf3y4IAfmfoQwlBX44e/fckkMYaiA7q6/f6dJ45IViP3zdzcuSQaGn39/OkBl4WEL4euFmLIwXDuETav6lKfAIPy1DYucRNFdUPCe9MOUE3e6CpI6FogZSEKrwbFyOIATQ5v5mkcgXV9auVGlwK4NDGRguL75b88HVDla8QBFF16ADQA8sQAAAABJRU5ErkJggg==",
      "text/plain": [
       "<PIL.Image.Image image mode=L size=28x28>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainset[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(28, 28)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(np.uint8(0), np.uint8(255))"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "a = np.array(trainset[0][0])  # PIL.Image -> ndarray\n",
    "print(a.shape)\n",
    "a.min(), a.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 28, 28])\n",
      "torch.float32 torch.FloatTensor\n",
      "tensor(0.) tensor(1.)\n"
     ]
    }
   ],
   "source": [
    "########## transforms.ToTensor() 적용 후################\n",
    "f1 = trainset[0][0]\n",
    "print(f1.shape)  # (1:channel-grayscale, 28: height, 28:width)\n",
    "print(f1.dtype, f1.type())\n",
    "print(f1.min(), f1.max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60000\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 200x200 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import random\n",
    "print(len(trainset))\n",
    "idx = random.randint(0, len(trainset)) #0 ~ 60000 사이 랜덤 정수를 반환.\n",
    "img, label = trainset[idx]\n",
    "\n",
    "plt.figure(figsize=(2, 2))\n",
    "plt.imshow(img.squeeze(), cmap=\"gray\") # (1, 28, 28) -> (28, 28). matplotlib은 이미지를 (h, w, c) 로 전달해야함.\n",
    "plt.title(f\"{idx}\\n{label}\")\n",
    "plt.show()    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test객체.test()\n"
     ]
    }
   ],
   "source": [
    "# 객체를 함수처럼 사용.\n",
    "class Test:\n",
    "\n",
    "    def test(self):\n",
    "        print(\"Test객체.test()\")\n",
    "\n",
    "t = Test()\n",
    "t.test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test객체.test()\n"
     ]
    }
   ],
   "source": [
    "class ToTensor2:\n",
    "\n",
    "    def __call__(self):\n",
    "        print(\"Test객체.test()\")\n",
    "t = ToTensor2()\n",
    "t()  # t.__call__() -> callable (함수, 메소드, __call__() 정의한 객체)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DataLoader: Dataset의 데이터들을 모델에 제공하는 역할. 데이터들을 모델에 어떻게 제공할지 설정해서 생성.\n",
    "## Dataset: 데이터들을 가지고 있는 역할. 하나씩 조회하는 기능을 제공.\n",
    "train_loader = DataLoader(\n",
    "    trainset, # Dataset\n",
    "    batch_size=batch_size, # batch size (256)\n",
    "    shuffle=True,  # 모델에 데이터를 제공하기 전에 섞을지 여부. (default: False) True: 한 epoch 학습 전에 섞는다.\n",
    "    drop_last=True, # 모델에 제공할 데이터의 개수가 batch_size보다 적으면 제공하지 않는다. (학습에 사용안함)\n",
    ")\n",
    "\n",
    "test_loader = DataLoader(testset, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(234, 40)"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 1 epoch 당 step 수.\n",
    "len(train_loader), len(test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 10000)"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 데이터 개수.\n",
    "len(trainset), len(testset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### 모델 정의"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# subclass(상속) 방식\n",
    "## nn.Module 상속한 클래스를 정의.\n",
    "## __init__(): 순전파 연산(추론)에 필요한 layer들을 생성.\n",
    "## forward(): 연산 로직을 정의"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MNISTModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()  # 상위클래스 nn.Module 을 초기화.\n",
    "        #input feature개수, output 개수\n",
    "        # 첫번째 Linear() : 입력데이터(X_train)을 입력. (input-입력데이터 feature수에 맞춘다.)\n",
    "        self.lr1 = nn.Linear(784, 128) # (784:(28*28) image의 pixcel수, 출력: 128)\n",
    "        self.lr2 = nn.Linear(128, 64)  # (128: lr1의 출력개수, 출력: 64)\n",
    "        self.lr3 = nn.Linear(64, 32)   # (64: lr2의 출력개수, 출력: 32)\n",
    "        self.lr4 = nn.Linear(32, 10)   # (32: lr3의 출력개수, 출력: 10 -> y의 class개수.)\n",
    "        # 마지막 Linear(): 출력 크기(10) - 분류: class개수(0 ~ 9)\n",
    "    def forward(self, X):\n",
    "        \"\"\"\n",
    "        X를 입력 받아서 y를 추론하는 계산로직을 정의\n",
    "        initializer에서 정의한 Linear들을 이용해서 계산.\n",
    "        parameter:\n",
    "            X: torch.FloatTensor - 추론할 MNIST 이미지들.\n",
    "                                shape: (batch_size, 1, 28, 28) - batch_size개수의 이미지를 받아서 추론\n",
    "        \"\"\"\n",
    "        # (batch_size, 1, 28, 28) 를 (batch_size, 784) feature들을 1차원으로 변환.\n",
    "        X = torch.flatten(X, start_dim=1) # 다차원 배열을 1차원 배열로 변환. (start_dim=1, 0축은 놔두고 1축 부터 flatten시킨다.)\n",
    "        X = self.lr1(X)  # Linear: 선형함수\n",
    "        X = nn.ReLU()(X) # Activation(활성) 함수. 비선형함수. ReLU(x) - max(x, 0)\n",
    "        X = self.lr2(X)\n",
    "        X = nn.ReLU()(X)\n",
    "        X = self.lr3(X)\n",
    "        X = nn.ReLU()(X)\n",
    "        output = self.lr4(X)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([5, 2, 3])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([5, 6])"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "####### flatten() 함수 테스트.\n",
    "v = torch.arange(30).reshape(5, 2, 3)\n",
    "print(v.shape)\n",
    "v2 = torch.flatten(v, start_dim=1)\n",
    "v2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0,  1,  2,  3,  4,  5],\n",
       "        [ 6,  7,  8,  9, 10, 11],\n",
       "        [12, 13, 14, 15, 16, 17],\n",
       "        [18, 19, 20, 21, 22, 23],\n",
       "        [24, 25, 26, 27, 28, 29]])"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "v2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 모델, loss function, optimizer 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MNISTModel(\n",
      "  (lr1): Linear(in_features=784, out_features=128, bias=True)\n",
      "  (lr2): Linear(in_features=128, out_features=64, bias=True)\n",
      "  (lr3): Linear(in_features=64, out_features=32, bias=True)\n",
      "  (lr4): Linear(in_features=32, out_features=10, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# 모델 객체 생성. device로 옮김\n",
    "model = MNISTModel().to(device) # 이 모델(의 파라미터들)을 연산을 처리할 device(cpu, cuda)로 이동.\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loss함수\n",
    "##  다중 분류 문제 -> crossentropy loss함수를 이용. (이진분류: binary crossentropy, 회귀: mse)\n",
    "loss_fn = nn.CrossEntropyLoss()  # torch.nn.functional.cross_entropy 함수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "# optimizer 정의 -> 파라미터 업데이트, 파라미터의 gradient값을 초기화.\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=lr) #(모델의 파라미터들, 학습률)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([256, 1, 28, 28]), torch.Size([256]))"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "####### 생성한 모델로 학습전에 추론.########\n",
    "# Data\n",
    "X_batch, y_batch = next(iter(train_loader))  # batch_size만큼 데이터를 추출, (X, y)\n",
    "X_batch.shape, y_batch.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X, y를 model과 같은 device로 이동.\n",
    "X_batch, y_batch = X_batch.to(device), y_batch.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model(X_batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 0.1809, -0.0719, -0.0501,  0.1288, -0.1330,  0.0768,  0.0653,  0.0225,\n",
       "         0.1682, -0.0877], grad_fn=<SelectBackward0>)"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 첫번째 데이터의 예측결과\n",
    "y_pred[0]  # 가장 큰값을 가진 index가 예측 class가 된다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0)"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred[0].argmax()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0, 0, 0, 0, 0, 8, 0, 0, 8, 0, 0, 0, 0, 0, 8, 0, 0, 8, 8, 0, 8, 0, 8, 0,\n",
       "        0, 0, 0, 0, 0, 8, 0, 0, 8, 0, 8, 0, 0, 0, 0, 0, 0, 0, 0, 8, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 8, 0, 0, 8, 0, 0, 0, 0, 0, 0, 0, 0, 0, 8,\n",
       "        8, 0, 0, 0, 0, 0, 8, 0, 0, 0, 0, 0, 0, 8, 0, 0, 8, 0, 0, 8, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 8, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 8, 0, 0, 0, 0,\n",
       "        0, 0, 8, 0, 0, 0, 0, 8, 0, 0, 0, 0, 0, 0, 0, 8, 8, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 8, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 8, 8, 0, 0, 0, 0, 0, 0, 0, 0, 8,\n",
       "        0, 0, 0, 8, 0, 0, 0, 8, 0, 0, 0, 0, 8, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 8, 0, 0, 8, 0, 8, 8, 0, 0, 0, 8, 8, 0, 0, 0, 8, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 8, 8, 0, 0, 0, 8, 0, 0, 0, 8, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 8, 0, 0, 0, 0, 0, 0, 0, 8, 0, 0])"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred.argmax(dim=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(2.3120, grad_fn=<NllLossBackward0>)"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 오차 계산\n",
    "loss = loss_fn(y_pred, y_batch)\n",
    "loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델 파라미터 업데이트\n",
    "## gradient 계산\n",
    "loss.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 업데이트\n",
    "optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 파라미터 gradient 초기화\n",
    "optimizer.zero_grad()\n",
    "####################################### 1 step 학습."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 학습(훈련-train) 및 검증"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# device로 이동할 대상: Model객체, X(input), y(output) => 같은 device에 위치해야함."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = MNISTModel().to(device)\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "# 학습\n",
    "## 에폭별 검증결과들을 저장할 리스트\n",
    "train_loss_list = []\n",
    "valid_loss_list = []\n",
    "valid_acc_list = []\n",
    "s = time.time()\n",
    "for epoch in range(epochs):\n",
    "    ###############################################\n",
    "    # 모델 Train - 1 epoch : Trainset\n",
    "    ###############################################\n",
    "\n",
    "\n",
    "\n",
    "    ###############################################\n",
    "    # 1 epoch 학습한 결과 검증: Testset\n",
    "    ###############################################\n",
    "\n",
    "\n",
    "e = time.time()\n",
    "print('학습에 걸린 시간(초):', e-s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 학습 로그 시각화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 학습된 모델 저장 및 불러오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 모델 성능 최종 평가"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## 새로운 데이터 추론"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "position": {
    "height": "347.844px",
    "left": "1891px",
    "right": "20px",
    "top": "361px",
    "width": "486px"
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
