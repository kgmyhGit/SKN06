{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b4a2b3c4-8539-466d-ad52-da953f97498f",
   "metadata": {},
   "source": [
    "# Naver 영화댓글 분류"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfca8d80-d72b-4c50-8225-16a06f17c731",
   "metadata": {},
   "source": [
    "# Huggingface Dataset 패키지\n",
    "- 허깅페이스 허브에 공유된 데이터셋을  다운로드해서 전처리 및 관리할 수있도록 돕는 라이브러리. \n",
    "- 많은 공개데이터셋을 동일한 인터페이스로 사용할 수있다.\n",
    "- 설치\n",
    "    - `pip install datasets`\n",
    "- https://huggingface.co/datasets\n",
    "- https://github.com/huggingface/datasets\n",
    "      \n",
    "## Huggingface Dataset loading\n",
    "- datasets 로딩\n",
    "    - `load_data('dataset name')`\n",
    "        - huggingface datasets에 등록된 Dataset 이름 넣어 Loading한다.\n",
    "          \n",
    "![img](figures/huggingface_dataset.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "71a95106-2d3d-4d5a-85c6-40a66fca0b1a",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "00e01475e0774afbac653185fac39f1b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "README.md:   0%|          | 0.00/3.74k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Playdata\\miniconda3\\envs\\ml\\Lib\\site-packages\\huggingface_hub\\file_download.py:139: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\Playdata\\.cache\\huggingface\\hub\\datasets--e9t--nsmc. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bf41cfedde42404da52ad60a57a0d59a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "nsmc.py:   0%|          | 0.00/3.18k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "79d9ac5b3f5e4f61908e229a03170500",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data:   0%|          | 0.00/14.6M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cf05f4f51d744edca08b66d4e9f34757",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data:   0%|          | 0.00/4.89M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cc24b05ce48a4cbebc018b16c005ad65",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split:   0%|          | 0/150000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "362ae03f622b4d13a62e4673377e21d9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating test split:   0%|          | 0/50000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'datasets.dataset_dict.DatasetDict'>\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "nsmc = load_dataset(\"e9t/nsmc\", trust_remote_code=True)\n",
    "print(type(nsmc))\n",
    "# trust_remote_code=True: 프로그램(.py)를 받아서 실행해서 데이터를 받는 경우 True로 지정."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9901b56e-e7e6-4de6-805d-865a51199a62",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['id', 'document', 'label'],\n",
       "        num_rows: 150000\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['id', 'document', 'label'],\n",
       "        num_rows: 50000\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nsmc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "32bf57c5-8fb9-4da6-b74d-6db47842e597",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'datasets.arrow_dataset.Dataset'>\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['id', 'document', 'label'],\n",
       "    num_rows: 150000\n",
       "})"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nsmc_train = nsmc['train']\n",
    "print(type(nsmc_train))\n",
    "nsmc_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "94ae86b0-062f-43cd-bd66-3e6b0a500a4a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 1, 0, 0, 1]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nsmc_train['id'][:5]\n",
    "nsmc_train[\"document\"][:5]\n",
    "nsmc_train['label'][:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b9ed9cdd-d81c-4873-b4be-3773cbe2866e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'list'> <class 'list'>\n"
     ]
    }
   ],
   "source": [
    "# 전체 데이터를 분리\n",
    "train_X = nsmc[\"train\"][\"document\"]\n",
    "train_y = nsmc['train']['label']\n",
    "test_X = nsmc['test']['document']\n",
    "test_y = nsmc['test']['label']\n",
    "\n",
    "print(type(train_X), type(train_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "303574ae-9a4a-4bb7-b8ca-fcd8e7c5fac7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 일부만 sampling\n",
    "# select(추출할 index들)\n",
    "sample_train = nsmc['train'].shuffle().select(range(10_000))  # 15만개 중 10_000개만 추출\n",
    "sample_test = nsmc['test'].shuffle().select(range(5_000))\n",
    "# sample_train\n",
    "train_X = sample_train[\"document\"]\n",
    "train_y = sample_train['label']\n",
    "test_X = sample_test['document']\n",
    "test_y = sample_test['label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64f367ea-d955-408e-9652-12950d8baa3b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "cd956109-6f8f-4412-a159-4c9c4cdb0ef8",
   "metadata": {},
   "source": [
    "## 모델, 토크나이저 loading\n",
    "\n",
    "- 모델 별 Model 클래스를 이용하거나 Auto class를 이용해 모델, 전처리기(tokenizer, ImageProcessor 등)을 로딩한다.\n",
    "    - Huggingface에 저장된 model name을 입력해서 pretrained 모델을 loading 한다.\n",
    "    - fine tuning 한 경우 모델 저장 디렉토리 경로를 넣어 pretrained 모델을 loading한다.\n",
    "- AutoModel은 model name을 주면 그 모델이 학습한 base 모델에 맞는 객체를 생성해서 반환한다.\n",
    "    - Auto Model은 task 별로 다양한 클래스들이 있다.\n",
    "        - 클래스 이름 형식: AutoModelFor{Task형식}\n",
    "        - ex) `AutoModelForObjectDetection`, `AutoModelForSequenceClassification`\n",
    "    - https://huggingface.co/docs/transformers/model_doc/auto\n",
    "    - 전처리기(tokenzier)는 사용하려는 모델이 사용한 전처리기를 사용해야 한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "787111a2-cd3b-4376-89c9-8394acb5a4d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at beomi/kcbert-base and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "\n",
    "model_name = \"beomi/kcbert-base\" # base model : feature 추출기.(backbone network)\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModelForSequenceClassification.from_pretrained(model_name, num_labels=2)\n",
    "# num_labels=2 : 클래스 개수 지정.\n",
    "## base model로 분류 모델을 지정하면 분류기(estimator)는 학습이 안된 것을 추가해 모델을 반환.\n",
    "#### 그래서 분류기가 추론한 클래스 개수를 지정해 준다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "c02f7b81-3eb6-4d4b-9031-d38010e13c43",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %pip install torchinfo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "66b22541-3ad5-4d18-ad53-9dbdbe6682c0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "=====================================================================================\n",
       "Layer (type:depth-idx)                                       Param #\n",
       "=====================================================================================\n",
       "BertForSequenceClassification                                --\n",
       "├─BertModel: 1-1                                             --\n",
       "│    └─BertEmbeddings: 2-1                                   --\n",
       "│    │    └─Embedding: 3-1                                   23,040,000\n",
       "│    │    └─Embedding: 3-2                                   230,400\n",
       "│    │    └─Embedding: 3-3                                   1,536\n",
       "│    │    └─LayerNorm: 3-4                                   1,536\n",
       "│    │    └─Dropout: 3-5                                     --\n",
       "│    └─BertEncoder: 2-2                                      --\n",
       "│    │    └─ModuleList: 3-6                                  85,054,464\n",
       "│    └─BertPooler: 2-3                                       --\n",
       "│    │    └─Linear: 3-7                                      590,592\n",
       "│    │    └─Tanh: 3-8                                        --\n",
       "├─Dropout: 1-2                                               --\n",
       "├─Linear: 1-3                                                1,538\n",
       "=====================================================================================\n",
       "Total params: 108,920,066\n",
       "Trainable params: 108,920,066\n",
       "Non-trainable params: 0\n",
       "====================================================================================="
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from torchinfo import summary\n",
    "summary(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "5eb52259-f139-4db7-9314-c3496e52ab31",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BertForSequenceClassification(\n",
       "  (bert): BertModel(\n",
       "    (embeddings): BertEmbeddings(\n",
       "      (word_embeddings): Embedding(30000, 768, padding_idx=0)\n",
       "      (position_embeddings): Embedding(300, 768)\n",
       "      (token_type_embeddings): Embedding(2, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): BertEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0-11): 12 x BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSdpaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (pooler): BertPooler(\n",
       "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (activation): Tanh()\n",
       "    )\n",
       "  )\n",
       "  (dropout): Dropout(p=0.1, inplace=False)\n",
       "  (classifier): Linear(in_features=768, out_features=2, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7ab74ab-3349-49fa-9626-3f2f28e52754",
   "metadata": {},
   "source": [
    "## pytorch Dataset 생성\n",
    "모델 입력으로 다음 4개 항목을 dictionary로 묶어서 제공하도록 구현한다.\n",
    "1. input_ids: 입력 text 토큰을 id로 변환한 값\n",
    "2. token_type_ids: 문자쌍 구분시 사용. 단일 문장: 0, 문자쌍-첫문장: 0, 두 번째 문장: 1\n",
    "3. attention_mask: 실제 토큰값과 패딩구분값\n",
    "4. labels: 정답 class index\n",
    "\n",
    "1 ~ 3은 위의 train_encoding, test_encoding으로 만듬. labels은 train_data/test_data의 label 키 값 사용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "490025cb-1381-4a58-adb6-0ccec439a6ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 토큰화\n",
    "train_encoding = tokenizer(\n",
    "    train_X,\n",
    "    return_tensors=\"pt\",\n",
    "    padding=True  # train_X중 제일 토큰수가 많은 것에 맞춘다.\n",
    ")\n",
    "test_encoding = tokenizer(\n",
    "    test_X,\n",
    "    return_tensors=\"pt\",\n",
    "    padding=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "1799e7c4-fdaf-41bd-9579-69546c5fcf5e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([10000, 108])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_encoding['input_ids'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a396d3f-93d9-4a6b-afa6-12d356968b11",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pprint import pprint\n",
    "a = {\n",
    "    \"attention_mask\":[[1, 1, 1], [2, 2, 2], [3, 3, 3]],\n",
    "    \"input_ids\":     [[1, 1, 1], [2, 2, 2], [3, 3, 3]],\n",
    "    \"token_type_ids\":[[1, 1, 1], [2, 2, 2], [3, 3, 3]],\n",
    "}\n",
    "pprint(tuple(a.items()))\n",
    "print(\"-------------------------\")\n",
    "{key:value[0] for key, value in a.items()}  # 0번 index 조회"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "63d47fa6-f4e5-40fe-beb2-fc292d6e7a03",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "class NSMCDataset(Dataset):\n",
    "\n",
    "    def __init__(self, comments, labels):\n",
    "        # comments: encoding된 댓글 목록\n",
    "        # labels: 정답 label\n",
    "        self.comments = comments\n",
    "        self.labels = labels\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        data = {key:values[index] for key, values in self.comment.items()}\n",
    "        # attention_mask, input_ids, token_type_ids + labels\n",
    "        data['labels'] = torch.tensor(self.labels[index], dtype=torch.int64)  # 정답을 추가.\n",
    "        return data\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "d3e6c69b-c559-4c3a-864e-34b68c0bd1f1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 5000)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_set = NSMCDataset(train_encoding, train_y)\n",
    "test_set =NSMCDataset(test_encoding, test_y)\n",
    "len(train_set), len(test_set)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d19f905f-3f53-480b-8e70-1e76f8479555",
   "metadata": {},
   "source": [
    "# 학습\n",
    "- Transformers는 model 학습을 위해 TrainingArguments, Trainer 클래스를 제공한다.\n",
    "- TrainingArguments Trainer를 위한 설정을 하는 클래스\n",
    "- TrainingArguments, Trainer를 이용하면 training option, logging, gradient accumulation, mixed precision등을 쉽게 설정해 학습, 평가를 모두 진행할 수 있다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "0f4058d8-7d36-4ea5-88ae-d034e2a6e54a",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (3231374433.py, line 20)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  Cell \u001b[1;32mIn[41], line 20\u001b[1;36m\u001b[0m\n\u001b[1;33m    last_best_model_at_end=True: # 가장 성능 좋았던 모델을 저장할 지 여부.:True-save_total_limit+1\u001b[0m\n\u001b[1;37m                               ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "from transformers import TrainingArguments, Trainer\n",
    "\n",
    "# 학습 관련된 설정\n",
    "save_dir = \"models/nsmc\"\n",
    "logging_dir = \"logging/nsmc\"\n",
    "train_args = TrainingArguments(\n",
    "    output_dir=save_dir,        # 학습도중 모델을 저장할 디렉토리.\n",
    "\n",
    "    num_train_epochs=1,         # 학습 에폭수\n",
    "    per_device_train_batch_size=128, # train 배치수.\n",
    "    per_device_eval_batch_size=128,  # 검증 배치수\n",
    "\n",
    "    logging_dir=logging_dir,     # 학습과정 로그를 저장할 디렉토리.\n",
    "    logging_steps= 50,           # 로그를 몇 step당 한번씩 남길지.\n",
    "\n",
    "    eval_strategy=\"epoch\",     # 검증을 언제할지 \"epoch\", \"step\", \"no\": X  기준.\n",
    "    save_strategy=\"epoch\",     # 모델을 언제 저장할지 기준.\n",
    "\n",
    "    save_total_limit=1,      # 최대 몇개를 저장할지. 최신 N개를 저장.\n",
    "    last_best_model_at_end=True, # 가장 성능 좋았던 모델을 저장할 지 여부.:True-save_total_limit+1\n",
    "    metric_for_best_model=\"eval_loss\", # best 모델 성능 평가 지표\n",
    "    greater_is_better=False,    # 성능이 클수록 좋은 지 여부.\n",
    "\n",
    "    push_to_hub=True, #  Hugging hub 계정에 학습 모델을 올릴 지 여부.\n",
    "    hub_model_id=\"계정/이름\" # 저장할 repository \n",
    "    hub_token=\"access token\" # 인증 키\n",
    "    report_to=None\n",
    "\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c7cafc3-b27e-4ff3-aeaf-0e19e815aba7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82a80239-306a-4574-ae6b-5603ae161a96",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5378b3e7-803b-41dd-9456-1d03288c7f39",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1df7ea65-606c-4572-8e6f-a253cefadb9d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "3f6e490a-4d3e-454d-a7dd-15b052cee797",
   "metadata": {},
   "source": [
    "## 모델 로드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23911e38-7e34-416d-9137-b9ce7c7895d4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74f7113d-d452-4016-b689-11f6f587e94c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "930e3bfb-b401-4a71-adc6-bf109b89ccaa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e07f8998-6ae3-48db-89eb-de61add8444f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d6e0f780-a07d-45d4-af5b-43af910adc5c",
   "metadata": {},
   "source": [
    "# 추론"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1abb813-88ca-41b3-8be6-7ff47eef5624",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence = [\"이걸 영화라고 만든 거냐?\", \"아무 기대 없이 봤는데 재미있네.\", \"내가 감독이어도 이것보다 재미있게 만들겠다.\", \"시간이 어떻게 가는 줄 모르고 봤다.\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81194e5f-9197-46b7-9074-c54ca04ebdee",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3d50cca-be78-4fb9-bb8c-9a3a0ff02b9a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6168441b-4ca7-4a46-bf02-e5eb6030d846",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acc7f10b-f61f-4f3d-abb0-29c00fdc679a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
