{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "n1-HdRR266M6",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Convolutional Neural Network 모델 정의"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Conv2d 생성\n",
    "layer = nn.Conv2d(\n",
    "    in_channels=3,  # 입력 데이터의 channel 개수. 입력 tensor의 shape: (batch_size, channel, height, width) \n",
    "    out_channels=5, # 필터의 개수 (output feature map의 개수)\n",
    "    kernel_size=3,  # 필터의 크기 (3, 3)\n",
    "    stride=1,       # 계산을 위하 이동 크기. 좌->우: 1칸씩, 상->하: 1칸 (default: 1)\n",
    "    padding=1,      # 패팅 크기 (정수: 상하/좌우 동일할 패팅크기를 명시 - 0(default): 패딩추가 안함.)\n",
    "                    # \"same\": 입력 size와 동일한 size의 출력이 나오도록 알아서 패딩을 추가.\n",
    ")\n",
    "# 다음 layer 생성\n",
    "# layer2 = nn.Conv2d(\n",
    "#     in_channels=5, # 이전 Conv2d의 out_channels 값이 다음 Conv2d의 in_channels 값이 된다.\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 5, 10, 10])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_data = torch.ones(1, 3, 10, 10) # batch크기, channel수, heigth, width\n",
    "output = layer(input_data)\n",
    "output.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10.0"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(10 - 3 + 2*1)/1 + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([5, 3, 3, 3])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### Conv2d의 weigth 의 shape\n",
    "layer.weight.shape\n",
    "# [5:필터개수-out_channels, \n",
    "#  3:channel수-in_channel, \n",
    "#  3:height-kernel_size, \n",
    "#  3:width-kernel_size]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([5])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "layer.bias.shape # channel당 1개씩 bias가 추가."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "pool_layer = nn.MaxPool2d(\n",
    "    kernel_size=2, # 값을 추출하는 영역 크기(2, 2) - default: 2\n",
    "    stride=2,      # 다음 값을 추출하기위해서 몇칸을 이동할지.(default: kernel_size)\n",
    "    padding=0\n",
    "    # 값을 추출할 영역이 kernel_size보다 작을 경우 추출할지 여부.\n",
    "    # 0-추출을 하지 않겠다.\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 3, 10, 10])\n",
      "torch.Size([1, 3, 5, 5])\n"
     ]
    }
   ],
   "source": [
    "print(input_data.shape)\n",
    "pool_output = pool_layer(input_data)\n",
    "print(pool_output.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 1, 5, 5])\n",
      "torch.Size([1, 1, 2, 2])\n"
     ]
    }
   ],
   "source": [
    "input_data = torch.randn(1, 1, 5, 5)\n",
    "\n",
    "print(input_data.shape)\n",
    "pool_output = pool_layer(input_data)\n",
    "print(pool_output.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.7670,  0.3891,  0.0278, -1.1643, -1.3077],\n",
       "        [ 0.4071,  0.0203,  0.2442, -0.0384,  1.5362],\n",
       "        [ 0.8467,  1.0411, -2.5247,  0.2642,  1.2496],\n",
       "        [ 2.5154,  0.0489, -0.5061, -1.4856,  0.3671],\n",
       "        [-0.4352,  0.5259,  0.5502,  0.6428,  0.0199]])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_data[0, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[0.7670, 0.2442],\n",
       "          [2.5154, 0.2642]]]])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pool_output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MNIST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting torchinfo\n",
      "  Using cached torchinfo-1.8.0-py3-none-any.whl.metadata (21 kB)\n",
      "Using cached torchinfo-1.8.0-py3-none-any.whl (23 kB)\n",
      "Installing collected packages: torchinfo\n",
      "Successfully installed torchinfo-1.8.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install torchinfo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "import torchinfo\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "from module.data import load_mnist_dataset, load_fashion_mnist_dataset\n",
    "from module.train import fit\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 하이퍼파라미터 지정\n",
    "EPOCH = 1\n",
    "BATCH_SIZE = 256\n",
    "LEARNING_RATE = 0.001\n",
    "DATA_ROOT_DIR = \"datasets\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data 준비"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\n",
      "Failed to download (trying next):\n",
      "HTTP Error 403: Forbidden\n",
      "\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-images-idx3-ubyte.gz\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-images-idx3-ubyte.gz to datasets\\MNIST\\raw\\train-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 9.91M/9.91M [00:02<00:00, 4.07MB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting datasets\\MNIST\\raw\\train-images-idx3-ubyte.gz to datasets\\MNIST\\raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz\n",
      "Failed to download (trying next):\n",
      "HTTP Error 403: Forbidden\n",
      "\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-labels-idx1-ubyte.gz\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-labels-idx1-ubyte.gz to datasets\\MNIST\\raw\\train-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 28.9k/28.9k [00:00<00:00, 159kB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting datasets\\MNIST\\raw\\train-labels-idx1-ubyte.gz to datasets\\MNIST\\raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz\n",
      "Failed to download (trying next):\n",
      "HTTP Error 403: Forbidden\n",
      "\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-images-idx3-ubyte.gz\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-images-idx3-ubyte.gz to datasets\\MNIST\\raw\\t10k-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1.65M/1.65M [00:01<00:00, 1.62MB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting datasets\\MNIST\\raw\\t10k-images-idx3-ubyte.gz to datasets\\MNIST\\raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz\n",
      "Failed to download (trying next):\n",
      "HTTP Error 403: Forbidden\n",
      "\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-labels-idx1-ubyte.gz\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-labels-idx1-ubyte.gz to datasets\\MNIST\\raw\\t10k-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4.54k/4.54k [00:00<00:00, 4.55MB/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting datasets\\MNIST\\raw\\t10k-labels-idx1-ubyte.gz to datasets\\MNIST\\raw\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "train_loader = load_mnist_dataset(DATA_ROOT_DIR, BATCH_SIZE, True)\n",
    "test_loader = load_mnist_dataset(DATA_ROOT_DIR, BATCH_SIZE, False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CNN 모델 정의"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CNN - layer block\n",
    "# ConvolutionLayer -> Activation -> Pooling Layer\n",
    "# ConvolutionLayer -> Activation -> ConvolutionLayer -> Activation-> Pooling Layer\n",
    "\n",
    "# ConvolutionLayer -> BatchNormalization -> Activation -> Dropout -> Pooling Layer\n",
    "\n",
    "## 구조: filter 개수는 늘려주고(channel-depth) feature map의 size는 줄이는 방식으로 구성.\n",
    "# depth: Conv2d,  size: MaxPool2d\n",
    "\n",
    "class CNNModel(nn.Module):\n",
    "\n",
    "    def __init__(self, dropout_rate=0.2):\n",
    "        # 모델을 구성하는 Layer함수들을 초기화(객체 생성)\n",
    "        super().__init__()\n",
    "        # block 단위로 정의 - nn.Sequential()\n",
    "        self.b1 = nn.Sequential(\n",
    "            nn.Conv2d(\n",
    "                in_channels=1, # grayscale 이미지 -> channel수: 1, color: 3\n",
    "                out_channels=32,\n",
    "                kernel_size=3,\n",
    "                stride=1,\n",
    "                padding=\"same\"\n",
    "            ),\n",
    "            nn.BatchNorm2d(32), # Conv: out_channels\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(p=dropout_rate),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2, padding=1)\n",
    "        )\n",
    "\n",
    "        self.b2 = nn.Sequential(\n",
    "            nn.Conv2d(\n",
    "                in_channels=32, # b1 채널개수(out_channels)\n",
    "                out_channels=64,\n",
    "                kernel_size=3,\n",
    "                stride=1,\n",
    "                padding=\"same\"\n",
    "            ),\n",
    "            nn.BatchNorm2d(64), # Conv: out_channels\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(p=dropout_rate),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2, padding=1)\n",
    "        )\n",
    "\n",
    "        self.b3 = nn.Sequential(\n",
    "            nn.Conv2d(\n",
    "                in_channels=64, # b2 채널개수(out_channels)\n",
    "                out_channels=128,\n",
    "                kernel_size=3,\n",
    "                stride=1,\n",
    "                padding=\"same\"\n",
    "            ),\n",
    "            nn.BatchNorm2d(128), # Conv: out_channels\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(p=dropout_rate),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2, padding=1)\n",
    "        )\n",
    "        # 추론기(분류기) - Fully Conntected Layer(nn.Liear)\n",
    "        self.classifier = \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    def forward(self, X):\n",
    "        # 추론(연산처리)\n",
    "        pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [
    "2ARCyjDW66NR",
    "6bAN1wPG66NS",
    "shNUg6al66NV",
    "7xgQxAU666NZ"
   ],
   "name": "07_CNN_MNIST분류, 모델저장.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "langchain",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
