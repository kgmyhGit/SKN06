{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "23870109-6d31-4db7-b782-b699fe671867",
   "metadata": {},
   "source": [
    "# GRU(Gated Recurrent Units) 모델\n",
    "- https://arxiv.org/pdf/1406.1078\n",
    "- LSTM의 RNN의 한계점인 기억력 소실문제를 해결하여 긴 sequence의 데이터에서도 좋은 성능을 내는 모델이다. 그러나 복잡한 구조로 parameter가 많아지게 되었고 연산량이 많은 문제점이 있다.\n",
    "    - parameter가 많아지면서 데이터양이 부족할 경우 과대적합이 발생하고 연산량이 많아 학습에 많은 시간이 걸리게 된다.\n",
    "- LSTM의 이런 문제를 개선하기 위한 변형 모델이 GRU이다.\n",
    "\n",
    "## LSTM과 차이\n",
    "1. LSTM은 forget gate, input gate, output gete 세개의 Gate연산을 함. GRU는 **reset gate와 update gate** 로 흐름을 제어한다.\n",
    "2. LSTM은 이전 처리결과로 Cell State, Hidden State 두개가 있었는데 이것을 하나로 합쳐 **Hidden State**로 출력한다.\n",
    "\n",
    "## GRU 성능\n",
    "- GRU는 적은 파라미터 수와 연산비용이 적게 드는 것에 비해 LSTM과 비슷한 성능을 내는 것으로 알려졌다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18729a02-f014-4082-826f-824b9d7adbf6",
   "metadata": {},
   "source": [
    "## GRU Cell 구조\n",
    "\n",
    "![gru_cell](figures/rnn/23_gru_cell.png)    \n",
    "[이미지 Source](https://www.oreilly.com/library/view/advanced-deep-learning/9781789956177/8ad9dc41-3237-483e-8f6b-7e5f653dc693.xhtml)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9740062-d77e-4b55-946d-4135af3c8e28",
   "metadata": {},
   "source": [
    "- **Reset Gate**\n",
    "    - 이전 timestep까지의 hidden state(feature)를 현재 timestep의 hidden state(feature) 계산시 얼마나 반영할 지 비율을 결정하는 gate.\n",
    "    - $r_{t} = \\sigma(h_{t-1}\\cdot U_{r} + X_{t}\\cdot W_{r})$\n",
    "        - $U_{r},\\, W_{r}$ 는 파라미터\n",
    "        - $\\sigma$: sigmoid(logisic) 함수\n",
    "- **Update Gate**\n",
    "    - 현재 timestep의 hidden state($h_t$)를 계산할 때 이전 time step까지 정보($h_{t-1}$)와 현재 time step의 정보($X_t$)를 각각 얼마나 반영할지 비율을 정의한다.\n",
    "    - $z_{t} = \\sigma(h_{t-1}\\cdot U_{z} + X_{t}\\cdot W_{z})$\n",
    "        - $U_{z},\\, W_{z}$ 는 파라미터\n",
    "        - $\\sigma$: sigmoid(logisic) 함수\n",
    "    - $h_t$를 계산할 때 $z_{t}$ 는 이전 정보인 $h_{t-1}$을 얼마나 반영할지 $1-z_{t}$는 현재 정보를 얼마나 반영할 지를 정한다.\n",
    "- **Cell의 출력값인 $h_t$ 계산**\n",
    "    - $z_{t}\\times h_{t-1} + tanh(h_{t-1} * r_{t}+X_{t}\\cdot W)\\times(1-z_{t})$\n",
    "    - 이전 정보에는 $z_t$를 곱해 얼마나 $h_t$ 에 더할지 연산\n",
    "    - 현재 정보($X_t$)에는 이전 정보를 일부를 반영한다. 이전 정보를 얼마나 반영할지를 reset gate 결과를 곱해 결정한다. 활성화 함수 tanh를 이용해 비선형성을 추가 한 결과에 $1-z_t$를 곱한다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28c6f7c4-0cfb-4ac8-b7dd-834a44c18880",
   "metadata": {},
   "source": [
    "## Pytorch GRU\n",
    "- `nn.GRU` 클래스 이용\n",
    "    - https://pytorch.org/docs/stable/generated/torch.nn.GRU.html\n",
    "- **입력**\n",
    "    - **input**: (seq_length, batch, hidden_size) shape의 tensor. (batch_first=False), batch_first=True이면 `seq_length`와 `batch` 위치가 바뀐다.\n",
    "    - **hidden**: (D * num_layers, batch, hidden_size) shape의 Tensor. D(양방향:2, 단방향:1), hidden은 생략하면 0이 입력됨.\n",
    "- **출력** - output과 hidden state가 반환된다.\n",
    "    - **output**\n",
    "        - 모든 sequence의 처리결과들을 모아서 제공.\n",
    "        - shape: (seq_length, batch, D * hidden_size) : D(양방향:2, 단방향:1), batch_first=True이면 `seq_length`와 `batch` 위치가 바뀐다.\n",
    "    - **hidden**\n",
    "        - 마지막 time step 처리결과\n",
    "        - shape: (D * num_layers, batch, hidden) : D(양방향:2, 단방향:1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "702c5b37-cadd-4e88-af53-581268bc2b18",
   "metadata": {},
   "outputs": [],
   "source": [
    "## GRU 입출력  확인\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "# dummy data\n",
    "input_data = torch.randn((20, 2, 10))  \n",
    "# (20: seq len, 2: batch, 10: 개별 timestep의 입력 feature수)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8b7d86e6-0a72-4fde-9e57-51417b1ed782",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([20, 2, 256])\n",
      "torch.Size([1, 2, 256])\n"
     ]
    }
   ],
   "source": [
    "gru1 = nn.GRU(\n",
    "    input_size=10,\n",
    "    hidden_size=256, \n",
    "    num_layers=1, # 몇층(layer)를 쌓을 지. (default: 1)\n",
    "    bidirectional=False # 양방향 여부 (default: False)\n",
    ")\n",
    "out1, hidden1 = gru1(input_data)\n",
    "#모든 timestep의 hidden state값을 묶어서 반환.[20:seq len, 2:batch, 256:hidden_size]\n",
    "print(out1.shape) \n",
    "# 마지막 timestep 처리 hidden state값 [1: seq len, 2, 256]\n",
    "print(hidden1.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "794b0319-660e-42f0-a390-6ec71ade0b17",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([20, 2, 512])\n",
      "torch.Size([2, 2, 256])\n"
     ]
    }
   ],
   "source": [
    "# bidirectional=True (양방향)\n",
    "gru2 = nn.GRU(\n",
    "    input_size=10,\n",
    "    hidden_size=256, \n",
    "    num_layers=1, # 몇층(layer)를 쌓을 지. (default: 1)\n",
    "    bidirectional=True # 양방향 여부 (default: False)\n",
    ")\n",
    "out2, hidden2 = gru2(input_data)\n",
    "\n",
    "# [20, 2, 512:hidden_size * 2]   양방향 hidden state를 합쳐서(concat) 반환.\n",
    "print(out2.shape)\n",
    "# [2:정/역방향 두개, 2, 256:hidden size]\n",
    "print(hidden2.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cf63dd57-148c-4a77-9ceb-aedde38a86b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([20, 2, 256])\n",
      "torch.Size([4, 2, 256])\n"
     ]
    }
   ],
   "source": [
    "# multi layer\n",
    "gru3 = nn.GRU(\n",
    "    input_size=10,\n",
    "    hidden_size=256, \n",
    "    num_layers=4, # 몇층(layer)를 쌓을 지. (default: 1)\n",
    "    bidirectional=False # 양방향 여부 (default: False)\n",
    ")\n",
    "out3, hidden3 = gru3(input_data)\n",
    "\n",
    "#[20, 2, 256] - 마지막 GRU Layer가 출력한 결과들이 최종 feature이므로 그것을 모아서 반환.\n",
    "# num_layers가 몇개든 out의 shape은 동일.\n",
    "print(out3.shape)\n",
    "# [4: 레이어수, 2, 256]  - 각 layer의 마지막 hidden state들을 모아서 반환\n",
    "print(hidden3.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "da1abf35-6271-41de-a217-63ff74d33837",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([20, 2, 512])\n",
      "torch.Size([8, 2, 256])\n"
     ]
    }
   ],
   "source": [
    "# multi layer, 양방향\n",
    "\n",
    "gru4 = nn.GRU(\n",
    "    input_size=10,\n",
    "    hidden_size=256, \n",
    "    num_layers=4, # 몇층(layer)를 쌓을 지. (default: 1)\n",
    "    bidirectional=True # 양방향 여부 (default: False)\n",
    ")\n",
    "out4, hidden4 = gru4(input_data)\n",
    "print(out4.shape) # [20, 2, 512: 양방향 hidden 합친것]\n",
    "# [8:양방향(2) x 레이어수: 각각, 2, 256]\n",
    "print(hidden4.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "780b5bac-e226-40e3-9e8c-96e3cf9ad9b8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "8389555c-17d0-41ed-abfc-42046bf8aeaa",
   "metadata": {},
   "source": [
    "# Encoder-Decoder 구조\n",
    "- 두개의 네트워크를 연결한 구조\n",
    "- Encoder network는 입력을 이해하고 Decoder network는 (Encoder의 이해를 바탕으로) 출력을 생성한다.\n",
    "\n",
    "## Seq2Seq\n",
    "- Encoder-Decoder 구조를 RNN 계열에 적용한 모델.\n",
    "- Encoder는 입력 Sequence의 전체 의미(특징)을 표현하는 **context vector**를 출력한다.\n",
    "    - **Context Vector는**\n",
    "        - 번역의 경우 번역할 대상 문장에서 **번역 결과를 만들때 필요한 feature들**을 가지고 있다.\n",
    "        - Chatbot의 경우 입력된 질문에서 **답변을 만들때 필요한 feature들**을 가지고 있다.\n",
    "- Decoder는 Encoder가 출력한 Context Vector를 입력받아 결과 sequence를 생성한다.\n",
    "    - **결과 sequence는**\n",
    "        - **번역**의 경우 번역 문장을 생성한다.\n",
    "        - **chatbot**의 경우 질문에 대한 답변을 생성한다.\n",
    "\n",
    "![seq2seq](figures/seq2seq.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9887d108-2ac6-425e-9643-d351e44282c7",
   "metadata": {},
   "source": [
    "# Seq2Seq 를 이용한 Chatbot 모델 구현\n",
    "- Encoder를 이용해 질문의 특성을 추출하고 Decoder를 이용해 답변을 생성한다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "daec7aee-1d3b-4990-b934-a4254a6e17ef",
   "metadata": {},
   "source": [
    "# Chatbot Dataset\n",
    "\n",
    "- https://github.com/songys/Chatbot_data\n",
    "- columns\n",
    "    - Q: 질문\n",
    "    - A: 답\n",
    "    - label: 일상다반사 0, 이별(부정) 1, 사랑(긍정) 2\n",
    "- **Download**\n",
    "\n",
    "![dataset](figures/chatbot.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fa75cf8-9cd9-4a72-a610-4392b80ca6b5",
   "metadata": {},
   "source": [
    "# Chatbot Dataset Loading 및 확인"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bbd0c3c-2b8f-4a4c-b90c-a0fa6d828c4c",
   "metadata": {},
   "source": [
    "## 데이터 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5ed2c29e-1aef-48c3-87ba-a89cc8ed6146",
   "metadata": {},
   "outputs": [],
   "source": [
    "# requests 모듈로 받기\n",
    "import requests\n",
    "import os\n",
    "\n",
    "os.makedirs(\"data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0fc98856-b66d-4e2e-bc8a-27e3d34dcfd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "url = \"https://raw.githubusercontent.com/songys/Chatbot_data/refs/heads/master/ChatbotData.csv\"\n",
    "res = requests.get(url)\n",
    "if res.status_code == 200:\n",
    "    with open(\"data/chatbot_data.csv\", \"wt\", encoding=\"utf-8\") as fw:\n",
    "        fw.write(res.text)\n",
    "else:\n",
    "    print(f\"불러오지 못함: {url}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e670d063-8c71-4ddf-b6b0-15631c7f58da",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(11823, 3)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv('data/chatbot_data.csv')\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "796816ae-1851-4b97-892b-671b5f869cab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 11823 entries, 0 to 11822\n",
      "Data columns (total 3 columns):\n",
      " #   Column  Non-Null Count  Dtype \n",
      "---  ------  --------------  ----- \n",
      " 0   Q       11823 non-null  object\n",
      " 1   A       11823 non-null  object\n",
      " 2   label   11823 non-null  int64 \n",
      "dtypes: int64(1), object(2)\n",
      "memory usage: 277.2+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5e784426-2a6d-4988-b9bc-4bfbd37b26e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 라벨 제거\n",
    "df.drop(columns='label', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "eaeb3e95-7b21-418e-9936-988b76d38070",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Q</th>\n",
       "      <th>A</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>12시 땡!</td>\n",
       "      <td>하루가 또 가네요.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1지망 학교 떨어졌어</td>\n",
       "      <td>위로해 드립니다.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3박4일 놀러가고 싶다</td>\n",
       "      <td>여행은 언제나 좋죠.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3박4일 정도 놀러가고 싶다</td>\n",
       "      <td>여행은 언제나 좋죠.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>PPL 심하네</td>\n",
       "      <td>눈살이 찌푸려지죠.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Q            A\n",
       "0           12시 땡!   하루가 또 가네요.\n",
       "1      1지망 학교 떨어졌어    위로해 드립니다.\n",
       "2     3박4일 놀러가고 싶다  여행은 언제나 좋죠.\n",
       "3  3박4일 정도 놀러가고 싶다  여행은 언제나 좋죠.\n",
       "4          PPL 심하네   눈살이 찌푸려지죠."
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1aad072-2245-41e8-9863-a0b451262fdd",
   "metadata": {},
   "source": [
    "# Dataset, DataLoader 정의"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd6e0b8d-ee13-488b-ae6e-2a7d4189fd6c",
   "metadata": {},
   "source": [
    "## Tokenization\n",
    "\n",
    "### Subword방식"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d080f3aa-6d49-464f-9469-91ef9bcd351c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(11823, 11823, 11823)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# token 학습 -> vocab 사전 생성.\n",
    "## 질문들 + 답변들 합쳐서 학습.\n",
    "question_texts = df['Q']\n",
    "answer_texts = df['A']\n",
    "all_texts = list(question_texts + \" \"+answer_texts) # 같은 index끼리 합치기 => list로 변환\n",
    "len(question_texts), len(answer_texts), len(all_texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "a8ea110e-9215-4385-9d41-2d6675fd2c17",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['12시 땡! 하루가 또 가네요.',\n",
       " '1지망 학교 떨어졌어 위로해 드립니다.',\n",
       " '3박4일 놀러가고 싶다 여행은 언제나 좋죠.',\n",
       " '3박4일 정도 놀러가고 싶다 여행은 언제나 좋죠.',\n",
       " 'PPL 심하네 눈살이 찌푸려지죠.']"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_texts[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "ac2eea8d-c5c6-42e0-9314-c94043113668",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tokenizers import Tokenizer\n",
    "from tokenizers.models import BPE\n",
    "from tokenizers.pre_tokenizers import Whitespace\n",
    "from tokenizers.trainers import BpeTrainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "60438a5d-a238-42e3-96ea-c02d458fbee3",
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_size = 10_000\n",
    "min_frequency = 5 \n",
    "\n",
    "tokenizer = Tokenizer(BPE(unk_token=\"[UNK]\"))\n",
    "tokenizer.pre_tokenizer = Whitespace()\n",
    "trainer = BpeTrainer(\n",
    "    vocab_size=vocab_size,\n",
    "    min_frequency=min_frequency,\n",
    "    continuing_subword_prefix='##', # 연결 subword 앞에 붙일 접두어지정. \n",
    "    special_tokens=[\"[PAD]\", \"[UNK]\", \"[SOS]\"] # [SOS]: 문장의 시작을 의미하는 토큰.\n",
    ")\n",
    "# tokenizer: token + ##izer\n",
    "## 학습\n",
    "tokenizer.train_from_iterator(all_texts, trainer=trainer) # 리스트로 부터 학습\n",
    "## tokenizer.train(\"파일경로\") # 파일에 있는 text를 학습."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "ad5b0c24-3261-4c24-be02-6cff4f789540",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "총 어휘수: 7040\n"
     ]
    }
   ],
   "source": [
    "print(\"총 어휘수:\", tokenizer.get_vocab_size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "44198fe6-9e49-49c4-ab70-d3ab3b2bdf45",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2290, 3852, 2258, 5913, 8, 3271, 2447, 322, 2243, 8, 1, 1, 1, 1817]\n",
      "['오늘', '날씨가', '너무', '좋습니다', '.', '즐거운', '하루', '되', '##세요', '.', '[UNK]', '[UNK]', '[UNK]', '##ㅋ']\n"
     ]
    }
   ],
   "source": [
    "# 토큰화\n",
    "encode = tokenizer.encode(\"오늘 날씨가 너무 좋습니다. 즐거운 하루 되세요. 쿄쿄쿜ㅋ\")\n",
    "print(encode.ids)\n",
    "print(encode.tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80caf0b3-01d5-4631-87c1-f48ab2f5bafc",
   "metadata": {},
   "source": [
    "### Tokenizer 저장"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "abe8873a-dde0-4c0b-9146-0da961f55bc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "dir_path = \"saved_model/vocab\"\n",
    "os.makedirs(dir_path, exist_ok=True)\n",
    "vocab_path = os.path.join(dir_path, \"chatbot_bpe.json\")\n",
    "tokenizer.save(vocab_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0ed30c5-fcd0-457a-be8d-a70e8617b7d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# question_texts, answer_texts"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba2b068c-ead0-4f75-bd01-4a0ebf486774",
   "metadata": {},
   "source": [
    "## Dataset, DataLoader 정의\n",
    "\n",
    "\n",
    "### Dataset 정의 및 생성\n",
    "- 모든 문장의 토큰 수는 동일하게 맞춰준다.\n",
    "    - DataLoader는 batch 를 구성할 때 batch에 포함되는 데이터들의 shape이 같아야 한다. 그래야 하나의 batch로 묶을 수 있다.\n",
    "    - 문장의 최대 길이를 정해주고 **최대 길이보다 짧은 문장은 `<PAD>` 토큰을 추가**하고 **최대길이보다 긴 문장은 최대 길이에 맞춰 짤라준다.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "0ae89444-25b0-4b96-819a-640e35d933dc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cpu'"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import random\n",
    "import os\n",
    "import numpy as np\n",
    "import time\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader, random_split, SubsetRandomSampler\n",
    "from torch import optim\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "d181d3a2-a7eb-482a-8c9e-b03feaca8f1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ChatbotDataset(Dataset):\n",
    "    \"\"\"\n",
    "    ChatbotDataset\n",
    "    parameter:\n",
    "        question_texts: list[str] - 질문 texts 목록. 리스트에 질문들을 담아서 받는다. [\"질문1\", \"질문2\", ...]\n",
    "        answer_texts: list[str] - 답 texts 목록. 리스트에 답변들을 담아서 받는다.     [\"답1\", \"답2\", ...]\n",
    "        max_length: 개별 문장의 token 개수. 모든 문장의 토큰수를 max_length에 맞춘다.\n",
    "        tokenizer: Tokenizer\n",
    "        vocab_size: int 총단어수\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, question_texts, answer_texts, max_length, tokenizer):\n",
    "        \"\"\"\n",
    "        parameter\n",
    "            question_texts: list[str] - 질문 texts 목록. 리스트에 질문들을 담아서 받는다. [\"질문1\", \"질문2\", ...]\n",
    "            answer_texts: list[str] - 답 texts 목록. 리스트에 답변들을 담아서 받는다.     [\"답1\", \"답2\", ...]\n",
    "            max_length: 개별 문장의 token 개수. 모든 문장의 토큰수를 max_length에 맞춘다.\n",
    "            tokenizer: Tokenizer\n",
    "        \"\"\"\n",
    "        pass\n",
    "\n",
    "    \n",
    "    def __pad_token_sequence(self, token_sequence):\n",
    "        \"\"\"\n",
    "        max_length 길이에 맞춰 token_id 리스트를 구성한다.\n",
    "        max_length 보다 길면 뒤에를 자르고 max_length 보다 짧으면 [PAD] 토큰을 추가한다.\n",
    "        \n",
    "        Parameter\n",
    "            token_sentence: list[int] - 길이를 맞출 한 문장 token_id 목록\n",
    "        Return\n",
    "            list[int] - length가 max_length인 token_id 목록\n",
    "        \"\"\"\n",
    "        pad_token = self.tokenizer.token_to_id('[PAD]')\n",
    "        seq_len = len(token_sequence) # 입력 문장의 토큰수\n",
    "        if seq_len > self.max_length: # 문장 최대 토큰수 보다 길다면.\n",
    "            return token_sequence[:self.max_length]\n",
    "        else:\n",
    "            return token_sequence + ([pad_token] * (self.max_length - seq_len))\n",
    "    \n",
    "    def __process_sequence(self, text):\n",
    "        \"\"\"\n",
    "        한문장을 받아서 padding이 추가된 token_id 리스트로 변환 후 반환\n",
    "        Parameter\n",
    "            text: str - token_id 리스트로 변환할 한 문장\n",
    "        Return\n",
    "            list[int] - 입력받은 문장에 대한 token_id 리스트\n",
    "        \"\"\"\n",
    "        pass\n",
    "\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.question_texts)\n",
    "\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        # return  index의 (질문토큰들,  답변토큰들)\n",
    "        q = self.question_texts[index]  # List\n",
    "        a = self.answer_texts[index]\n",
    "        # List->LongTensor. nn.Embedding()의 입력(정수타입)으로 들어간다. \n",
    "        return torch.tensor(q, dtype=torch.int64), torch.tensor(a, dtype=torch.int64)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bcb808e-6edc-4f5e-8de3-41d4cb318e52",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12cca6bc-bf91-4030-9c83-2aa72e0c0351",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "2b6d2b6f-ccf7-4aec-9c08-176a2456e813",
   "metadata": {},
   "source": [
    "### Trainset / Testset 나누기\n",
    "train : test = 8 : 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb7d0d5a-c8ba-48be-bc46-d5ba12cd89e6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42aed6cf-4aa2-4262-a4d4-964365ce7dea",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0128f9f8-bb19-40c9-9372-0763e7a550af",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "3d4b274f-8c8a-4aa6-af6d-a66bf5c38210",
   "metadata": {},
   "source": [
    "### DataLoader 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c51e1123-cbdd-4dce-8998-d4638ce04e60",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c61053a2-8362-47ff-a167-efcbdf2c8226",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "470a9d5a-672d-498d-afd4-76e7c5c40e94",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "1cdaf424-c7de-46be-b74b-88a3efcdf352",
   "metadata": {},
   "source": [
    "# 모델 정의\n",
    "\n",
    "## Seq2Seq 모델 정의\n",
    "- Seq2Seq 모델은 Encoder와 Decoder의 입력 Sequence의 길이와 순서가 자유롭기 때문에 챗봇이나 번역에 이상적인 구조다.\n",
    "    - 단일 RNN은 각 timestep 마다 입력과 출력이 있기 때문에 입/출력 sequence의 개수가 같아야 한다.\n",
    "    - 챗봇의 질문/답변이나 번역의 대상/결과 문장의 경우는 사용하는 어절 수가 다른 경우가 많기 때문에 단일 RNN 모델은 좋은 성능을 내기 어렵다.\n",
    "    - Seq2Seq는 **입력처리(질문,번역대상)처리 RNN과 출력 처리(답변, 번역결과) RNN 이 각각 만들고 그 둘을 연결한 형태로 길이가 다르더라도 상관없다.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e17d7410-a73e-4be1-b41d-9ea07d6b0911",
   "metadata": {},
   "source": [
    "## Encoder\n",
    "Encoder는 하나의 Vector를 생성하며 그 Vector는 **입력 문장의 의미**를 N 차원 공간 저장하고 있다. 이 Vector를 **Context Vector** 라고 한다.    \n",
    "![encoder](figures/seq2seq_encoder.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff60f00e-707c-47e9-ab60-dad42d0ec508",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b7c9fcf-6d84-4c2f-b7b5-82ea92b80150",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5c94832-5298-4f42-8e54-31fef6925610",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07f2fa3d-7689-478d-90d8-ed3411f7a90f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99e8344f-8cf7-45a8-8092-ab20365cdb91",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "24779603-15ac-4ba1-a24c-6e86658b3ad6",
   "metadata": {},
   "source": [
    "## Decoder\n",
    "- Encoder의 출력(context vector)를 받아서 번역 결과 sequence를 출력한다.\n",
    "- Decoder는 매 time step의 입력으로 **이전 time step에서 예상한 단어와 hidden state값이** 입력된다.\n",
    "- Decoder의 처리결과 hidden state를 Estimator(Linear+Softmax)로 입력하여 **입력 단어에 대한 번역 단어가 출력된다.** (이 출력단어가 다음 step의 입력이 된다.)\n",
    "    - Decoder의 첫 time step 입력은 문장의 시작을 의미하는 <SOS>(start of string) 토큰이고 hidden state는 context vector(encoder 마지막 hidden state) 이다.\n",
    "\n",
    "![decoder](figures/seq2seq_decoder.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "282f60e8-7e86-479a-8522-d32aab86b1b0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbb1cd25-b1e6-4f64-9319-e397561845ba",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52cdf137-057b-4e41-95cd-c58219032b67",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f84a90a0-c12e-4194-88ab-cd9523e4f7ef",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79828e5a-c03f-4af3-afc8-9b66ced6fdb8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "3563f5b2-f18b-42b5-9bd4-f4f8abd767ac",
   "metadata": {},
   "source": [
    "## Seq2Seq 모델\n",
    "\n",
    "- Encoder - Decoder 를 Layer로 가지며 Encoder로 질문의 feature를 추출하고 Decoder로 답변을 생성한다.\n",
    "\n",
    "### Teacher Forcing\n",
    "- **Teacher forcing** 기법은, RNN계열 모델이 다음 단어를 예측할 때, 이전 timestep에서 예측된 단어를 입력으로 사용하는 대신 **실제 정답 단어(ground truth) 단어를** 입력으로 사용하는 방법이다.\n",
    "    - 모델은 이전 시점의 출력 단어를 다음 시점의 입력으로 사용한다. 그러나 모델이 학습할 때 초반에는 정답과 많이 다른 단어가 생성되어 엉뚱한 입력이 들어가 학습이 빠르게 되지 않는 문제가 있다.\n",
    "- **장점**\n",
    "    - **수렴 속도 증가**: 정답 단어를 사용하기 때문에 모델이 더 빨리 학습할 수있다.\n",
    "    - **안정적인 학습**: 초기 학습 단계에서 모델의 예측이 불안정할 때, 잘못된 예측으로 인한 오류가 다음 단계로 전파되는 것을 막아줍니다.\n",
    "- **단점**\n",
    "    - **노출 편향(Exposure Bias) 문제:** 실제 예측 시에는 정답을 제공할 수 없으므로 모델은 전단계의 출력값을 기반으로 예측해 나가야 한다. 학습 과정과 추론과정의 이러한 차이 때문에 모델의 성능이 떨어질 수있다.\n",
    "        - 이런 문제를 해결하기 학습 할 때 **Teacher forcing을 random하게 적용하여 학습시킨다.**\n",
    "![seq2seq](figures/seq2seq.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eec05c3a-7da5-4297-974e-fcc032ea9119",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbf0ecb0-c657-4ca5-abf4-a31bab50300b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b73cc882-8a49-4b1b-98ae-d23cc1dc832e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65871f8b-6346-4b6e-a384-41ac3b86da80",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "6e89fed5-b059-4371-b836-c3eb59bebdfb",
   "metadata": {},
   "source": [
    "# 학습"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6dac7b8a-935e-4f3a-9fa5-efbacbfc19d7",
   "metadata": {},
   "source": [
    "## 모델생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0280640f-243a-4413-8e8c-dc0285b7aaa2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a609b827-8287-4ea8-8df7-03a37ac8157d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0b4af8c-d687-4a05-97f2-41374797538a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "6ba83263-e042-4579-9784-2403eb3c3fa1",
   "metadata": {},
   "source": [
    "## loss함수, optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "839652a6-a4f0-4146-888b-30a9670854c8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "6a659df1-87a2-4fe0-a095-e031ed130e68",
   "metadata": {},
   "source": [
    "## train/evaluation 함수 정의\n",
    "\n",
    "### train 함수정의"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "048ca8af-0556-4b59-a0ba-69f1995873aa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69040b84-9346-4cee-b188-159b9958662a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f68e8c9b-15c4-41b5-81af-88aaaa9fe600",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "8981388d-ad33-4318-844b-29a5a434d2a7",
   "metadata": {},
   "source": [
    "### Test 함수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52e0f5d3-dcdc-4b8e-b359-99aa8391e79b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5326e1fa-7821-4d5e-9118-1b60c12c8db0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "4a71e20c-8a03-44f4-bbbc-8f4e51b85636",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "335aa2c8-4e29-46dd-90bd-69a41301adf7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf61c71e-3bbb-4a8b-8681-1dce2e4758f9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "6fe0585a-eb35-47dd-88bf-276d749f5f00",
   "metadata": {},
   "source": [
    "# 결과확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 482,
   "id": "e4bcf956-b7e1-4f05-bd96-723fe0624339",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import SubsetRandomSampler\n",
    "\n",
    "\n",
    "def handle_special_tokens(decoded_string):\n",
    "    \"\"\"\n",
    "    Subword 처리\n",
    "    subword는 단어의 시작으로 쓰인 것과 중간 부분(연결)에 사용된 두가지 subword가 있다.  연결 subword는 `#`과 같은 특수문자로 시작 한다.\n",
    "    tokenizer.decode() 결과 문자열은 subword의 특수문자('#')을 처리하지 않는다. 이것을 처리하는 함수\n",
    "    ex) \"이 기회 #는 내 #꺼 #야\" ==> \"이 기회는 내꺼야\"\n",
    "    \n",
    "    Parameter\n",
    "        decoded_string: str - Tokenizer가 decode한 중간 subword의 특수문자 처리가 안된 문자열. \n",
    "    Return\n",
    "        str: subword 특수문자 처리한 문자열\n",
    "    \"\"\"\n",
    "    pass\n",
    "\n",
    "# dataset에서 일부 데이터들을 가지고 확인\n",
    "def random_evaluation(model, dataset, device, n=10):\n",
    "    \"\"\"\n",
    "    Dataset에서 일부 질문-답변 쌍들을 가져다 모델에 질문을 넣어 추론한 결과와 함께 확인.\n",
    "    Parameter\n",
    "        model: 학습된 seq2seq 모델\n",
    "        dataset: 질문-답변 쌍울 추출할 dataset\n",
    "        device\n",
    "        n: int - 추출할 질문-답변 쌍 개수 default: 10\n",
    "    \"\"\"\n",
    "    pass\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25d9fb1a-8b8a-4536-9dc3-554599757637",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7bc65a4-5082-4df5-90a6-6d26154698dc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "3c4965d1-a305-4465-8f64-f689d55490ac",
   "metadata": {},
   "source": [
    "# 새로운 데이터 추론"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "827215a2-7bdb-44c5-b891-8ff15ae621f5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cc2920e-fcdb-47d3-a61d-14c61ddb6809",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
